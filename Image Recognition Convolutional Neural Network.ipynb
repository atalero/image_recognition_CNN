{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Image Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4foVnI5Exbol"
   },
   "outputs": [],
   "source": [
    "import numpy as np, time\n",
    "import torch, torchvision\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "from google.colab import files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Download the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "vhRLVpgRKvms",
    "outputId": "955c838d-6799-46bb-99cf-c41e6f5a750f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor(),torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# change download to true for the firt time\n",
    "trainset = torchvision.datasets.CIFAR10(root=\"/data\", train=True,download=True, transform=transform)\n",
    "\n",
    "#validationset = torchvision.datasets.CIFAR10(root=\"/data\", train=True,download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root=\"/data\", train=False,download=True, transform=transform)\n",
    "\n",
    "#   After this step, trainset[i] will be a tuple containing a Pytorch Float-\n",
    "#   Tensor of shape (3,32,32) (size 32 by 32, 3 color channels) representing the\n",
    "#   i-th image (in trainset[i][0]), as well as the true label for this image (in\n",
    "#   trainset[i][1]). The labels are from 0 to 9 in the following order: plane, car,\n",
    "#   bird, cat, deer, dog, frog, horse, ship, truck.\n",
    "\n",
    "# activation = relU\n",
    "# cross entropy loss\n",
    "# number of layers and size should be a parameter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create test and validation loaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JfDzqcF9ecII"
   },
   "outputs": [],
   "source": [
    "train_length = len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YYCk_KgWd8vK"
   },
   "outputs": [],
   "source": [
    "valid_length = int(0.10*train_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38IQJuOqdPcF"
   },
   "outputs": [],
   "source": [
    "split = torch.utils.data.random_split(trainset,( valid_length, train_length - valid_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYmSZHZ3fOtn"
   },
   "outputs": [],
   "source": [
    "validationset = split[0]\n",
    "trainset = split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FeEKCkYB6CVR"
   },
   "outputs": [],
   "source": [
    "#create the test loader\n",
    "\n",
    "test_batch_size = 1000\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size= test_batch_size, shuffle = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qT62YHBzh6aR"
   },
   "outputs": [],
   "source": [
    "#NEW DEV LOADER (02/09 10:00PM)\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(validationset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Returns a loader for training data dependent on batch size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eXWH2x9C4WhT"
   },
   "outputs": [],
   "source": [
    "#NEW TRAIN LOADER (02/09 10:00PM)\n",
    "def get_train_loader(batch_size):\n",
    "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, num_workers=1,shuffle = True)\n",
    "\n",
    "    return(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define the loss and the optimizer for our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNVbe1Plbqzo"
   },
   "outputs": [],
   "source": [
    "def createLossAndOptimizer(net, learning_rate=0.001):\n",
    "    \n",
    "    #Loss function \"\"\"TO BE FINALLY DECIDED!!!\"\"\"\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    #Optimizer\n",
    "    #optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0, dampening=0, weight_decay=0, nesterov=False)\n",
    "    optimizer = optim.Adam(net.parameters(), lr=learning_rate, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "    #optimizer = optim.Adagrad(net.parameters(), lr=learning_rate, lr_decay=0.000083333, weight_decay=0, initial_accumulator_value=0)\n",
    "    #nesterov enables Nesterov momentum (default: False)\n",
    "    \n",
    "    return(loss, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of Architecture\n",
    "\n",
    "C = Convolution Layer<br>\n",
    "P = Pooling Layer<br>\n",
    "FC = Fully Connected Layer<br>\n",
    "D = Dropout<br>\n",
    "N = Normalization<br>\n",
    "O = Output\n",
    "\n",
    "C => N => RELU => P => C => N => RELU = > P => image flattening => FC => D => FC => O (softmax)\n",
    "\n",
    "See code cell below for dimensions and kernel parameters\n",
    "\n",
    "**Class for our CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5kPj04-GcEJ_"
   },
   "outputs": [],
   "source": [
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    #Our batch shape for input x is (3, 32, 32)\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.max_pool_kernel1 = 2\n",
    "        self.max_pool_kernel2 = 2\n",
    "        \n",
    "        #records num layers in convolution output\n",
    "        self.conv1_output = 12\n",
    "        self.conv2_output = 24\n",
    "        \n",
    "        self.linear_features = 500\n",
    "        \n",
    "        self.full_layer_dimension = self.conv2_output * 8 * 8\n",
    "        \n",
    "\n",
    "        #convolution params\n",
    "        k1 = 3\n",
    "        s1 = 1\n",
    "        p1 = 1\n",
    "        \n",
    "        k2 = 3\n",
    "        s2 = 1\n",
    "        p2 = 1\n",
    "        \n",
    "        #Input channels = 3, output channels = 12\n",
    "        self.conv1 = torch.nn.Conv2d(3, self.conv1_output, kernel_size=k1, stride=s1, padding=p1)\n",
    "        #output channel dimension is 32*32\n",
    "        \n",
    "        #normalization layer 1\n",
    "        self.norm1 = torch.nn.BatchNorm2d(num_features=self.conv1_output)\n",
    "        \n",
    "        self.conv2 = torch.nn.Conv2d(self.conv1_output, self.conv2_output, kernel_size=k2, stride=s2, padding=p2)\n",
    "        \n",
    "        #output channel dim is 32*32\n",
    "        \n",
    "        #normalization layer 2\n",
    "        self.norm2 =  torch.nn.BatchNorm2d(num_features=self.conv2_output)\n",
    "        #4608 input features, 64 output features (see sizing flow below)\n",
    "        \n",
    "        # linear takes:\n",
    "        #arg1 = input size = num_channels * width * length\n",
    "        #arg2  = output size\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(self.conv2_output * 8 * 8, self.linear_features)\n",
    "        \n",
    "        #second arg of fc2 is 10 because we only have ten labels!!!\n",
    "        self.fc2 = torch.nn.Linear(self.linear_features, 10)        \n",
    "        \n",
    "\n",
    "      \n",
    "    def forward(self, x):\n",
    "        #DOCS NOTES\n",
    "        #torch.nn.MaxPool2d(kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False)\n",
    "        #stride â€“ the stride of the window. Default value is kernel_size\n",
    "        \n",
    "        \"\"\"The most common form is a (max) pooling layer with \n",
    "        filters of size 2x2 applied with a stride of 2\"\"\"\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x , self.max_pool_kernel1 , stride=2)    #size 16    \n",
    "        \n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x , self.max_pool_kernel2 , stride=2)\n",
    "        \n",
    "        \n",
    "        x = x.view(-1, self.full_layer_dimension)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        x = F.dropout(x, p=0.5, training = self.training)\n",
    "        #DROPOUT LAYER WOULD GO HERE\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        #DIMENSION MAY BE WRONG\n",
    "        #return(F.log_softmax(x, dim=1))\n",
    "        return(F.softmax(x, dim=1))\n",
    "        #return(F.softmax(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to compute dimensions of output of a convolution layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cBIqMMIETr2H"
   },
   "outputs": [],
   "source": [
    "def calculate_layer_size(self, input, F, S, P):\n",
    "    #returns the dimension of the output layer\n",
    "    #F = filter dimension\n",
    "    #S = stride\n",
    "    #P = padding\n",
    "\n",
    "    numerator = W - F + 2*P\n",
    "    if numerator % S != 0:\n",
    "      print(\"ERROR IN DIMENSIONS SPECIFIED\")\n",
    "      return\n",
    "    return int(numerator/S) + 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class for training our model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lg1DwanMCC7G"
   },
   "outputs": [],
   "source": [
    "def trainNet(net, batch_size, n_epochs, learning_rate):\n",
    "  \n",
    "    #Print all of the hyperparameters of the training iteration:\n",
    "    print(\"===== HYPERPARAMETERS =====\")\n",
    "    print(\"batch_size=\", batch_size)\n",
    "    print(\"epochs=\", n_epochs)\n",
    "    print(\"learning_rate=\", learning_rate)\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    #Get training data\n",
    "    train_loader = get_train_loader(batch_size)\n",
    "    n_batches = len(train_loader)\n",
    "    \n",
    "    #Create our loss and optimizer functions\n",
    "    loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
    "    \n",
    "    #Time for printing\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    j = 0\n",
    "    \n",
    "    net.cuda()\n",
    "    \n",
    "    #Loop for n_epochs\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        start_time = time.time()\n",
    "\n",
    "        print(\"Current Epoch: \" + str(epoch) + \"/n\")\n",
    "        \n",
    "        e = int(epoch)\n",
    "        \n",
    "        #decrease learning rate\n",
    "        if e != 0 and e%30 ==0:\n",
    "            learning_rate/=10\n",
    "            print(learning_rate)\n",
    "            loss, optimizer = createLossAndOptimizer(net, learning_rate)\n",
    "\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            \n",
    "            #Get inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            #Set the parameter gradients to zero\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward pass, backward pass, optimize\n",
    "            outputs = net(inputs) #calls forward\n",
    "            \n",
    "            loss_size = loss(outputs, labels) #calculates loss (type of loss is specified in createLossAndOptimizer)\n",
    "            \n",
    "            loss_size.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            print_stats(outputs, labels, batch_size, loss_size, j)\n",
    "        \n",
    "            j+=1\n",
    "        \n",
    "        a = test_model( valid_loader, net, val = True)\n",
    "        net.train()\n",
    "        \n",
    "        if a > 70:\n",
    "          CC_70 = net\n",
    "        elif a > 75:\n",
    "          CC9_75 = net\n",
    "        elif a > 78:\n",
    "          CC9_78 = net\n",
    "        elif a > 80:\n",
    "          CC9_80 = net\n",
    "        elif a > 82:\n",
    "          CC9_82 = net\n",
    "          \n",
    "    print(\"Training finished, took {:.2f}s\".format(time.time() - training_start_time))\n",
    "    \n",
    "        \n",
    "    with open(\"net\", 'wb') as f:\n",
    "      pickle.dump(net, f)      \n",
    "    \n",
    "    files.download(\"net\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TAqX_ydNXnSg"
   },
   "outputs": [],
   "source": [
    "with open(\"cnn10\", 'wb') as f:\n",
    "  pickle.dump(CNN10, f)      \n",
    "files.download(\"cnn10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print output while training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l-29t_n8zE5J"
   },
   "outputs": [],
   "source": [
    "#copied from in-class pytorch tutorial, prints loss and accuracy so far\n",
    "def print_stats(outputs, labels, batch_size, loss_size, i):\n",
    "  predictions = outputs.data.max(1)[1]\n",
    "  accuracy = np.sum(predictions.cpu().numpy() == labels.cpu().numpy())/batch_size*100\n",
    "  \n",
    "  if i% 500 == 0:\n",
    "    print(\"Train step: {}\\tLoss: {:.3f}\\tAccuracy: {:.3f}\".format(i, loss_size.item(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that takes a loader and returns accuracy for data provided by loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "83_kG77_1T_U"
   },
   "outputs": [],
   "source": [
    "#copied from class tutorial. Call with the loader for either validation or test  data.\n",
    "def test_model(loader, model, val = False):\n",
    "  model.eval() #makes sure that dropout layers or batchnorm are not used (means \"evaluation mode\")\n",
    "  correct = 0\n",
    "  \n",
    "  for images, labels in loader:\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    \n",
    "    with torch.no_grad(): # impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you wonâ€™t be able to backprop (which you donâ€™t want in an eval script).\n",
    "      outputs = model(images)\n",
    "      predictions = outputs.data.max(1)[1]\n",
    "      correct += predictions.eq(labels.data).sum()\n",
    "  \n",
    "  a = 100.0 * correct / len(loader.dataset)\n",
    "  \n",
    "  if not val:\n",
    "    print(\"Test set accuracy: {:.2f}%\".format(a))\n",
    "  else:\n",
    "    print(\"Validation set accuracy: {:.2f}%\".format(a))\n",
    "  \n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7xe-p0cvXcUR"
   },
   "outputs": [],
   "source": [
    "CNN10.forward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy  on Validation Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "ElcvOuQiCjz4",
    "outputId": "53e66d2a-02d6-4b99-efde-56a3c726b16b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 73.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(73, device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DO NOT CHANGE!!\n",
    "test_model( valid_loader, CNN10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy  on Test Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uygk76kSCj6i",
    "outputId": "cba8a2ca-2923-4275-e7af-89fc432461ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 72.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(72, device='cuda:0')"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DO NOT CHANGE!!\n",
    "test_model(test_loader , CNN10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function that displays the image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GibfkmWMKpKy"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def imshow(img):\n",
    "  img = img / 2 + 0.5 # unnormalize\n",
    "  npimg = img.numpy()\n",
    "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to output prediction on any given image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EMK5NE7ox_7s"
   },
   "outputs": [],
   "source": [
    "def give_prediction(image):\n",
    "  classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "  b = torch.zeros([1, 3, 32, 32])\n",
    "  b[0] = image\n",
    "  r = CNN10(b.cuda())\n",
    "  return classes[r.data.max(1)[1].cpu().numpy()[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running our Model on Test  Set Images\n",
    "\n",
    "See below some images and the result of what our model predicts for each one of them. Given that we had high prediction accuracy (73.00%) on test set, most of these images output correct predictions. We chose images that are easy to interpret (from human eyes) despite the 32 by 32 image size (which is the original format of the images in the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "iHiaOyLNx8Vm",
    "outputId": "220bf32c-9c03-4a9e-b8cf-5e5a2eaaab59"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xt8VeWZL/Df2rfsnRu5h5tcBYkC\nrVov4EHlUlvo1KrzOYMySDvjWHv8wBEtBQ4qau1IxcuM2jMjUHE6Yod0mJnWOdKBoWpFG+LAdNAg\nGi4KMSYhCSG3fd97nT/8uPdK9lp5HgPkMv19/9r73U/W+2Zl7Sd7r/dmmKZpgoiI+uQa7AYQEQ0H\nTJZERApMlkRECkyWREQKTJZERApMlkRECp6BqORnU/Iyym58tRqvfOOq1PNRuUnVsUb63WKM34iL\nMXkB3Yipglwjoyzr2f9A5H9fkXrudsXE4ySMhKo+lzezvt5i8q+HzpD9+Sz5m/fQcveM1PNQRK4v\nYcr/U90u3f/dGOTz3taV+QvOfPk9vPun6XZ3R1XVKWoDEiMmqY4Vv/wrYkzHG69nlC2s/C1+vfi6\n1PNTHvmcA0BT1CfGFHU3izEftXlV9cVz8zPK1v/6N/jhwvnpgtxc8ThNwaCqvhEROS6ru1uMCboz\nr/UNb/4e/+faS3uUuZPy1fCzVuf3cr+T5WOPPYaDBw/CMAysW7cOM2fO/EI/Xzj14v5WPehc4y8Z\n7Cb0m3fC9MFuQr9kTx6e7QaAgskVg92Efhtz0bTBbkK/XFBx7t+j/UqW77zzDk6cOIHKykocO3YM\n69atQ2Vl5bluGxHRkNGve5ZVVVVYsGABAGDy5Mlob29HV1fXOW0YEdFQ0q9Pli0tLbjkkvTH3KKi\nIjQ3NyPX4X7Gja9W237t/vaRzv5UPyQEfqW7L3M+ZCli+rqzNGrn8JzhevW+4dluALht/6nBbkK/\nbTpeP9hN6Jdtzcob20rnpINHml5u7cj53LePdPbo+BlOHTyBXwUR+lZ26vlw6uAZtdNEw6J0HcOl\ng+fqfSb2XZ1u63Dq4Llt/yn8w1fKUs+HUwfPpuP1uGvSmHTBMOng2dYcxdLSnufvbDt4+vU1vKys\nDC0tLannp06dQmlpaX8ORUQ0LPQrWV5zzTXYtWsXAODQoUMoKytz/ApORPTfQb++hl922WW45JJL\ncOutt8IwDDz00EPnul1ERENKv+9Zrlq1Sh07d7xcnq+4VwcAbq98w64rJN/QcpnyvU8AMOP27TLj\n6fsk0aR8vzUc1d0jdSnu/UXicn0dYfvyUQA62tLPu2Nyu+KK38+lvJISij9zZ8ih3HKLq1u+TQwA\ncPjz9RDsblUd63jjHjFmhGk/KqSxqz312FSccwAwFL9j3C3/grm5Jar6juZmTh4BgJbc4tTjd880\niccZkVD2Byj+Nj7F2zRu2F+fvl7lbsW9975wuiMRkQKTJRGRApMlEZECkyURkQKTJRGRApMlEZEC\nkyURkQKTJRGRApMlEZHCgGwrMcZrP6PGWp6I61blCSvWkQlG5BknCcXKPQAQjWSWZQNo7UgfIBGT\n6wvZHMeOsIDTZ21KyP/juhyadBGA5o70tIhuxWlX/Hpwe3T/dxOG/At2xeyP1RpOl4c1U3MARBT1\nxTXLOAFwJeU/YkeW/QntiKXLc5O62WM+RdubDflY9fmaRf2AQx32K/wc6kqXf9QmrxQ0SdFuAPBk\nKVYQM+WLL+mwmpC/90yis1zhj58siYgUmCyJiBSYLImIFJgsiYgUmCyJiBSYLImIFJgsiYgUmCyJ\niBQGZFB6a1vmoPSyXuXhpHJQc5a8rWdIs2WERzdQt6OjI6PsAgBNli3PEw6DqK3CykHpMVMebB2H\nHBPqYwn95lD6zx5UbA8aV7TJG9MNEo8ptgSOOAza7oimy8Oa/SngvOWAlZnQbcMcUFyinQ6/XsJS\n3h7XDUp3GfJWuCGffB3XRXVb0ybO2O9FkjiTvtjLknLKKPToJpjkKf6EXsWfJsthkkbv8oTBbSWI\niM47JksiIgUmSyIiBSZLIiIFJksiIgUmSyIiBSZLIiIFJksiIoUBGZT+qZGTUVbWq7zLrRsknuvL\nFmOiYXlQbHdQN3A22GX//6TJUm4qVu0OKwdthzUrexvysaJ9DCRvjqZfUywqD1MxCN6niAGAuEvR\ndoeYLsvEhb5+PyvNot0xxcB1APAolrH3xO3fUtbySMkYVX1ZJWPFmPZPPxVjzLYmVX0jHcvTk0c6\nXfK5mpCtey97XYqZGoGAGOJy2BbA5fb3eJ5IKrdHcKrnrH6aiOgPBJMlEZECkyURkQKTJRGRApMl\nEZECkyURkQKTJRGRApMlEZECkyURkcKAzOBpcOVmlH25V3m3KS+hDwBmi/3S91bhDnkZ/VBEN4PH\naQOARksV7j62cEi1KaGYSgIgophN4rCKfg+m4fyn7bRUkVS03VBtdaH7/VS7QTjMUEpYyxWzmADA\n08d5+JzDLhYZ3Al5BkiOO/NaB4Acb7rcP/NSVX3HDL8Y0xzO3LKltyIzpqqvo6PFttwIpC+Yklx5\nW5dx+Zkz9uzkKq490yX//cKRbtvypLfnH9aInd0Mnn4ly+rqatxzzz2YMmUKAGDq1Kl48MEHz6oh\nRERDWb8/WV555ZV49tlnz2VbiIiGLN6zJCJSMExTsZRKL9XV1XjkkUcwbtw4tLe3Y/ny5bjmmmsc\n4zuPf4C8SdPOqqFERIOpX8myqakJBw4cwMKFC1FXV4dly5Zh9+7d8PnsO2l+fU3m4k8L327sUa7u\n4Oke6A6ezLg7Po3ihdHp9roV+5TrO3jkdp1NB8/3Pw3hqdHpZa+Sis4bTQePS9vB41acd0/mL/iD\nEyE8MT7d7kRS18Hj1Sxnp+zg8Sg6eFzuvIyy73/UgqcmlqSeJ+bMU9Wn6eD56NgxMcbX2qCqz66D\n5836Dlw7Jj99LLfcwXNpfuY5sJNnhsQYTQfPmebMDp6/ajyDe0cW9ChLxuQl4Z5pdW5Tv76Gl5eX\nY9GiRTAMA+PGjUNJSQmamnRr5hERDUf9SpavvPIKXnjhBQBAc3MzWltbUV5efk4bRkQ0lPSrN3ze\nvHlYtWoVfvOb3yAWi+Hhhx92/ApORPTfQb+SZW5uLp5//nl1/OGGroyyhb3KY1HlrdOYHJdMyPfF\nXIrtDQAgadh/+D5luXHoU9zTi5i6rQtciu0ZXIr7ny6383FMS3vdikHbLsVtbbdm/wYADqez57Fs\n7lkCQJbHcnNR8TcGAJiKQenK71dexT1Ls6jQttxlKf9IsQ0JAOw7dlyM6TjdKsZMKy5W1Zdv2g9w\nz89L37OcqLi/m2PoBn+7Fdu/ICrfZzRN+z6K3uXa97wTDh0iIlJgsiQiUmCyJCJSYLIkIlJgsiQi\nUmCyJCJSYLIkIlJgsiQiUhiQldKb2uwnp1vLsxzXJO/JrRj7bCgGn2a5dPUlHBaISFj+zyQV/3PM\nczloWzFI3NPHgbyW1/oYu26JkYP8LnmBBQCIQx6cb3rs/zZ+T1bqccSrXAjFK7fL5dO13UjIC1u0\njLBfKb3DUn64QbewxfEjH4gxnoi8aIw/USLGAMAUt/3f5uJEujwnJNcXVSwGAwDxiDx43auYgOF2\nuKbcvSaCJJU5xgk/WRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkM\nyAyehEM11nLD0I2u9yhmwhiKbVk1M4EAOB7JY3nBq5h2Yyq3inUpjuVVHMvj6mMGj+U1t2K2Uzxb\nvkzixfbbKfQWiMkzeLL89vs5FZaUph53Qbd1gceU42KavYUBhBSXaGfM/ljW8qZmeSsIADDMmBiT\n55WvhVFhedYNAJSZ9ttMl3V1pB4nTHl2TlIzLQxARPFeVuzYAlfS/vp09dpSRLkbtXM9Z/fjRER/\nGJgsiYgUmCyJiBSYLImIFJgsiYgUmCyJiBSYLImIFJgsiYgUBmRQutthywFruUs5YNSjGtwtD5x1\nQTdw1kja12dYxlb3Mf47pa9B4j0oRuG6FNs8eD32A7t7v5ZTmC8eK5wnb7uQGJEtxgCA2WK/xUiP\nY0XsB65byxMJ3aD07oQ8sDvpsd8KoreIP0eMOROzH7luLc8NFKjqmzA+IMYE4h1ijCeh2+ahPWp/\nXbVnp9uRDMoD3D1J3XsrrphYkFBMVjFM+/eWYfb8We3EECf8ZElEpMBkSUSkwGRJRKTAZElEpMBk\nSUSkwGRJRKTAZElEpMBkSUSkMCCD0rMcxqhayz2mbsCoZhHmpGJgt27YbB+BlnJT0XblrwdTMTo/\nAXmgbtyTpXqtq4/B65871Wm/graV3ysP2AaAoFcevO4vyrMtby8flXqcP260qr7xE8eLMaMuuFh1\nLHdRsRgTfOtt2/ILvrog9TjSIp9PAGiqqxNjPjl0QIxpLNcNgu/w2k9QqBs9NvXY09QiHqegs0tV\nn2bVdVMxAcPlMAg+3qs8oViZvc96NEG1tbVYsGABtm3bBgBoaGjA7bffjiVLluCee+5BNBo9q0YQ\nEQ11YrIMBoN49NFHMWvWrFTZs88+iyVLluDnP/85xo8fjx07dpzXRhIRDTYxWfp8PmzZsgVlZWWp\nsurqasyfPx8AMHfuXFRVVZ2/FhIRDQHiPUuPxwOPp2dYKBSCz/fZva7i4mI0Nzefn9YREQ0Rhqnp\nnQDw3HPPobCwEEuXLsWsWbNSnyZPnDiBNWvWYPv27Y4/23T4fZRX6G6iExENRf3qDc/OzkY4HIbf\n70dTU1OPr+h2/u+cKzPKftjShfUl6aWxshyWQuvNqWfdKmnKe1N73bp9yqPIPNaa5iAeL0336vo1\nvdPaFdoUcV5Ffb4c+97p/3W0Hn974ZjUc3ehfc+z1am4oje8qEiMAQCvvGIa/HmZbbrr1d9i0zeu\nSz3X9oaXDHBv+C9sesMfevQxPPLgutTzowPcGz5d2RuebbMH+d/t/T2+M+fS1PNz2xsunwdVb3gk\n803z9Oku3FfUc+m9qCHnhZ+0Oi9B169xlrNnz8auXbsAALt378acOXP6cxgiomFD/GRZU1ODxx9/\nHPX19fB4PNi1axeefPJJrF27FpWVlRg9ejRuuummgWgrEdGgEZPl9OnT8dJLL2WUv/jii+elQURE\nQ9GAzODxG/Yj9a3lHuWcGrchN1lz99N0n+VMT8vPJ+VbIUgqZw+o2u6R294Rc54dYX0tHpNrzJk6\nU4yZNu8GMQYAiseMFWNcufb3Wy9f9UDqcdYIeTsMAIqNC4B4QrclRmtMvsc26cqrxfI54y5U1Xdo\nX7UY87fvyMP23v74hKq+vLwRtuX7GttTj6+fJN/fNU8cV9WXaK2XYxTvG5dDH3WsV3lCO43OqZ6z\n+mkioj8QTJZERApMlkRECkyWREQKTJZERApMlkRECkyWREQKTJZERAoDs62Ew2BQa7np0g1KNxRx\nhmI1Cpfy/4TTCfJYfj7uVmwrYejq0ywCEnTLW0HkTJ7q+Jr/wvRrJTO/JB4ra8IkMeaUx35Ac2/v\n1X4iH6vpVEbZV+Z+Fdt/vTf1PNTWnhFjp7PrjBhzus158QSrtm457opZX8kou/2bN+LA3vSCF7O/\nf72qvtw58jVzwLIot5N/euPXqvpaOhpsyz+qT5eX5ckLplw1foqqvmCHvOCGKybHeBymHiR6LYIT\n56B0IqLzj8mSiEiByZKISIHJkohIgcmSiEiByZKISIHJkohIgcmSiEhhQAalexx2I7SWR7VpW7Ep\no5GQB667TeXK7A7/T3yWge9nDHk9bq9yJfiY4RdjRlTMkI8zfrLja/Ep6dWu32mWB3ef+XifGJP0\nBcQYAKg5dkyMOXn8aEbZkxt/iBd/uiX1PNt0XgneqlSxe2VD62nVsSKGPBng2uuvsy0PZKVXf+/u\njqrqC+SUyPV984/FmN8dOqSq7+M6+7+NmUgP7j70ibzjZFZAN0HByJLj8iLy6vSFDu+/aK+3HAel\nExENACZLIiIFJksiIgUmSyIiBSZLIiIFJksiIgUmSyIiBSZLIiIFJksiIoUBmcFjeOyrsZYbiu0U\nAMDtkqfwmAl5Rk3S0I3mTzpsBxF3pctDUflYSZfuVHsnyVs4nM6TZz4cevc9x9f2WV4709YpHquo\npFyMiRfpZm0kkvLsFbfP/pxby4OdcrsBAIFCMcQ7IkeMAYCK6ZeKMVfNt5/BYy0Px3Szjzxd8nU1\n8zJ5W4m5Cxap6qv8+d/blmdbZtqYUfm9dfDoYVV9eR6vGFPqlmMSSfs2tfR6zwUQU7XLCT9ZEhEp\nMFkSESkwWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkMyKD0pMt+S4Ue5fJYVwCAS7EdhEN1\nPUQN3SD4aG6+bXkwNzf1uKj8IvE44bCuvjNlo8SYA8dPiDE+h4kAANCVTLelqMj+97MqKZFjPkno\nBvxG43Jcbr59fdZyV468/QYAlI6fKMbMu/wK1bHmf/2P5PrGjLctHzshXR6N6K4Fj1/exiIcCYox\nPuWg+xmXfEksbzwqb1HRGupS1dddWCS3acZXxJjSYLd9+cWX9Xje9t47qnY5UX2yrK2txYIFC7Bt\n2zYAwNq1a/HNb34Tt99+O26//Xa88cYbZ9UIIqKhTvxkGQwG8eijj2LWrJ7Tqu677z7MnTv3vDWM\niGgoET9Z+nw+bNmyBWVlZQPRHiKiIUlMlh6PB35/5v2hbdu2YdmyZbj33ntx+rRuK1EiouHKME3d\nZrrPPfccCgsLsXTpUlRVVaGgoAAVFRXYvHkzGhsbsX79esefbfngfZRMu9jxdSKioa5fveHW+5fz\n5s3Dww8/3Gf8tnmzM8pWfnoGfz26IPU8HtctWxXwyD2EcUXPbFQ5aCqaW5BRdv+Rk/jLKeNSz7PK\nx4jH0faGd4xS9IY31IsxTr3hv95XhYVXp/9++W55ybuSMnmJtk8Uy+IBwIcf14kx0XAoo+x47WFM\nmlqReu5KyEu9AcDki6aIMTPOc2/4VyaMxP6PG1PPoxHd8oB+Q77Wg5F2MaZy289U9f3Xm7/LKNtb\n9e+YM+urqeeq3vCIrjfcp+gNv7pC/pBl1xu+5c3f4s5rey6Xp+kN39GWee19rl/jLFesWIG6us8u\n+urqakyZIl+QRETDmfjJsqamBo8//jjq6+vh8Xiwa9cuLF26FCtXrkQgEEB2djY2bNgwEG0lIho0\nYrKcPn06XnrppYzyr33ta+pKTIeB5D3Kk4qR5AB0d1jlr5Yxf5aqvtMF9ittW8uLFJ+sg3HdV6+j\nrfIK4OUXzxRjTn78oeNrnb70+Ul45fNuGvJX3mBUNyh9+owZYszXv/512/J1D6bvi0+ZNEFV35gx\nY8WYorKRqmMlFV/EWk7bfy3Otd4+8srXJwDEo85fCT/38t+9KMbs/ed/UtU3s8x+AP9EV7rt4bh8\nDtpiultOF18sXwv/Y8FCMcbT1GRbfsnV1/d4/vahd1XtcsLpjkRECkyWREQKTJZERApMlkRECkyW\nREQKTJZERApMlkRECkyWREQKTJZERAoDsq2EAftZItZyl6HL2zHFFJ6YW/612rJyxRgAeC9kPzPF\nWt5VUyseJ7vQfiZQb/nF8mySjm55K4ETDY2q10zFFeA/fUaM6W6zX9q/t1U/+GMxZvFtt4nl0Zhu\nxpCpmDkV7NItyhGJRMQYj0N1HsukFo9yS5Od//QvYkzVy78QYwItuiUUQ132F0PoeHrxk9Hl9ttm\nWI0ee5kYAwBXzZEXDy9TbLPiy7HfhmTkpJ4z67JGlKra5YSfLImIFJgsiYgUmCyJiBSYLImIFJgs\niYgUmCyJiBSYLImIFJgsiYgUBmRQOhIOI3Ut5aZunC5iigG9yfzMHRl7G3XlLDEGAN5rarUtd42Z\nkHrc2dAhHid6RjfwGT55Z7xjtYfl+jrDqtdMt1c8VvEIeUC9tzBbjAGAESNKxJiGxsytGfLGjuhR\nfrpT3tUQAEIh5/PwOeUYcRSOsB/8bJWb47evw2P5XKLbGwUjR8q7hs6c/mUxJni6TVVf2ST77VHG\nz5uTelwydZp4nPxSeddGAHArPqp1dsnbrBRm25/zZKDn7phJ5cQQJ/xkSUSkwGRJRKTAZElEpMBk\nSUSkwGRJRKTAZElEpMBkSUSkwGRJRKTAZElEpDBAM3jicnk8oTpUsLhMjLlq8VIxxn/5Var6Xv/H\nf7Yt95akl7vvOtYsHicZdzgHvY/ba9aBna52eZuHWJfzrKJIZ/q1rOw88VjZAXkLjpKRY8UYAHBn\n5YgxTa2Zv9/UsSN6lHeFdNtYJBSzcwrzR6iOFVH8DTuaMrfzmDy6AJ9aynNzdLOdLr1e3nbBp2j7\nJw31qvq8BfbHqrhxUepxxLTfIsbKpdzyIxmWt0dJJuRj1TV+oipvCsmzgfrCT5ZERApMlkRECkyW\nREQKTJZERApMlkRECkyWREQKTJZERApMlkRECgMyKD3hsIy+tTwS0w1KH3v9DWLMFd/5nhjzHyft\nB7L2ll86Siz35hwRj2OauoG6sWhEjAl2KgbX9lFfLJl+LRaRt7E4cvyoGHPBhRfLbQLgypIH3Yfj\n9ltwWMujyoHPAb88CL67Uz4HALB75ytizLvv/Wfmz/3yH/DoI4+knpeWl6rq+9oN3xBjJl80XYzx\nlI9W1dd5xn77ifyCdHuDEXkgeUQx2BwAooqdVoId8t/m7TffyCxcc19GeV2D7j3vRJUsN27ciAMH\nDiAej+Ouu+7CjBkzsHr1aiQSCZSWluKJJ56Azye/CYiIhisxWe7btw9HjhxBZWUl2tracPPNN2PW\nrFlYsmQJFi5ciKeffho7duzAkiVLBqK9RESDQrxnecUVV+CZZ54BAOTn5yMUCqG6uhrz588HAMyd\nOxdVVVXnt5VERIPMME3lvpwAKisrsX//frz11lupBHny5EmsXr0a27dvd/y5lsPvo6RCd0+LiGgo\nUnfw7NmzBzt27MDWrVtxww3pThZNrv3ZNVdmlH3/dBeeKkqvZhMJ627Yly79thhz05qHxRhtB8/L\nv8q8qf/yX/8If7rygfSxXn9TPI5H2cGTnRMQYw4fPCAfyLS/e94dCiEnYKnDK99rDhSWizHaDp6V\n96wUY0aPydwv+6uXT8G/H0h3pAWDuk4ETQePdsWrs+ngueGm21LPB7qDp7Nbd67sOnj+59euxD/u\neif1/Jx28Cj2fu8+0yrGvP3a7oyyV159BTd+48YeZR/87g3xWLVtzqt1qYYO7d27F88//zy2bNmC\nvLw8ZGdnIxz+bPP6pqYmlJXJy6YREQ1nYrLs7OzExo0bsWnTJhQUFAAAZs+ejV27dgEAdu/ejTlz\n5pzfVhIRDTLxa/jOnTvR1taGlSvTX59+/OMf44EHHkBlZSVGjx6Nm2666bw2kohosInJcvHixVi8\neHFG+YsvvqiuJBi3X13ZWp7MLlQdKzB+qhizqzrzvlFvje32A3B7KygsEsuz/H7xOEZC14/WWH9C\njAlH5FXCfVlZjq8ljfQXCp9fXgU9O79AjPH6nOuzcrndYkzUYbSytTyuXXlerg7/+qtfqo710gtb\nxBjTsG/Xf76THjFieHQT5w4dfE+M+e7ye8WYqYr7mgBgwP5kWctPt54WjxPqdr7vZxXrlu9Z7t2z\nS4w5uO9t2/KqN3/b43mRR92XbYvTHYmIFJgsiYgUmCyJiBSYLImIFJgsiYgUmCyJiBSYLImIFJgs\niYgUmCyJiBQGZFuJqMNsC2u5v3SE6lhv/f6/xJhXfvqyGPOly7+squ/CL33JttzlSv+fyepjtszn\n4qGwqr6gYvaDxyNPS3H5slWvTb/8KvFYEy6cJsYEAs71WbkVM3icZudYy71er6q+5lOfijH/9q//\nojqW3yt/tigqtl+haUx5ujwUDanqO370AzHmVzucl0b83LduuU2MAYDOTpt2fe1yHDt6LPW09UyL\nfKCE7lr/3ev/Lsa8W20/O8cqy2GFLcR7btESyJFnq/WFnyyJiBSYLImIFJgsiYgUmCyJiBSYLImI\nFJgsiYgUmCyJiBSYLImIFAZkUHoC9oOMreXhpG6r2JN1H4kxHpe8fHxHZ6eqPp/PfqtYa3lhobzt\nQu2nH6vqi8UdBthaZGUrtoIodN5uNa8o/Vp+QbF4rG7FVqpFRfJxAJzVTqA5OeltbT2Kwe0AUHvo\n92JMe7u8VQIAFOTliTFtbfbHspYnzKSqvvxceRvfmt/L2yJPnVqhqm/k2Em25fFE+r3p9H6wOv7h\nh6r6at+vEWOyXPK5Ks3Lty8v6Fmeo9j+pS/8ZElEpMBkSUSkwGRJRKTAZElEpMBkSUSkwGRJRKTA\nZElEpMBkSUSkMCCD0rsccrK1PNLVrTpWslQecD5x/DgxJmEYqvpM2NdnLQ8EAnJ9iYSqPrdPXnV9\nRJHzgPPPFY6c4PjayAsmph6bpnweQt3y32bs2LFiDNBzhXknwaD9IPhwOL0Ct6H8+zU1NYkxHuWq\n6zkOg5+tsnPtJwyUl49OPe5SnE8A6DjTJsZ0dsoD6o9+IA/+BoBR4ybYlhuWgeGGIb//Tn78saq+\neEie7FDglwfB+93211RGeVI3GcAJP1kSESkwWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkw\nWRIRKTBZEhEpqGbwbNy4EQcOHEA8Hsddd92F1157DYcOHUJBwWfbKdxxxx24/vrrHX/+VMI+J1vL\noxHd6PruiDwTxvTLswySHl191lkjTuVJuTpEYrptMzwBeSuBEaWjxJgLJthvEdD7tZJCeTsIw2EW\nk1VAuWR/Q8OnYozpcELPtKVntGT55ZlOAJBQzNowPLoZPG6PPJtkRIH9FiPFpSNTj+PJZlV98ZC8\nxUiws0OM+fj4EVV9FzacsC1vsJR3ddu/H6zqT55U1ReNyMeKmfK1F4xH7Mu7em0d45Nn2vVFTJb7\n9u3DkSNHUFlZiba2Ntx88824+uqrcd9992Hu3LlnVTkR0XAhJssrrrgCM2fOBADk5+cjFAqp5zkT\nEf13Id6zdLvdyM7OBgDs2LED1157LdxuN7Zt24Zly5bh3nvvxenTut3xiIiGK8M0FTcFAOzZsweb\nNm3C1q1bUVNTg4KCAlRUVGCZS/8sAAANA0lEQVTz5s1obGzE+vXrHX+27tAhXHDJJees0UREA02V\nLPfu3YtnnnkGP/3pT1OdOp87evQoHn74YWzbts3x52/Nyryxuj0S6lEezZL3wgaA5onOHRefM0fI\ne1MnFUs/AcCXr5mdUfY3D30fdz/yVOr5yfflfZKr335dVZ/pst9j3Wr0uMlizPjJ9ntF/+vPnsM3\nv70i9fxcdfB8+fLLxBgAKC6R67Pr4Fn6jTnY9ure1HNtB0/V3tfEmH+u3K461qjicjHGroPn3/5f\nJb7+R4tTz5uadB08XadbxJiWlgYxZuQFF6jqW/CtWzLKnvvLB7Di/h+l26To4Hlj56uq+ppP1Iox\nhT752stxZy7X98GZbkwr6NlZmq3o4PnPU87nXPwa3tnZiY0bN2LTpk2pRLlixQrU1dUBAKqrqzFl\nyhSxEUREw5nYwbNz5060tbVh5cqVqbJbbrkFK1euRCAQQHZ2NjZs2HBeG0lENNjEZLl48WIsXrw4\no/zmm28+Lw0iIhqKBmRbiQ6P/bf9HuUOS8P35gnLA3VjuYqB64ZuIHLQ4R6NtTy3SL4PN3riRar6\n8kuLxJip0+zvR1pdNNW5Q23O3K+mHo8dKd+Hc/jz9ZCVrbuHmOWTz7uZtN8yorjYcp4V22EAQE4g\nT4xxKa+FhGLC26gxY8Ty0vKRtjG9vX/wXTEmGOkSYxqb5IkAAFB7yL4+a3lXMCQep/lUvaq+aFy+\nP9+tmWToddv/bLzXz/rObsIipzsSESkwWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkwWRIR\nKQzIoHT4HaqxlhuqxY/gDcqDcPMD8iDjTvtxrBmiHW1i+enTrfKBTN0aoKGubjHmw8OHxZjGk3W2\n5au/cyN+u+ffUs9zA/LiAl7FSuLegG5hEhfkweTJeOa5Wnj1j/CLn//8Cx0HANpbTsn1KVex9/nk\nt0ttrf3iENZyt0t38Z1qbhRjIjH7VcKtOjvbVfW989abYnkkKi+kEQkFVfV5FBNRworJB6Zpf5yu\nXuUe5Xl3wk+WREQKTJZERApMlkRECkyWREQKTJZERApMlkRECkyWREQKTJZERApMlkRECgMyg8fl\nsZ/dYS33e+WZJADQjaQY03DiqBgTytJtg1B/8gPb8gNv7Uk9bjzVJB6nu71TVZ+pmNWgmevkPEvk\nb7D7l/+Qeqb6b2nIMx8Mt+5SchlyjYbN7swvPvsj/OLvX0gX6La7hwvy1gWxqDwLBgAmj7ffMsLK\nMOzPQ8CTPofNzfIWtwAwZtQoMebwB/K1l4zLW7EAQHub/Uw0a7mpuPpcytl4pibOZpvb3pJu+5zQ\nu9w0dLO+nPCTJRGRApMlEZECkyURkQKTJRGRApMlEZECkyURkQKTJRGRApMlEZHCgAxK92bniuU+\nj26QeNIlNzkSkQcZN3boBol3OyzbX/dpQ+qxTzHAvVQxwBgAukMhMSaelLeo6GsJ/UBOjqotaYrB\nw4o2aeOScfuB5IYZFWN6i5vygOyksu01NQfFmIumTrctj1quydEjddfCiRNHxJhwWN7CwVBNYwCc\n5gu4LOWGZjsP5dhvQzHg3PDKn+d82X5VueE5u8+G/GRJRKTAZElEpMBkSUSkwGRJRKTAZElEpMBk\nSUSkwGRJRKTAZElEpDAgg9IjDgPJreWmciRrVDEo3V80QowZlS3HAIDht1/lfcpls1KPc/PzxOOY\ncd3A54+PHxdjQmF54Lo/4LzyfE7Z2NRjt1teBd1tyKvTGzG5TQCQiMXEGKdzVVBSmnocj8rHAYBE\nMizGxKK6lcS7w/Jkh/c//FAsdymuYQDoaG8WY0zF28abZX8NZxwraX8wtyfdXkOz2rhyULrm2vP4\nvGKML8thUHqv8qRydX3HtkgBoVAIa9euRWtrKyKRCO6++25MmzYNq1evRiKRQGlpKZ544gn4fLo/\nCBHRcCQmy9dffx3Tp0/HnXfeifr6evz5n/85LrvsMixZsgQLFy7E008/jR07dmDJkiUD0V4iokEh\n3rNctGgR7rzzTgBAQ0MDysvLUV1djfnz5wMA5s6di6qqqvPbSiKiQaa+Z3nrrbeisbERzz//PP7s\nz/4s9bW7uLgYzc3yvRUiouHMME39Xc/Dhw9j9erVaG5uxr59+wAAJ06cwJo1a7B9+3bHn/u4thYT\npk49+9YSEQ0S8ZNlTU0NiouLMWrUKFRUVCCRSCAnJwfhcBh+vx9NTU0oKyvr8xh3L/xGRtnOY0ew\naPKU1HOfsocwqljKrTUgL0EWOove8IN7fokvLbgp9Xw49YY3vLcPo2ZcnXo+XHrDPzn2AcZOnpZ6\nPhi94XFFlf6szOUIW5o+Qkn5xNTzc9kbnjTl38+lHCBo1xseCYWQZbmWhmJveK7NkoP1J+owZvwF\nPY+l+Fx44uQnjq+Jp3H//v3YunUrAKClpQXBYBCzZ8/Grl27AAC7d+/GnDlzxEYQEQ1n4r+4W2+9\nFffffz+WLFmCcDiM9evXY/r06VizZg0qKysxevRo3HTTTdJhiIiGNTFZ+v1+PPXUUxnlL7744nlp\nEBHRUDQgM3jiDtsuWMtNyPcmAMBT2Pf9UQAYecF4MSa7bIyqvpjDjYop0y9NPe4OyUv7t7W0qurz\n5RSIMblF5WKM12HmEQAUjUrfyzFd8g0mr1u+6eVJ6rZ5MJPy/U8zYR9TOjF9zzIWku/VAUA03CXG\nhMPdqmMpmg6fz/5ecb51KwmH36+3hCnfJI1E5e1RtPcsXS7792AgL31/X9MdrN2mw+tWzMZTTHZx\nG/b3Pt1Gz98nqdhipC+cG05EpMBkSUSkwGRJRKTAZElEpMBkSUSkwGRJRKTAZElEpMBkSUSk8IVW\nHSIi+kPFT5ZERApMlkRECkyWREQKTJZERApMlkRECkyWREQKA7KeZW+PPfYYDh48CMMwsG7dOsyc\nOXMwmvGFVFdX45577sGUKZ/tGzR16lQ8+OCDg9wqWW1tLe6++2585zvfwdKlS9HQ0IDVq1cjkUig\ntLQUTzzxRGqnzqGkd7vXrl2LQ4cOoaDgs/U+77jjDlx//fWD20gHGzduxIEDBxCPx3HXXXdhxowZ\nw+KcA5ltf+2114b8eQ+FQli7di1aW1sRiURw9913Y9q0aef+nJsDrLq62vzud79rmqZpHj161PyT\nP/mTgW5Cv+zbt89csWLFYDfjC+nu7jaXLl1qPvDAA+ZLL71kmqZprl271ty5c6dpmqb51FNPmS+/\n/PJgNtGWXbvXrFljvvbaa4PcMllVVZX5F3/xF6Zpmubp06fN6667blicc9O0b/twOO+vvvqquXnz\nZtM0TfOTTz4xb7jhhvNyzgf8a3hVVRUWLFgAAJg8eTLa29vR1SWvZk1fnM/nw5YtW3rsvlldXY35\n8+cDAObOnYuqqqrBap4ju3YPF1dccQWeeeYZAEB+fj5CodCwOOeAfdsTCd2q54Np0aJFuPPOOwEA\nDQ0NKC8vPy/nfMCTZUtLCwoLC1PPi4qK0Nwsb/k5FBw9ehTf+973cNttt+Htt98e7OaIPB4P/H5/\nj7JQKJT6OlJcXDwkz71duwFg27ZtWLZsGe69916cPn16EFomc7vdyM7OBgDs2LED11577bA454B9\n291u97A478BnmyuuWrUK69atOy/nfFDuWVqZw2S25YQJE7B8+XIsXLgQdXV1WLZsGXbv3j1k7z1p\nDJdzDwDf+ta3UFBQgIqKCmzevBk/+clPsH79+sFulqM9e/Zgx44d2Lp1K2644YZU+XA459a219TU\nDJvzvn37dhw+fBg/+MEPepznc3XOB/yTZVlZGVpaWlLPT506hdLS0oFuxhdWXl6ORYsWwTAMjBs3\nDiUlJWhqahrsZn1h2dnZCIc/2+yrqalp2HzVnTVrFioqKgAA8+bNQ21t7SC3yNnevXvx/PPPY8uW\nLcjLyxtW57x324fDea+pqUFDQwMAoKKiAolEAjk5Oef8nA94srzmmmuwa9cuAMChQ4dQVlaG3Nzc\ngW7GF/bKK6/ghRdeAAA0NzejtbUV5eXyLotDzezZs1Pnf/fu3ZgzZ84gt0hnxYoVqKurA/DZfdfP\nRyUMNZ2dndi4cSM2bdqU6kEeLufcru3D4bzv378fW7duBfDZbb5gMHhezvmgrDr05JNPYv/+/TAM\nAw899BCmTZsm/9Ag6+rqwqpVq9DR0YFYLIbly5fjuuuuG+xm9ammpgaPP/446uvr4fF4UF5ejief\nfBJr165FJBLB6NGjsWHDBni9um2IB4pdu5cuXYrNmzcjEAggOzsbGzZsQHFx8WA3NUNlZSWee+45\nTJw4MVX24x//GA888MCQPueAfdtvueUWbNu2bUif93A4jPvvvx8NDQ0Ih8NYvnw5pk+fjjVr1pzT\nc84l2oiIFDiDh4hIgcmSiEiByZKISIHJkohIgcmSiEiByZKISIHJkohIgcmSiEjh/wMuC2aPlq39\nywAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "KHnDQ5yOygoG",
    "outputId": "9a5ac915-7485-422b-9a79-32b1af4f6a48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[6][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "lFdqSj2bytaU",
    "outputId": "9ba9e52c-d150-4bfb-fd48-5d856a50b736"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzP7iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ElO7haLrytf_",
    "outputId": "fa07f5ab-3956-47b5-dabe-8a227b7ad87a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deer'"
      ]
     },
     "execution_count": 104,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[100][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "GPtjeFcPytll",
    "outputId": "07fde6c9-705b-4dff-d0ed-b5a52cd34439"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XucFOWZL/BfdVf39GXuVyAGRQPK\nEUzixiToUeTyMR/J5qOYRMgESaIxGBYO6BogiEhiIoqXc5RswkVhEzGHSSbJWffEz4FDNFmTDJOF\nTdwMa0QSRcCZYYYZhrn0tbrOHx67a6ar5nkcYC6b3/ev6affqXq7uvqZnqrnfV/Dtm0bREQ0KN9I\nd4CIaCxgsiQiUmCyJCJSYLIkIlJgsiQiUmCyJCJSMIdjJ7fv+EFe7JvzP4X1P/vn7ONL3vx31bZC\ngTKxzWsTrxTbdAYjqv1duu2RvNjyHd/F5tuX5tqk3hS3U/yxS1X7CxfL/bLNjNgmnUq7xq9b+jj+\n5bt/n32cTCbFbfn9frGNqWgDAKl0t9gmmYjlxW74+53Y+/iXso8zad2p65dfHjJ/eku1reY/doht\nWj9RmxdbsfHrePLrG7OP37jp06r9hQ/+Xmwz5R/yz8+B/Kbuvfnjkr/Piz20YjHWPpn7/Iaj8naK\nmv9Ftb8/feizYpt40QVim3Hh/OrHjbOuwtdf+td+sUtip8RtfWOh93sz5GT50EMP4ZVXXoFhGFi7\ndi2uuOKK9/T7F5TJSW+0qpl00Uh3YciKqieOdBeGpGTcxSPdhSGruWDCSHdhyC4YVznSXRiS9xcr\nsvp7NKRk+bvf/Q5Hjx5FXV0d/vznP2Pt2rWoq6s7130jIho1hnTNsqGhAXPnzgUAXHLJJejq6kJP\nT8857RgR0WhiDGW44/3334+ZM2dmE2ZtbS2+/e1vY9KkSa7tj3d2jul/u4mIzskNHinfOm/kvGvH\n7Yv73fgZSzd4vvXSC1g3a16uzRi6wfPJDT/GzzfkLqyPlRs8n330V/jx12ZmH4+lGzwPPbsZa29b\nnn08lm7w/GDjPVj89SdyfRojN3h23XQ9Fv3TL/vFzvYGz5D+Da+urkZ7e3v28cmTJ1FVVTWUTRER\njQlDSpbXXHMN9uzZAwA4dOgQqqurUVhYeE47RkQ0mgzp3/Arr7wSl19+ORYuXAjDMPDAAw+c634R\nEY0qQ75mee+996rbBmHIcdtSbSttyNfrbFO+ZxVQtAGA4AUVYryqMCBvp6ZUtT/TL3/Z9/nkvntd\nswSAaCTs2Jbcp2QiJbYx/O7v8UB2Ru57xnbvlDNeENb9JxMoKxbbpIJhsQ0AVFadEdtEPuB+zXmS\nI+635WufAJCB93v4LrO4SGzT59Nds/QFQmI8ifzryQMF2rtU+wt1yu0S4XKxTWVPwiN+ut/jaFJ3\n3L1wuCMRkQKTJRGRApMlEZECkyURkQKTJRGRApMlEZECkyURkQKTJRGRApMlEZHCsCwr4cu4j0To\nF9eO4PHYlpOZkUcZFCfjqv0Vvt995I0z7g/LIySMkDzKBwBUE+Zl5GM12Gacz5mBoLy7tGaWI3mU\nDwDEXGYUyuNz71PGyB3nkspxqv0VlcizlHdVdKq2VTZRPmeMaIFr/NLxuXhx8oRqf4ly95EpTtGP\nuU+L6NThMSJqoO5i9ymaqhzx3h555p5wy1HV/spaXhPbRErlz824mPtMVuPa/9J/W4Vnl+74zZKI\nSIHJkohIgcmSiEiByZKISIHJkohIgcmSiEiByZKISIHJkohIYViK0gGvouZc3DR0yxJkbLlAOpqU\np6uPpnpU+yuvdC+KdcZ9fvdCZCdD+fosWy66Nyy5KH2w5Wudz2n6lQnIp0kqoytKNwxFAX/A/Xj6\nHPFIkW4d+uLCSrGNFZIL8wHA7j0ptonYfa7xUkc8061bejdeIK/jW3yF+7InTiV+3etDqftnYooj\n3tLVJm4mmpIL1wFgYqJFbFNg1YhtqlLuy33UpPq/X7HAhap+eeE3SyIiBSZLIiIFJksiIgUmSyIi\nBSZLIiIFJksiIgUmSyIiBSZLIiKFYSlKtzyK0p1xU5m2rYw8lXi4p0Nsc2FcLogFgNKo++zYpcFc\nPByUZ3OO+MKq/cUhF3f7E/IM2ulBCtcDgVx/LUWBuxmJiG0MZWF35bgqsY1lhlzjF0y8KPtzKFqi\n2l8w7D7TvVMEur73JeTBDpm4+6zdGSs3Q3zIp5kOH0ilesU28ZD8/hkBeSAHAFxkuxd3O+NRxYz/\noSt0xd+BS8aLbQpC7ueCU5/fvXi/rLj/77aZRap+eeE3SyIiBSZLIiIFJksiIgUmSyIiBSZLIiIF\nJksiIgUmSyIiBSZLIiIFJksiIoVhGcFjZNxHEDjjPt0gA/gNecRCtEee+r7GPq3aX8RjeYYSf64f\n4aC8rETYkNsAgM+Ul13w+eWlIFIp7+UpQqFcX5IpeekC0yf3KRKWR1oAQCAit0vBYymP8twSEb6g\nbkRUqEwetZG05NcHAOlYodgm7jHKJ27kTnBLOYKnvESxdIZPHqFkW7r9GWn3c6bcEQ9EouJ2/NM/\notqfr1we6VNgy6PHTsP9HE4G+p9rPcGzG8EzpGTZ2NiIFStWYPLkyQCAKVOm4P777z+rjhARjWZD\n/mb50Y9+FE899dS57AsR0ajFa5ZERAqGbdu6CxoOjY2N+MY3voGJEyeiq6sLy5YtwzXXXOPZ/kRH\nB95XXn5WHSUiGklDSpatra04ePAgbrzxRhw7dgyLFy/G3r17EQy6T3V117atebEtX1nSL37psf/Q\nddiQL/jGC+S7RdNt3drGkYr8i/+zvroVL31vSfZxaVjuU8SQL4wDQMKU1w33JeUp2rxu8Hz4K5vx\n+23Ls4/Hyg2eqbd+A6/+6IHsY19Qt254ScXFYpszlvta3wP1th4R2yQ6TuTFPv7V72H/976afWz5\ndR+5kE9xTBU3i/Q3ePKvyv3NV5/Awe/dk33cHZfPBX9Q99nylU8X22hu8Pwl0ZkXu/VLa/CjnQ/3\nizUVTRW39c3P3OT53JD+Da+pqcG8efNgGAYmTpyIyspKtLa2DmVTRERjwpCS5fPPP49nnnkGANDW\n1oZTp06hpqbmnHaMiGg0GdLd8NmzZ+Pee+/FL37xC6RSKWzYsMHzX3Aiov8MhpQsCwsLsWXLFnX7\naNL9GqIzHrB1hcFmJv/6xEDFimtQZkSeHh8AwgH3aybOuN8nF5ynbbmYHgB8luKapeI6lX+Qd9b5\nXEDxz4VmKY+0X1d0HyqQC7uTcffrqLadK8aP9+oGFRRWyOdCUUT3h95QXJtOwn3AgOGI+5Ly0iEA\nUFyuuM7tkwcoxGMxsQ0AdPe4F9Qn4rllJUxL3h8K5evEAOCLVMuNMvL1+e5O9zbdff3jyajuM+iF\npUNERApMlkRECkyWREQKTJZERApMlkRECkyWREQKTJZERApMlkRECsMyU7rfo9C6X9ySJ3QAANPX\nK7YpCcjFp2aBbmILv8/9EDnjGcVEBRlbNxW8ZiZ4W1GUblne23E+l8kojlVAnpXcMHVF/jbkwQeG\n4VHY7YgnE/J5AAA9PfIghkKjRLUtUzFDfVGhe9G9M25YuqJ0n6LgPO0xu7mTOdgIhX479NifI26a\n8vcrs6hKtbtoqTwTWTrWLrZJxeKqePq0fC4Mht8siYgUmCyJiBSYLImIFJgsiYgUmCyJiBSYLImI\nFJgsiYgUmCyJiBSYLImIFIZlBA9sj6nhHfF00n1K+4F8QfdqfacCU17iwOfT/Z3wGivjjFsZeXRO\nwK9bNsNQ/P1KJOSp9gdb4Lh/d+X9FRTIxzPiMXJlIM1xTyXdR5L4PEb2DMbIyCNckJaPJwAETfk9\nDJa4jwYqccTTCd0yD6m0YjkPxQgev/LcKy0tFeMZxfIhRlR3LoQD8vt5vKVDbNN1plsVb219XdUv\nL/xmSUSkwGRJRKTAZElEpMBkSUSkwGRJRKTAZElEpMBkSUSkwGRJRKQwLEXpQcu9aNQZN5Knddsq\nkJcv0JTg2oNVbTukU+5LADjjZiAobsdrqYSB+nrlguWMxzIdTsGgd5+che+aftm23EZbMK4pStcM\nBNAU5gNAKi4vP2FG5WUzAMDnl/vuC4Vc4yFHvC+lW0LFUCwxEgjIn4fBlhhxCin67ou6F647JRTL\nbwBAolcuOH/z2Ftim6Ot7tsZGD/aIe9vMPxmSUSkwGRJRKTAZElEpMBkSUSkwGRJRKTAZElEpMBk\nSUSkwGRJRKQwLEXpBd0nxXjIkouHASBiVoptTJ+iSFy1N+/idWd8sALwd6WVRdSav1/hcFTRxrvQ\nurCwOPtzMuledO+kmb09rnx9mqJ0r0J5Z7ywUD4GAGAa8iz2sLRF4vJABq/X54z7FYXkAOBXdF1T\nlJ7yGFgxkOa4a46BptgcAAoC8qzrAcWs66cs98/fwPjbve6DY7RU3ywPHz6MuXPnYteuXQCA5uZm\n3HbbbaitrcWKFSuQTOpONiKisUpMln19fXjwwQcxY8aMbOypp55CbW0tfvjDH+LCCy9EfX39ee0k\nEdFIE5NlMBjE9u3bUV1dnY01NjZizpw5AIBZs2ahoaHh/PWQiGgUEK9ZmqYJ0+zfLBaLZa/TVVRU\noK2t7fz0joholDBs5fQ7mzdvRllZGRYtWoQZM2Zkv00ePXoUq1evxu7duz1/9+TJt1FdPeHc9JiI\naAQM6W54JBJBPB5HKBRCa2trv3/R3Wz97oN5sfs3fA8Pbvhq9nH1yddU+66qlO+GF5XId9DMAvfp\nqAYKmvl3G6+560n8ZsuK7OOSwiJxO9q74UnFmtIFQfkOqNfd8CmffwiHn1ub25/ibrjPlE8TM6K7\nO625G+42pdiln7kfr9XnzqNYTLf2dlhxN7W0RJ52DAD8kKc689v50+eVzb0bnfv+e/ZxrE9X+ZFM\nKN4bzTrsyrvhbtuadOs38caP1ufaRIvz2gzUldZ9tjR3w/9w9LjY5qcHj+bF6p7+Ryz48hf7xQ6+\nLd8NP/LCTzyfG1Kd5dVXX409e/YAAPbu3Ytrr712KJshIhozxK8MTU1NeOSRR3DixAmYpok9e/bg\nsccew5o1a1BXV4cJEybg5ptvHo6+EhGNGDFZTps2Dc8++2xefOfOneelQ0REo9GwjODxn24W4xE7\nrtpWgWJ0Dmz5ml5aOdV+wO9+iJz3xeJxue+2cn+mX+57QHGtx+fzfmudz/n98v29YEhedqFgkBFD\nTobiGltfX59r3HlNTTNqCgBCQfkUNzK6a3rptNzOst3fZ+fADeWKJuqlSM7VdjK2+5ChfvGkfK3Y\np1j2BACSKXlbnb3ygJe/nHZvMzAeLy5X9csLx4YTESkwWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEp\nMFkSESkwWRIRKQxLUXoo5V5k7IybLhNWuDEVBdkw5JcV6+tR7c+A3zUeT+YKb1NJueC8wH0zecLR\niNgmYMobSyW9C+Wdz/lMubg7opiMIhhVFqUrCqT7Yu7ni3MtEO1EGiVheVIHv60r2rYgn6NWyr0g\nO51yVKJbivUioPtMqCbJUL4+ze+nUvIADL+tLfKXv6tp3ue2HvfP8sB4+MMfVPXLC79ZEhEpMFkS\nESkwWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkMS1F6JOBeRO2Mm5Ey1bYyfjm/9/bKq+dZ\nipX6AMDwmPQ55oj7FTNtR4t0K96FQorifMX+/Ib363M+ZxbI+/MVyAMBzIBuUEFaU0TtVbjuiAcU\nM6ADQFwx+MAyFAMdAARLa8Q2vniXezxSkv0509Ou2l9KsfKmpr7dZ+pen+cM7v7cuWv55T6FoSu6\nNwx5cMUF1fLKm+PGl6jiPe97v6pfXvjNkohIgcmSiEiByZKISIHJkohIgcmSiEiByZKISIHJkohI\ngcmSiEiByZKISGF4lpXwGG3hjGtHgPT0nBHbGIrp+ItKilX7i6fdRyNYmVzc9MsjEYqKi1T78/nl\nJQAS8YS8Idt7FIWVTmZ/DipGRAWC8tITpqk7lSxLHjmVybgPJXHGY3F5eQMAQFB+bwpDur4fb28T\n27gtqTAewFvduVFllQW60Vy+jMfyGg5pyOdLSvmdKBBx/0ykI45RNL6kaxunTEK3ZEsmI58LVcXy\nciUf+y8Xq+K/MM7uuyG/WRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpDFNR\nunuRuDOeSsRU2woUyMXd5VVVYhu/sgg+4FEgXVSU60fU4/U5RaNR1f4Sfd1im1TaY60LBwNeawQA\naUVheP9tyYXPmYx2KQF5W4pVJVRLLgBAJCwX1BeXui9LMNCRk8fENm3tp/JiHwNw5Njb2ceFl1yg\n2l95VC7ITsTl9zJu65aVeO1Yc17sUgBNjnjAJ+/vfYW6z1amTy66D0bl73OX1hSq4r/tkj83g1F9\nszx8+DDmzp2LXbt2AQDWrFmDT33qU7jttttw22234Ze//OVZdYKIaLQTv1n29fXhwQcfxIwZM/rF\n77nnHsyaNeu8dYyIaDQRv1kGg0Fs374d1dXVw9EfIqJRSUyWpmkiFMof+L9r1y4sXrwYd999Nzo6\nOs5L54iIRgvDtj1XC+5n8+bNKCsrw6JFi9DQ0IDS0lJMnToV27ZtQ0tLC9avX+/5u6db30JpzcRz\n1mkiouE2pLvhzuuXs2fPxoYNGwZt/382r8yLLfzWT7F73S3Zx760PPUToLwbXj1ObKO9G55wuRs+\n565H8YstX8s+1twNn1Dhfscub3+Ku+ExzTR1HnfDp9/5Xfxx+9Ls46LK8eK2ShRtzICuCi2tuJPf\n1pY/FdqU+ffh8M++nX18srVVtb+SErkKYfwHpqq29W+Hh3Y3/PMrnsBzT96Tffwh7d1wUz5WXYq7\n4T3Ku+FHW/P/Q/z0Xd/CT7asyz4e7rvhqag8leIfUvlVA0sXfw3f/cGj/WI7u+Tz+F+XL/J8bkh1\nlsuXL8exY++cOI2NjZg8efJQNkNENGaI3yybmprwyCOP4MSJEzBNE3v27MGiRYuwcuVKhMNhRCIR\nbNy4cTj6SkQ0YsRkOW3aNDz77LN58U984hPqnQQD7rNVO+MBUy4eBoBIofxvlemTvzCHInLBLwBE\nAu7/wpSVlWV/ziTlWbsTScXs5gASCbmdXNYN+AYp/nY+pykm1/Tdyuj+SdFcIvd7zDzvjBeX6ArJ\nA4or8h1vnlBta2KRvM8yw/0jNaWqJvuzL6krjrb88ntjKGbpt5S12L0x9/fZGZ8ySb6EMK5MNwDj\n2J9fl/vUlX9ZY6CKQvdBKBW+/q/nwghnSiciOu+YLImIFJgsiYgUmCyJiBSYLImIFJgsiYgUmCyJ\niBSYLImIFJgsiYgUhmVZCdPnPprEGQ+busH+muEIAVP+GxCN6EYZJD1GgJhm7tD19spLHMRt3VIO\nfkPuu3UWSzO885zh+rMXzagbn2LUFKAbMeQ12YYzrpmQAwACPvm88lnKJTF6T4ttKvzux6HCn3v/\nkz29qv1lfPIos3RSPq/Scd3ru2ziBDEeVXy2WltaVPtL2HK/LMXnvdJjmNbA+HSO4CEiOv+YLImI\nFJgsiYgUmCyJiBSYLImIFJgsiYgUmCyJiBSYLImIFIalKD1U4L5khDPuVxSoAoDhl4uoCzz25xQI\n6F56IuFecO4s1LYsuTA4ZSvn9vfJBeCawm7DYyAAAGQcfc8oCrI1r8+2dSv6eS0Z0b+N+3vjjLss\nuumqMykPGKiplFcMBYCgJS8fEjvT7hpPJXLx7i55dU4AiEQuFNskFNvKeJzDAxWF3Av4i6xY9uee\nth5xOynoBmCEo/LAEJ/icxrwuZ/D0QHxiwrk92/QvpzVbxMR/ZVgsiQiUmCyJCJSYLIkIlJgsiQi\nUmCyJCJSYLIkIlJgsiQiUmCyJCJSGJYRPMFQRIz7FNPHA4BPkd+DHlP799+ObgiIYbmPfnDGDcXo\no3giqdpfUrH8RGCQ0TlZgyxPYdm553yKZSVCpnyamIrtAICVkduZgZAYL6t0P6cGOh2Xz6uulG7E\nSU1xodim0GOJg8KK8uzPsXhCtT+fpTimcXlUipnRvb50wn25C2fcCMojsAKWbomYgE8e9eWLyvtD\n2mPZmkz/3y2ydSOZPPtyVr9NRPRXgsmSiEiByZKISIHJkohIgcmSiEiByZKISIHJkohIgcmSiEhh\nWIrSzQL3AuJ+8ZSuYFRTvG5ALhK3M7oieL/HchDOuG3JBeddZ7pV+wspptGPRsJiG7/fu+DXdjyn\nKs33KMzvt01dzT0SisOesd2PgTMeLipV7S9YJh+rrjOnVdvKKJY0CRV6DMAorMn+XFyhKLQG0N3Z\nJzey5e875ZXlYhsASBa4DwZAOPea2rrkZSXCGY/tDGynWUKlQP4sB/xl7k/4i/s9jNu6YnkvqmS5\nadMmHDx4EOl0GkuWLMH06dOxatUqWJaFqqoqPProowgG5XVviIjGKjFZ7t+/H6+//jrq6urQ2dmJ\n+fPnY8aMGaitrcWNN96IJ554AvX19aitrR2O/hIRjQjxO/xVV12FJ598EgBQXFyMWCyGxsZGzJkz\nBwAwa9YsNDQ0nN9eEhGNMMN2rukqqKurw4EDB/DrX/86myDfeustrFq1Crt37/b8vd6OZkTLx599\nb4mIRoj6Bs++fftQX1+PHTt24IYbbsjGNbn29z9+JC/2X5f8D/x668pc4Bze4CmvrBTbBAuLxTYA\nEIvF8mKXL9yAQ7s3ZB93dnaI2znT1aXa37m6weO1dvqHbn8Cf9hxT/ZxcXGJuC1NG3OQG0pOMcUN\nnlg6/5y6+JPL8Jeffyf7OKS8wWMFzt0NnpKg4gaPL3+Gn6qZd6LtV9uzj7vb3dcWHyihuMET65P7\nHq3QHSu3GzzTP3Mf/lj/7ezj46obPPLsTAAQlt8aZArkEyZg5N/g+chn/hsO1D/VL3a4QD4OtZ9a\n7PmcqnTo5ZdfxpYtW7B9+3YUFRUhEokg/v+nhmptbUV1dbVmM0REY5aYLLu7u7Fp0yZs3boVpaXv\nZOarr74ae/bsAQDs3bsX11577fntJRHRCBP/53vhhRfQ2dmJlStz/zI//PDDWLduHerq6jBhwgTc\nfPPN57WTREQjTUyWCxYswIIFC/LiO3fuVO/EZ7pfz3LGbUt3n8mvmJHbUM3ardufz2NWcmfcVMwk\nHtJcoAFgp+Vrtz6/vD+f37vu1flcb1/+NdmBBitwf1c4rJu53FZcJvd6Z5xxw6e73B4t9ihYdggp\n2gBAuveM2MaAx8z64dz1stIJ8jVgAPjjiVfENuVl48Q2wVLd/jp63M+FHit3vqQhF5wbJboi+G64\nz8zulMnIn9NU0v1caI31j7+OqKpfXjjckYhIgcmSiEiByZKISIHJkohIgcmSiEiByZKISIHJkohI\ngcmSiEiByZKISGFYlpVIe8wM74z7fbqp9v2G3C4jz0R/Tp3LWeK7OuVZZGJxeQ2HjO09iikWT2R/\n9puK464YEeVTjZoCQgXy1P4Zj0FMBcHc72pGTQFAMCzPgJNQni89p+URPAGXkUWVAHqsXLwoWqTa\nX9WlHxTbFIbl969LMfIIAHo8Rsv0OJaJiJbIM/dkIrpZh3oV53H8tDzK563u/BPmkwD+o6N//M1J\n8minwfCbJRGRApMlEZECkyURkQKTJRGRApMlEZECkyURkQKTJRGRApMlEZHCsBSlJ9L5y4MOjId8\nurw9SK111jDXpKsKpC3L/RjkbUtR4J5QLD1hDNKnpKMv4aC8ZEQiJS9HWhTVvX8FLsutDpSE+/5M\nxzLB2uXufX65aDvgsezJQJYhv8/NLc15sYsAvNWSW/62TLeKBYJl8qqpp86cEtu83S4vXwsAXQn3\n497Wm4uPq5YL6k8ql30+dvhPYpu2461im5aaK13jTW3d/R6f+eB4Vb+88JslEZECkyURkQKTJRGR\nApMlEZECkyURkQKTJRGRApMlEZECkyURkcKwFKXHE+5F1M64phgbAOyAYmZv5azrGj6PYnlnPBBQ\nFDUrZxIvMuS/X/FYXGyTTHsXkicdgwGMpFxwHvYYVOCUHmR/Tr6UXFAfjyU84rnXbad1x7PYVgwG\n0Ix0ABAskM/RlMexcsaPt7ap9lc6Piq2aWmRt3XyZIdqf8UVNa5xwwxnf+5JyrOb//GVV1T7e+PF\nfWKb7l75fLFu+YhrvH3AZ8lfpJvB3Qu/WRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkwWRIR\nKTBZEhEpMFkSESmoRvBs2rQJBw8eRDqdxpIlS/Diiy/i0KFDKC0tBQDccccduP766z1/P+5R9e+M\nhwK6wUTpjJzfNUs4aEecAF6jO3JxQ7EkRoFyhFLGlreVSMmvz7a8F9ewHSMb0pa8PIPXqBSnWFwe\nVQQAKcijqzK2e5uMnXtNlmJpDQDo7ZGXOPAFwmIbADAy8nEIhd235Yw3n5CXSgCA15r/TWwTNeXR\nR5HCYtX+gh5LfjjjSUv+3KR7usU2AFDa3Se2KS91H1Xk1HHhRPftD4ifCepGankRM9T+/fvx+uuv\no66uDp2dnZg/fz4+/vGP45577sGsWbPOaudERGOFmCyvuuoqXHHFFQCA4uJixGIx9eJbRET/WYj/\n8/n9fkQiEQBAfX09rrvuOvj9fuzatQuLFy/G3XffjY4O3UB9IqKxyrCVa4ru27cPW7duxY4dO9DU\n1ITS0lJMnToV27ZtQ0tLC9avX+/5u11tJ1BS9b5z1mkiouGmuqvy8ssvY8uWLXj66adRVFSEGTNm\nZJ+bPXs2NmzYMOjv7935zbzYZ1dtxY83Lck+Lo1GVB2OKtboLowUiG1CEXn9agBw+1Ny6WfW4bX6\nb+XaQP57o720HPNYu9mpu7dXbJNIuE9zNnf5ZuzbvDz72PTLx7NUMbVVWaHu/TND8rRjCZcbPBfP\n+zv85YV/yD62fLobZuUXXCS20d7gOX1GvnHxduvJvNg1f/sF/OZ/fz/7+A3lDZ72mPdNundpbvCE\nArpjFSnOX9D805/7In7yP/8x+9j2yX068PJLqv11/+JFsY1Pc4PnjnvyYs99eRE+//SufrEzH/uE\nuK1/nl7l3Rfpl7u7u7Fp0yZ8M85gAAAMUUlEQVRs3bo1e/d7+fLlOHbsGACgsbERkydPFjtBRDSW\niV8rXnjhBXR2dmLlypXZ2C233IKVK1ciHA4jEolg48aN57WTREQjTUyWCxYswIIFC/Li8+fPPy8d\nIiIajYZlWYkey70o3RkPKIqxAcBIy102Y/J2gn7ddZy03/2aUMpRzG375OtGpnKpC02xdRzyMhYZ\n07uNZeauQfoteX89Htc/ncyQfJ0YACJJuXg9VFTiHg/l3vtuXU06Tp5qEduURctV29LUwSc8rg86\n436P1zeQkegR21RVjxPblBbqllM4fvy4azzWnbtGHhpksMO7xpu6AQqTKhXn+vhqsc1vJ0xyjacH\nxC31nQN3HO5IRKTAZElEpMBkSUSkwGRJRKTAZElEpMBkSUSkwGRJRKTAZElEpDAsRemdGfeiWGfc\naJcLcAHADMgF2X7FYP+QoZtII1Hg/vfEOeFFzJbn94x4zEI9UF9MMZGGx0ziToUF3oXIRkGuKNpM\nywXE8bT83vT2KUYCAIgoavONtHsRvDNu2PJ5AABdne1iG6tbV0Rth+Xi9XDYveDcGR9fXaTaX1FU\nHgxQHJUL3EsUE6EAQE/3Gdd4aUlupvXmgwfE7QRbX1ftr6ZQPmfeKJf73l1UqYor6ukHxW+WREQK\nTJZERApMlkRECkyWREQKTJZERApMlkRECkyWREQKTJZERApMlkRECsMygidlTxDj8aaDqm3FffII\nlz7FyqbJi+VRNwBQMM591EZvLDcl/mlLHmmRMnSH2iyQl5S1EvJ0/LGE+1IeA58rishL0/oMeTr+\nZE+n2AYAeg15GEXG41j19vZlf7b9uuVrCxRvc3dSN3osaMrvTWXEfTRJZSB3nA3laK7eIvl9Tvvl\n5TzimvUwAASD7sfdGT/dfljczsQeedQUAPgj8oioUxMvFtvYHsdzYNzvtq71e8BvlkRECkyWREQK\nTJZERApMlkRECkyWREQKTJZERApMlkRECkyWREQKw1OUfvS0HD/whmpbfRn3bTn1TpCnorery1T7\nC3ss83DGEY/55KLtVK9cuA4AmsUSUrZc2J0+0+X5XF9XR66dLS9xUFolL13QHdMtK9F+xrtY/l1h\nlyL/DwBoP+1YVsLUFRgHA0GxjXKFCsCWi7vtpHsVvDNulumWeSgvkYvg3+xwXwrCqfuUbsBA8u1W\n13ifI261HhW3U2brzvX2kilym4umiW2MoPtxGhj3pc9uXQl+syQiUmCyJCJSYLIkIlJgsiQiUmCy\nJCJSYLIkIlJgsiQiUmCyJCJSGJaidP8B91nQnfGK1pOqbdmBXrnRJRVik4JSuQ0AWKb7LMzOuK2Y\n/TuR0hVRJzLyTPC2Ty7sjia9C5ELHM/Fjx8Xt9WbdJ/92ymtrOy2DbldrCcuxtNJ76J7p4DiuKcj\nyo9BUC627grknwtTZgLHj7yZfWxML1XtrqCoWGxzIiV/3+k9cUq1P9/v/j0/+HdApyNuvt4ibsea\nLA90AIBTEz8ktukaLxelBwLu59TAuJ3UDZzwIp4lsVgMa9aswalTp5BIJLB06VJcdtllWLVqFSzL\nQlVVFR599FEEg/JICSKisUpMli+99BKmTZuGO++8EydOnMDtt9+OK6+8ErW1tbjxxhvxxBNPoL6+\nHrW1tcPRXyKiESF+h583bx7uvPNOAEBzczNqamrQ2NiIOXPmAABmzZqFhoaG89tLIqIRpr5muXDh\nQrS0tGDLli340pe+lP23u6KiAm1tbeetg0REo4Fh2/r1IV999VWsWrUKbW1t2L9/PwDg6NGjWL16\nNXbv3u35e21H3kDVByadfW+JiEaI+M2yqakJFRUVGD9+PKZOnQrLshCNRhGPxxEKhdDa2orq6upB\nt/H0Z+/Mi3399/uw8cNzs48/8KfXVB3W3A2P/80HxDbFc6/T7c9lmqz5y76Jn31nffZxTLMWtqX8\nm5SRp3tT3Q0/7T7d1i3rv4+ffvML2cdFcfl4FlXLd8OTyrvhacXdcMNlLexZyzfipc1fz20nqZzy\n7hzeDY8E5Wn94oFxebHZd9yOF5/ZkX1sTJfvAgNAQVWV2OatNsWUhU1Nqv35fvV/82Jf+v4O7PzC\n7dnHpxr+l7idy5V3w49c9bdim9/OvENs01edv7b4P11eipsO9T82dq98N/z5j473fE68ZnngwAHs\n2PHOG93e3o6+vj5cffXV2LNnDwBg7969uPbaa8VOEBGNZeKf1IULF+K+++5DbW0t4vE41q9fj2nT\npmH16tWoq6vDhAkTcPPNNw9HX4mIRoyYLEOhEB5//PG8+M6dO89Lh4iIRqNhGcFTcdR9yQhnPGjJ\n1+EAoKdcnpI/cpF8MykV1k3tn7TdryH22f7sz5biOqOpaAMAlqJZwOgT24R63a9ZDnzOaHtL3NZp\nRbGDFdSNSgmXel8TelfK4+pQquVI9ud0b49qf/EWeSmI3oRuuYGoLZ8zzaUX5MVm33E7jrx8IPu4\nu2zwa/zvCvjla399cXkEj31MN4KnsMFlBA+AHke85C330VVOb095v2p/bZM/JraJRSaKbcyU+6i3\ngfFUSpdjvHBsOBGRApMlEZECkyURkQKTJRGRApMlEZECkyURkQKTJRGRApMlEZHCe5p1iIjorxW/\nWRIRKTBZEhEpMFkSESkwWRIRKTBZEhEpMFkSESkMy3yWAz300EN45ZVXYBgG1q5diyuuuGIkuvGe\nNDY2YsWKFZg8eTIAYMqUKbj//vtHuFeyw4cPY+nSpfjiF7+IRYsWobm5GatWrYJlWaiqqsKjjz6a\nXalzNBnY7zVr1uDQoUMoLX1n3sw77rgD119//ch20sOmTZtw8OBBpNNpLFmyBNOnTx8TxxzI7/uL\nL7446o97LBbDmjVrcOrUKSQSCSxduhSXXXbZuT/m9jBrbGy0v/KVr9i2bdtHjhyxb7311uHuwpDs\n37/fXr58+Uh34z3p7e21Fy1aZK9bt85+9tlnbdu27TVr1tgvvPCCbdu2/fjjj9vPPffcSHbRlVu/\nV69ebb/44osj3DNZQ0OD/eUvf9m2bdvu6OiwZ86cOSaOuW27930sHPef//zn9rZt22zbtu3jx4/b\nN9xww3k55sP+b3hDQwPmzn1nVcdLLrkEXV1d6OnRzXpN700wGMT27dv7rb7Z2NiIOXPmAABmzZqF\nhoaGkeqeJ7d+jxVXXXUVnnzySQBAcXExYrHYmDjmgHvfLcsa4V7J5s2bhzvvfGcF2ebmZtTU1JyX\nYz7sybK9vR1lZbklRcvLy9HWpli3YBQ4cuQI7rrrLnzuc5/Db37zm5Hujsg0TYRCoX6xWCyW/Xek\noqJiVB57t34DwK5du7B48WLcfffd6OjoGIGeyfx+PyKRd5ZPrq+vx3XXXTcmjjng3ne/3z8mjjvw\nzuKK9957L9auXXtejvmIXLN0ssfIaMuLLroIy5Ytw4033ohjx45h8eLF2Lt376i99qQxVo49ANx0\n000oLS3F1KlTsW3bNnznO9/B+vXr5V8cIfv27UN9fT127NiBG264IRsfC8fc2fempqYxc9x3796N\nV199FV/72tf6HedzdcyH/ZtldXU12tvbs49PnjyJKsVi8iOtpqYG8+bNg2EYmDhxIiorK9Ha6r0o\n2GgViUQQj7+z6FRra+uY+Vd3xowZmDp1KgBg9uzZOHz48Aj3yNvLL7+MLVu2YPv27SgqKhpTx3xg\n38fCcW9qakJzczMAYOrUqbAsC9Fo9Jwf82FPltdccw327NkDADh06BCqq6tRWKhbaXEkPf/883jm\nmWcAAG1tbTh16hRqampGuFfv3dVXX509/nv37sW11147wj3SWb58OY4dOwbgneuu71YljDbd3d3Y\ntGkTtm7dmr2DPFaOuVvfx8JxP3DgAHbs2AHgnct8fX195+WYj8isQ4899hgOHDgAwzDwwAMP4LLL\nLhvuLrxnPT09uPfee3HmzBmkUiksW7YMM2fOHOluDaqpqQmPPPIITpw4AdM0UVNTg8ceewxr1qxB\nIpHAhAkTsHHjRgQCgZHuaj9u/V60aBG2bduGcDiMSCSCjRs3oqKiYqS7mqeurg6bN2/GpEm55Zgf\nfvhhrFu3blQfc8C977fccgt27do1qo97PB7Hfffdh+bmZsTjcSxbtgzTpk3D6tWrz+kx5xRtREQK\nHMFDRKTAZElEpMBkSUSkwGRJRKTAZElEpMBkSUSkwGRJRKTAZElEpPD/AByyuPg/re5KAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[205][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Ae2nYAB2ytrw",
    "outputId": "2e4a16c3-7fb8-47d1-f971-d36d54444d66"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cat'"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[205][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "lxdFFmoYytwr",
    "outputId": "7159c6ef-2d36-484a-a40e-1f95d57d6455"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[3000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jyfFwLTWyt1a",
    "outputId": "cba9d06b-f239-4603-b7c3-7f7fc6a22f8d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dog'"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[3000][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "xqrQPa-Gz89O",
    "outputId": "283769fe-6d18-4452-d278-421ff7a680e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[609][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "ApLfbLLXz9OL",
    "outputId": "56be3fc3-85fd-48c6-f43f-991c835d5c6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truck'"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[609][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "l2W5N6AIz9UI",
    "outputId": "b5217768-cb7b-4680-e58d-2b2bd7d43f9a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[613][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "f1SEMKi0z9Zw",
    "outputId": "990e8e2c-e214-4269-d7cb-1a78fbb56454"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ship'"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[613][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "EVxp0VV00R8g",
    "outputId": "ba7ea813-960a-4ed3-d2e1-f8782837db74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[900][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "SCWJtgkL0UJh",
    "outputId": "fb13c701-11cd-4284-ef0e-5419489d1af4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deer'"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[900][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "M5jdeQG00Z06",
    "outputId": "26485959-5685-4fed-9bc3-dfafb291232c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[901][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "pcpmMaeO0aDI",
    "outputId": "a8165be6-f166-4970-b66f-b4714fb492cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 123,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[901][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "WtotKRqD0aKD",
    "outputId": "1ad07290-fab3-4c49-d3e6-36ccbb58fdf7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngcGSiEiBwZKISIHBkohIgcGSiEjh/wPrse4PfcftUgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[902][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8EfpPQT70aHp",
    "outputId": "a9e2262f-0bf1-4dc6-ca53-cbfbfc020412"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'frog'"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[902][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347
    },
    "colab_type": "code",
    "id": "BrYKjoCh0aBI",
    "outputId": "d2844509-b0a2-44cf-a458-643cdec183a3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(testset[9015][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WrRTeyFy0Z94",
    "outputId": "128ecbb3-96dc-4883-9bd0-8ceac374805f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ship'"
      ]
     },
     "execution_count": 128,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "give_prediction(testset[9015][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model\n",
    "\n",
    "In the cell below, you may view the logs for the final model (named CNN10), which was used to predict the images above.\n",
    "\n",
    "Parameters\n",
    "n_epochs = 120\n",
    "batch_size = 32\n",
    "learning_rate 0.001\n",
    "\n",
    "### Methods use to improve the model\n",
    "1. A dropout layer with dropout probability of 0.5 between two fully connected layers\n",
    "2. Optimizer: Adam\n",
    "3. Adaptive learning rate: every 30 epochs the learning rate is divided by 10\n",
    "4. Early stopping, we measure validation accuracy every epoch and save updates of the model at specific thresholds in case the model begins to degrade (however this was not necessary as our model did not degrade)\n",
    "\n",
    "### Results\n",
    "\n",
    "**Training accuracy** for last three training batches (the last epoch):<br>\n",
    ">  90.625%<br>\n",
    ">  84.375%<br>\n",
    ">  81.250%<br>\n",
    "        \n",
    "> Training Accuracy (taking the average): 85.425%\n",
    "        \n",
    "**Loss** on last three training batches (the last epoch):<br>\n",
    "> 1.575<br>\n",
    "> 1.629<br>\n",
    "> 1.648<br>\n",
    "        \n",
    "> Loss on training data (taking the average): 1.6173\n",
    "       \n",
    "**Validation Accuracy** : 73.00%\n",
    "\n",
    "**Test Set Accuracy**: 72.00%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 11316
    },
    "colab_type": "code",
    "id": "ZXWoN8tEWmYi",
    "outputId": "35e02c3e-4c0f-475a-f716-cdc27f219ac7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 120\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.305\tAccuracy: 6.250\n",
      "Train step: 500\tLoss: 2.013\tAccuracy: 46.875\n",
      "Train step: 1000\tLoss: 1.888\tAccuracy: 56.250\n",
      "Validation set accuracy: 48.00%\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 1.994\tAccuracy: 46.875\n",
      "Train step: 2000\tLoss: 1.951\tAccuracy: 50.000\n",
      "Train step: 2500\tLoss: 1.976\tAccuracy: 50.000\n",
      "Validation set accuracy: 53.00%\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 2.014\tAccuracy: 43.750\n",
      "Train step: 3500\tLoss: 1.957\tAccuracy: 50.000\n",
      "Train step: 4000\tLoss: 1.942\tAccuracy: 50.000\n",
      "Validation set accuracy: 58.00%\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 1.943\tAccuracy: 50.000\n",
      "Train step: 5000\tLoss: 1.865\tAccuracy: 62.500\n",
      "Train step: 5500\tLoss: 1.829\tAccuracy: 62.500\n",
      "Validation set accuracy: 60.00%\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 1.883\tAccuracy: 59.375\n",
      "Train step: 6500\tLoss: 1.825\tAccuracy: 65.625\n",
      "Train step: 7000\tLoss: 1.950\tAccuracy: 53.125\n",
      "Validation set accuracy: 60.00%\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 1.722\tAccuracy: 78.125\n",
      "Train step: 8000\tLoss: 1.706\tAccuracy: 75.000\n",
      "Validation set accuracy: 63.00%\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.853\tAccuracy: 59.375\n",
      "Train step: 9000\tLoss: 1.819\tAccuracy: 65.625\n",
      "Train step: 9500\tLoss: 1.777\tAccuracy: 65.625\n",
      "Validation set accuracy: 63.00%\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 1.680\tAccuracy: 78.125\n",
      "Train step: 10500\tLoss: 1.950\tAccuracy: 50.000\n",
      "Train step: 11000\tLoss: 1.843\tAccuracy: 62.500\n",
      "Validation set accuracy: 63.00%\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.846\tAccuracy: 62.500\n",
      "Train step: 12000\tLoss: 1.835\tAccuracy: 62.500\n",
      "Train step: 12500\tLoss: 1.841\tAccuracy: 62.500\n",
      "Validation set accuracy: 66.00%\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 1.792\tAccuracy: 65.625\n",
      "Train step: 13500\tLoss: 1.947\tAccuracy: 53.125\n",
      "Train step: 14000\tLoss: 1.803\tAccuracy: 65.625\n",
      "Validation set accuracy: 65.00%\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.899\tAccuracy: 56.250\n",
      "Train step: 15000\tLoss: 1.689\tAccuracy: 78.125\n",
      "Validation set accuracy: 67.00%\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.687\tAccuracy: 78.125\n",
      "Train step: 16000\tLoss: 1.821\tAccuracy: 62.500\n",
      "Train step: 16500\tLoss: 1.681\tAccuracy: 78.125\n",
      "Validation set accuracy: 67.00%\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.763\tAccuracy: 71.875\n",
      "Train step: 17500\tLoss: 1.861\tAccuracy: 59.375\n",
      "Train step: 18000\tLoss: 1.719\tAccuracy: 75.000\n",
      "Validation set accuracy: 68.00%\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 19000\tLoss: 1.697\tAccuracy: 78.125\n",
      "Train step: 19500\tLoss: 1.740\tAccuracy: 75.000\n",
      "Validation set accuracy: 68.00%\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.787\tAccuracy: 68.750\n",
      "Train step: 20500\tLoss: 1.728\tAccuracy: 71.875\n",
      "Train step: 21000\tLoss: 1.645\tAccuracy: 84.375\n",
      "Validation set accuracy: 68.00%\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.770\tAccuracy: 68.750\n",
      "Train step: 22000\tLoss: 1.780\tAccuracy: 68.750\n",
      "Train step: 22500\tLoss: 1.743\tAccuracy: 71.875\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.840\tAccuracy: 59.375\n",
      "Train step: 23500\tLoss: 1.719\tAccuracy: 71.875\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.828\tAccuracy: 62.500\n",
      "Train step: 24500\tLoss: 1.737\tAccuracy: 71.875\n",
      "Train step: 25000\tLoss: 1.778\tAccuracy: 68.750\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.562\tAccuracy: 90.625\n",
      "Train step: 26000\tLoss: 1.709\tAccuracy: 71.875\n",
      "Train step: 26500\tLoss: 1.706\tAccuracy: 75.000\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.819\tAccuracy: 62.500\n",
      "Train step: 27500\tLoss: 1.803\tAccuracy: 65.625\n",
      "Train step: 28000\tLoss: 1.796\tAccuracy: 65.625\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.840\tAccuracy: 62.500\n",
      "Train step: 29000\tLoss: 1.745\tAccuracy: 71.875\n",
      "Train step: 29500\tLoss: 1.705\tAccuracy: 75.000\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 30500\tLoss: 1.755\tAccuracy: 68.750\n",
      "Validation set accuracy: 71.00%\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.674\tAccuracy: 81.250\n",
      "Train step: 31500\tLoss: 1.617\tAccuracy: 81.250\n",
      "Train step: 32000\tLoss: 1.673\tAccuracy: 81.250\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.794\tAccuracy: 65.625\n",
      "Train step: 33000\tLoss: 1.730\tAccuracy: 71.875\n",
      "Train step: 33500\tLoss: 1.788\tAccuracy: 68.750\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.686\tAccuracy: 78.125\n",
      "Train step: 34500\tLoss: 1.724\tAccuracy: 71.875\n",
      "Train step: 35000\tLoss: 1.704\tAccuracy: 75.000\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.873\tAccuracy: 56.250\n",
      "Train step: 36000\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 36500\tLoss: 1.726\tAccuracy: 75.000\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.696\tAccuracy: 75.000\n",
      "Train step: 37500\tLoss: 1.607\tAccuracy: 87.500\n",
      "Validation set accuracy: 71.00%\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.748\tAccuracy: 68.750\n",
      "Train step: 38500\tLoss: 1.625\tAccuracy: 84.375\n",
      "Train step: 39000\tLoss: 1.630\tAccuracy: 84.375\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.695\tAccuracy: 78.125\n",
      "Train step: 40000\tLoss: 1.651\tAccuracy: 81.250\n",
      "Train step: 40500\tLoss: 1.832\tAccuracy: 62.500\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.666\tAccuracy: 81.250\n",
      "Train step: 41500\tLoss: 1.693\tAccuracy: 78.125\n",
      "Train step: 42000\tLoss: 1.699\tAccuracy: 75.000\n",
      "Validation set accuracy: 71.00%\n",
      "Current Epoch: 30/n\n",
      "0.0001\n",
      "Train step: 42500\tLoss: 1.560\tAccuracy: 90.625\n",
      "Train step: 43000\tLoss: 1.715\tAccuracy: 75.000\n",
      "Train step: 43500\tLoss: 1.689\tAccuracy: 78.125\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.676\tAccuracy: 78.125\n",
      "Train step: 44500\tLoss: 1.647\tAccuracy: 84.375\n",
      "Train step: 45000\tLoss: 1.814\tAccuracy: 62.500\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.696\tAccuracy: 75.000\n",
      "Train step: 46000\tLoss: 1.595\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.761\tAccuracy: 71.875\n",
      "Train step: 47000\tLoss: 1.712\tAccuracy: 75.000\n",
      "Train step: 47500\tLoss: 1.675\tAccuracy: 81.250\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.710\tAccuracy: 75.000\n",
      "Train step: 48500\tLoss: 1.604\tAccuracy: 87.500\n",
      "Train step: 49000\tLoss: 1.623\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.749\tAccuracy: 71.875\n",
      "Train step: 50000\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 50500\tLoss: 1.667\tAccuracy: 78.125\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.598\tAccuracy: 87.500\n",
      "Train step: 51500\tLoss: 1.698\tAccuracy: 75.000\n",
      "Train step: 52000\tLoss: 1.650\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.629\tAccuracy: 84.375\n",
      "Train step: 53000\tLoss: 1.586\tAccuracy: 87.500\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.659\tAccuracy: 84.375\n",
      "Train step: 54000\tLoss: 1.627\tAccuracy: 84.375\n",
      "Train step: 54500\tLoss: 1.644\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.659\tAccuracy: 81.250\n",
      "Train step: 55500\tLoss: 1.552\tAccuracy: 90.625\n",
      "Train step: 56000\tLoss: 1.667\tAccuracy: 81.250\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.699\tAccuracy: 75.000\n",
      "Train step: 57000\tLoss: 1.640\tAccuracy: 81.250\n",
      "Train step: 57500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.650\tAccuracy: 81.250\n",
      "Train step: 58500\tLoss: 1.679\tAccuracy: 81.250\n",
      "Train step: 59000\tLoss: 1.805\tAccuracy: 62.500\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.619\tAccuracy: 84.375\n",
      "Train step: 60000\tLoss: 1.688\tAccuracy: 75.000\n",
      "Train step: 60500\tLoss: 1.581\tAccuracy: 21.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.650\tAccuracy: 81.250\n",
      "Train step: 61500\tLoss: 1.752\tAccuracy: 71.875\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.726\tAccuracy: 71.875\n",
      "Train step: 62500\tLoss: 1.627\tAccuracy: 81.250\n",
      "Train step: 63000\tLoss: 1.744\tAccuracy: 71.875\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.743\tAccuracy: 71.875\n",
      "Train step: 64000\tLoss: 1.669\tAccuracy: 78.125\n",
      "Train step: 64500\tLoss: 1.697\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.651\tAccuracy: 81.250\n",
      "Train step: 65500\tLoss: 1.690\tAccuracy: 78.125\n",
      "Train step: 66000\tLoss: 1.669\tAccuracy: 78.125\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.670\tAccuracy: 78.125\n",
      "Train step: 67000\tLoss: 1.596\tAccuracy: 87.500\n",
      "Train step: 67500\tLoss: 1.711\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.576\tAccuracy: 87.500\n",
      "Train step: 68500\tLoss: 1.615\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.531\tAccuracy: 93.750\n",
      "Train step: 69500\tLoss: 1.504\tAccuracy: 96.875\n",
      "Train step: 70000\tLoss: 1.646\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.709\tAccuracy: 75.000\n",
      "Train step: 71000\tLoss: 1.667\tAccuracy: 81.250\n",
      "Train step: 71500\tLoss: 1.798\tAccuracy: 65.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 1.556\tAccuracy: 90.625\n",
      "Train step: 72500\tLoss: 1.586\tAccuracy: 87.500\n",
      "Train step: 73000\tLoss: 1.660\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.608\tAccuracy: 87.500\n",
      "Train step: 74000\tLoss: 1.639\tAccuracy: 81.250\n",
      "Train step: 74500\tLoss: 1.643\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.689\tAccuracy: 78.125\n",
      "Train step: 75500\tLoss: 1.641\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.614\tAccuracy: 84.375\n",
      "Train step: 76500\tLoss: 1.817\tAccuracy: 65.625\n",
      "Train step: 77000\tLoss: 1.663\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.561\tAccuracy: 93.750\n",
      "Train step: 78000\tLoss: 1.620\tAccuracy: 84.375\n",
      "Train step: 78500\tLoss: 1.674\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.635\tAccuracy: 84.375\n",
      "Train step: 79500\tLoss: 1.560\tAccuracy: 90.625\n",
      "Train step: 80000\tLoss: 1.639\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.705\tAccuracy: 78.125\n",
      "Train step: 81000\tLoss: 1.690\tAccuracy: 78.125\n",
      "Train step: 81500\tLoss: 1.571\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.570\tAccuracy: 90.625\n",
      "Train step: 82500\tLoss: 1.586\tAccuracy: 87.500\n",
      "Train step: 83000\tLoss: 1.641\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.587\tAccuracy: 87.500\n",
      "Train step: 84000\tLoss: 1.700\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 60/n\n",
      "1e-05\n",
      "Train step: 84500\tLoss: 1.678\tAccuracy: 78.125\n",
      "Train step: 85000\tLoss: 1.642\tAccuracy: 84.375\n",
      "Train step: 85500\tLoss: 1.667\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.632\tAccuracy: 81.250\n",
      "Train step: 86500\tLoss: 1.580\tAccuracy: 90.625\n",
      "Train step: 87000\tLoss: 1.606\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.591\tAccuracy: 87.500\n",
      "Train step: 88000\tLoss: 1.556\tAccuracy: 90.625\n",
      "Train step: 88500\tLoss: 1.595\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.614\tAccuracy: 84.375\n",
      "Train step: 89500\tLoss: 1.620\tAccuracy: 84.375\n",
      "Train step: 90000\tLoss: 1.754\tAccuracy: 71.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.706\tAccuracy: 75.000\n",
      "Train step: 91000\tLoss: 1.615\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 1.698\tAccuracy: 78.125\n",
      "Train step: 92000\tLoss: 1.642\tAccuracy: 84.375\n",
      "Train step: 92500\tLoss: 1.597\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.618\tAccuracy: 84.375\n",
      "Train step: 93500\tLoss: 1.709\tAccuracy: 75.000\n",
      "Train step: 94000\tLoss: 1.674\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.717\tAccuracy: 75.000\n",
      "Train step: 95000\tLoss: 1.599\tAccuracy: 87.500\n",
      "Train step: 95500\tLoss: 1.740\tAccuracy: 71.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.624\tAccuracy: 84.375\n",
      "Train step: 96500\tLoss: 1.702\tAccuracy: 75.000\n",
      "Train step: 97000\tLoss: 1.741\tAccuracy: 71.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.608\tAccuracy: 84.375\n",
      "Train step: 98000\tLoss: 1.682\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.724\tAccuracy: 75.000\n",
      "Train step: 99000\tLoss: 1.727\tAccuracy: 71.875\n",
      "Train step: 99500\tLoss: 1.678\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 100500\tLoss: 1.652\tAccuracy: 81.250\n",
      "Train step: 101000\tLoss: 1.630\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.562\tAccuracy: 90.625\n",
      "Train step: 102000\tLoss: 1.741\tAccuracy: 75.000\n",
      "Train step: 102500\tLoss: 1.604\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 103500\tLoss: 1.602\tAccuracy: 87.500\n",
      "Train step: 104000\tLoss: 1.638\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.579\tAccuracy: 87.500\n",
      "Train step: 105000\tLoss: 1.537\tAccuracy: 93.750\n",
      "Train step: 105500\tLoss: 1.647\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.712\tAccuracy: 75.000\n",
      "Train step: 106500\tLoss: 1.683\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.513\tAccuracy: 96.875\n",
      "Train step: 107500\tLoss: 1.611\tAccuracy: 87.500\n",
      "Train step: 108000\tLoss: 1.625\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 1.525\tAccuracy: 93.750\n",
      "Train step: 109000\tLoss: 1.694\tAccuracy: 78.125\n",
      "Train step: 109500\tLoss: 1.655\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.542\tAccuracy: 90.625\n",
      "Train step: 110500\tLoss: 1.746\tAccuracy: 68.750\n",
      "Train step: 111000\tLoss: 1.573\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.514\tAccuracy: 96.875\n",
      "Train step: 112000\tLoss: 1.677\tAccuracy: 78.125\n",
      "Train step: 112500\tLoss: 1.612\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.612\tAccuracy: 84.375\n",
      "Train step: 113500\tLoss: 1.677\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.681\tAccuracy: 78.125\n",
      "Train step: 114500\tLoss: 1.601\tAccuracy: 87.500\n",
      "Train step: 115000\tLoss: 1.558\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.620\tAccuracy: 84.375\n",
      "Train step: 116000\tLoss: 1.712\tAccuracy: 75.000\n",
      "Train step: 116500\tLoss: 1.633\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.588\tAccuracy: 87.500\n",
      "Train step: 117500\tLoss: 1.646\tAccuracy: 81.250\n",
      "Train step: 118000\tLoss: 1.723\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.606\tAccuracy: 84.375\n",
      "Train step: 119000\tLoss: 1.693\tAccuracy: 75.000\n",
      "Train step: 119500\tLoss: 1.578\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.656\tAccuracy: 78.125\n",
      "Train step: 120500\tLoss: 1.649\tAccuracy: 81.250\n",
      "Train step: 121000\tLoss: 1.639\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.591\tAccuracy: 87.500\n",
      "Train step: 122000\tLoss: 1.676\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.605\tAccuracy: 84.375\n",
      "Train step: 123000\tLoss: 1.671\tAccuracy: 78.125\n",
      "Train step: 123500\tLoss: 1.723\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 124500\tLoss: 1.564\tAccuracy: 90.625\n",
      "Train step: 125000\tLoss: 1.648\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.719\tAccuracy: 71.875\n",
      "Train step: 126000\tLoss: 1.653\tAccuracy: 81.250\n",
      "Train step: 126500\tLoss: 1.629\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 90/n\n",
      "1.0000000000000002e-06\n",
      "Train step: 127000\tLoss: 1.739\tAccuracy: 71.875\n",
      "Train step: 127500\tLoss: 1.662\tAccuracy: 78.125\n",
      "Train step: 128000\tLoss: 1.552\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.523\tAccuracy: 93.750\n",
      "Train step: 129000\tLoss: 1.529\tAccuracy: 93.750\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.677\tAccuracy: 81.250\n",
      "Train step: 130000\tLoss: 1.506\tAccuracy: 96.875\n",
      "Train step: 130500\tLoss: 1.625\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.741\tAccuracy: 71.875\n",
      "Train step: 131500\tLoss: 1.746\tAccuracy: 71.875\n",
      "Train step: 132000\tLoss: 1.559\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.657\tAccuracy: 81.250\n",
      "Train step: 133000\tLoss: 1.631\tAccuracy: 81.250\n",
      "Train step: 133500\tLoss: 1.494\tAccuracy: 96.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 134500\tLoss: 1.766\tAccuracy: 68.750\n",
      "Train step: 135000\tLoss: 1.668\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.607\tAccuracy: 87.500\n",
      "Train step: 136000\tLoss: 1.668\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.689\tAccuracy: 75.000\n",
      "Train step: 137000\tLoss: 1.707\tAccuracy: 75.000\n",
      "Train step: 137500\tLoss: 1.666\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.699\tAccuracy: 75.000\n",
      "Train step: 138500\tLoss: 1.666\tAccuracy: 84.375\n",
      "Train step: 139000\tLoss: 1.762\tAccuracy: 68.750\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 140000\tLoss: 1.605\tAccuracy: 87.500\n",
      "Train step: 140500\tLoss: 1.629\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 100/n\n",
      "Train step: 141000\tLoss: 1.647\tAccuracy: 81.250\n",
      "Train step: 141500\tLoss: 1.691\tAccuracy: 78.125\n",
      "Train step: 142000\tLoss: 1.573\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 101/n\n",
      "Train step: 142500\tLoss: 1.607\tAccuracy: 87.500\n",
      "Train step: 143000\tLoss: 1.605\tAccuracy: 87.500\n",
      "Train step: 143500\tLoss: 1.526\tAccuracy: 93.750\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 102/n\n",
      "Train step: 144000\tLoss: 1.651\tAccuracy: 81.250\n",
      "Train step: 144500\tLoss: 1.706\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 103/n\n",
      "Train step: 145000\tLoss: 1.605\tAccuracy: 84.375\n",
      "Train step: 145500\tLoss: 1.631\tAccuracy: 81.250\n",
      "Train step: 146000\tLoss: 1.652\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 104/n\n",
      "Train step: 146500\tLoss: 1.522\tAccuracy: 93.750\n",
      "Train step: 147000\tLoss: 1.592\tAccuracy: 87.500\n",
      "Train step: 147500\tLoss: 1.711\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 105/n\n",
      "Train step: 148000\tLoss: 1.692\tAccuracy: 75.000\n",
      "Train step: 148500\tLoss: 1.687\tAccuracy: 75.000\n",
      "Train step: 149000\tLoss: 1.567\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 106/n\n",
      "Train step: 149500\tLoss: 1.638\tAccuracy: 84.375\n",
      "Train step: 150000\tLoss: 1.559\tAccuracy: 90.625\n",
      "Train step: 150500\tLoss: 1.637\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 107/n\n",
      "Train step: 151000\tLoss: 1.577\tAccuracy: 87.500\n",
      "Train step: 151500\tLoss: 1.558\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 108/n\n",
      "Train step: 152000\tLoss: 1.689\tAccuracy: 78.125\n",
      "Train step: 152500\tLoss: 1.613\tAccuracy: 84.375\n",
      "Train step: 153000\tLoss: 1.612\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 109/n\n",
      "Train step: 153500\tLoss: 1.651\tAccuracy: 81.250\n",
      "Train step: 154000\tLoss: 1.733\tAccuracy: 71.875\n",
      "Train step: 154500\tLoss: 1.730\tAccuracy: 71.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 110/n\n",
      "Train step: 155000\tLoss: 1.639\tAccuracy: 84.375\n",
      "Train step: 155500\tLoss: 1.599\tAccuracy: 87.500\n",
      "Train step: 156000\tLoss: 1.629\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 111/n\n",
      "Train step: 156500\tLoss: 1.708\tAccuracy: 75.000\n",
      "Train step: 157000\tLoss: 1.668\tAccuracy: 78.125\n",
      "Train step: 157500\tLoss: 1.612\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 112/n\n",
      "Train step: 158000\tLoss: 1.704\tAccuracy: 75.000\n",
      "Train step: 158500\tLoss: 1.656\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 113/n\n",
      "Train step: 159000\tLoss: 1.629\tAccuracy: 84.375\n",
      "Train step: 159500\tLoss: 1.611\tAccuracy: 84.375\n",
      "Train step: 160000\tLoss: 1.554\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 114/n\n",
      "Train step: 160500\tLoss: 1.567\tAccuracy: 90.625\n",
      "Train step: 161000\tLoss: 1.635\tAccuracy: 81.250\n",
      "Train step: 161500\tLoss: 1.755\tAccuracy: 71.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 115/n\n",
      "Train step: 162000\tLoss: 1.656\tAccuracy: 81.250\n",
      "Train step: 162500\tLoss: 1.659\tAccuracy: 81.250\n",
      "Train step: 163000\tLoss: 1.630\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 116/n\n",
      "Train step: 163500\tLoss: 1.619\tAccuracy: 84.375\n",
      "Train step: 164000\tLoss: 1.618\tAccuracy: 84.375\n",
      "Train step: 164500\tLoss: 1.627\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 117/n\n",
      "Train step: 165000\tLoss: 1.631\tAccuracy: 81.250\n",
      "Train step: 165500\tLoss: 1.596\tAccuracy: 87.500\n",
      "Train step: 166000\tLoss: 1.594\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 118/n\n",
      "Train step: 166500\tLoss: 1.566\tAccuracy: 90.625\n",
      "Train step: 167000\tLoss: 1.629\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 119/n\n",
      "Train step: 167500\tLoss: 1.575\tAccuracy: 90.625\n",
      "Train step: 168000\tLoss: 1.629\tAccuracy: 84.375\n",
      "Train step: 168500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Training finished, took 2224.56s\n"
     ]
    },
    {
     "ename": "MessageError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d2f0a7e6e360>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mCNN10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-8a1d9f852f5c>\u001b[0m in \u001b[0;36mtrainNet\u001b[0;34m(net, batch_size, n_epochs, learning_rate)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"net\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m       \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"net\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0;34m'port'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m       \u001b[0;34m'path'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m       \u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m   })\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: TypeError: Failed to fetch"
     ]
    }
   ],
   "source": [
    "\n",
    "CNN10 = CNN()\n",
    "trainNet(CNN10, batch_size=32, n_epochs=120, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Models\n",
    "\n",
    "For record keeping, below are the outputs for training the model with other hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 10690
    },
    "colab_type": "code",
    "id": "SxbBfqYeZJPO",
    "outputId": "9d5e8686-c001-41b0-cfb7-86963d2b88e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 120\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.297\tAccuracy: 18.750\n",
      "Train step: 500\tLoss: 2.104\tAccuracy: 34.375\n",
      "Train step: 1000\tLoss: 2.017\tAccuracy: 43.750\n",
      "Validation set accuracy: 47.00%\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.088\tAccuracy: 37.500\n",
      "Train step: 2000\tLoss: 2.090\tAccuracy: 37.500\n",
      "Train step: 2500\tLoss: 1.819\tAccuracy: 68.750\n",
      "Validation set accuracy: 54.00%\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 1.802\tAccuracy: 65.625\n",
      "Train step: 3500\tLoss: 1.910\tAccuracy: 53.125\n",
      "Train step: 4000\tLoss: 1.766\tAccuracy: 71.875\n",
      "Validation set accuracy: 56.00%\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 1.873\tAccuracy: 59.375\n",
      "Train step: 5000\tLoss: 1.842\tAccuracy: 62.500\n",
      "Train step: 5500\tLoss: 1.859\tAccuracy: 59.375\n",
      "Validation set accuracy: 60.00%\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 1.805\tAccuracy: 62.500\n",
      "Train step: 6500\tLoss: 1.869\tAccuracy: 59.375\n",
      "Train step: 7000\tLoss: 1.934\tAccuracy: 53.125\n",
      "Validation set accuracy: 62.00%\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 1.751\tAccuracy: 68.750\n",
      "Train step: 8000\tLoss: 2.007\tAccuracy: 43.750\n",
      "Validation set accuracy: 63.00%\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.911\tAccuracy: 53.125\n",
      "Train step: 9000\tLoss: 1.797\tAccuracy: 65.625\n",
      "Train step: 9500\tLoss: 1.889\tAccuracy: 53.125\n",
      "Validation set accuracy: 62.00%\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 1.727\tAccuracy: 71.875\n",
      "Train step: 10500\tLoss: 1.830\tAccuracy: 65.625\n",
      "Train step: 11000\tLoss: 1.875\tAccuracy: 59.375\n",
      "Validation set accuracy: 64.00%\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.839\tAccuracy: 59.375\n",
      "Train step: 12000\tLoss: 1.830\tAccuracy: 62.500\n",
      "Train step: 12500\tLoss: 1.717\tAccuracy: 75.000\n",
      "Validation set accuracy: 65.00%\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 1.846\tAccuracy: 59.375\n",
      "Train step: 13500\tLoss: 1.826\tAccuracy: 65.625\n",
      "Train step: 14000\tLoss: 1.676\tAccuracy: 81.250\n",
      "Validation set accuracy: 66.00%\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.572\tAccuracy: 93.750\n",
      "Train step: 15000\tLoss: 1.803\tAccuracy: 62.500\n",
      "Validation set accuracy: 66.00%\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.754\tAccuracy: 75.000\n",
      "Train step: 16000\tLoss: 1.834\tAccuracy: 65.625\n",
      "Train step: 16500\tLoss: 1.777\tAccuracy: 68.750\n",
      "Validation set accuracy: 67.00%\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.753\tAccuracy: 71.875\n",
      "Train step: 17500\tLoss: 1.786\tAccuracy: 68.750\n",
      "Train step: 18000\tLoss: 1.798\tAccuracy: 65.625\n",
      "Validation set accuracy: 68.00%\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.736\tAccuracy: 75.000\n",
      "Train step: 19000\tLoss: 1.972\tAccuracy: 46.875\n",
      "Train step: 19500\tLoss: 1.670\tAccuracy: 81.250\n",
      "Validation set accuracy: 68.00%\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.811\tAccuracy: 65.625\n",
      "Train step: 20500\tLoss: 1.578\tAccuracy: 87.500\n",
      "Train step: 21000\tLoss: 1.614\tAccuracy: 84.375\n",
      "Validation set accuracy: 67.00%\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.701\tAccuracy: 75.000\n",
      "Train step: 22000\tLoss: 1.789\tAccuracy: 68.750\n",
      "Train step: 22500\tLoss: 1.831\tAccuracy: 59.375\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.795\tAccuracy: 65.625\n",
      "Train step: 23500\tLoss: 1.798\tAccuracy: 62.500\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.701\tAccuracy: 75.000\n",
      "Train step: 24500\tLoss: 1.800\tAccuracy: 65.625\n",
      "Train step: 25000\tLoss: 1.677\tAccuracy: 78.125\n",
      "Validation set accuracy: 68.00%\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.773\tAccuracy: 68.750\n",
      "Train step: 26000\tLoss: 1.718\tAccuracy: 75.000\n",
      "Train step: 26500\tLoss: 1.716\tAccuracy: 75.000\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.734\tAccuracy: 71.875\n",
      "Train step: 27500\tLoss: 1.673\tAccuracy: 78.125\n",
      "Train step: 28000\tLoss: 1.795\tAccuracy: 68.750\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.664\tAccuracy: 78.125\n",
      "Train step: 29000\tLoss: 1.835\tAccuracy: 62.500\n",
      "Train step: 29500\tLoss: 1.806\tAccuracy: 65.625\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.726\tAccuracy: 75.000\n",
      "Train step: 30500\tLoss: 1.659\tAccuracy: 81.250\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.821\tAccuracy: 62.500\n",
      "Train step: 31500\tLoss: 1.711\tAccuracy: 75.000\n",
      "Train step: 32000\tLoss: 1.837\tAccuracy: 62.500\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.649\tAccuracy: 81.250\n",
      "Train step: 33000\tLoss: 1.768\tAccuracy: 65.625\n",
      "Train step: 33500\tLoss: 1.791\tAccuracy: 65.625\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.722\tAccuracy: 75.000\n",
      "Train step: 34500\tLoss: 1.859\tAccuracy: 59.375\n",
      "Train step: 35000\tLoss: 1.938\tAccuracy: 50.000\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.662\tAccuracy: 78.125\n",
      "Train step: 36000\tLoss: 1.671\tAccuracy: 81.250\n",
      "Train step: 36500\tLoss: 1.654\tAccuracy: 78.125\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.675\tAccuracy: 78.125\n",
      "Train step: 37500\tLoss: 1.727\tAccuracy: 75.000\n",
      "Validation set accuracy: 69.00%\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.643\tAccuracy: 81.250\n",
      "Train step: 38500\tLoss: 1.676\tAccuracy: 81.250\n",
      "Train step: 39000\tLoss: 1.798\tAccuracy: 68.750\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.838\tAccuracy: 62.500\n",
      "Train step: 40000\tLoss: 1.573\tAccuracy: 90.625\n",
      "Train step: 40500\tLoss: 1.654\tAccuracy: 81.250\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.780\tAccuracy: 68.750\n",
      "Train step: 41500\tLoss: 1.586\tAccuracy: 90.625\n",
      "Train step: 42000\tLoss: 1.631\tAccuracy: 81.250\n",
      "Validation set accuracy: 70.00%\n",
      "Current Epoch: 30/n\n",
      "0.0001\n",
      "Train step: 42500\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 43000\tLoss: 1.669\tAccuracy: 75.000\n",
      "Train step: 43500\tLoss: 1.656\tAccuracy: 81.250\n",
      "Validation set accuracy: 71.00%\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.562\tAccuracy: 90.625\n",
      "Train step: 44500\tLoss: 1.699\tAccuracy: 78.125\n",
      "Train step: 45000\tLoss: 1.570\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.567\tAccuracy: 90.625\n",
      "Train step: 46000\tLoss: 1.616\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.655\tAccuracy: 78.125\n",
      "Train step: 47000\tLoss: 1.683\tAccuracy: 78.125\n",
      "Train step: 47500\tLoss: 1.627\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.564\tAccuracy: 90.625\n",
      "Train step: 48500\tLoss: 1.612\tAccuracy: 84.375\n",
      "Train step: 49000\tLoss: 1.702\tAccuracy: 75.000\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.696\tAccuracy: 75.000\n",
      "Train step: 50000\tLoss: 1.643\tAccuracy: 81.250\n",
      "Train step: 50500\tLoss: 1.653\tAccuracy: 81.250\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.811\tAccuracy: 62.500\n",
      "Train step: 51500\tLoss: 1.640\tAccuracy: 81.250\n",
      "Train step: 52000\tLoss: 1.699\tAccuracy: 75.000\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.555\tAccuracy: 90.625\n",
      "Train step: 53000\tLoss: 1.802\tAccuracy: 65.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.643\tAccuracy: 81.250\n",
      "Train step: 54000\tLoss: 1.756\tAccuracy: 68.750\n",
      "Train step: 54500\tLoss: 1.619\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.636\tAccuracy: 81.250\n",
      "Train step: 55500\tLoss: 1.788\tAccuracy: 68.750\n",
      "Train step: 56000\tLoss: 1.671\tAccuracy: 81.250\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.603\tAccuracy: 87.500\n",
      "Train step: 57000\tLoss: 1.930\tAccuracy: 53.125\n",
      "Train step: 57500\tLoss: 1.641\tAccuracy: 81.250\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.675\tAccuracy: 78.125\n",
      "Train step: 58500\tLoss: 1.680\tAccuracy: 78.125\n",
      "Train step: 59000\tLoss: 1.558\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.617\tAccuracy: 84.375\n",
      "Train step: 60000\tLoss: 1.743\tAccuracy: 71.875\n",
      "Train step: 60500\tLoss: 1.545\tAccuracy: 21.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.699\tAccuracy: 75.000\n",
      "Train step: 61500\tLoss: 1.784\tAccuracy: 65.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.533\tAccuracy: 93.750\n",
      "Train step: 62500\tLoss: 1.583\tAccuracy: 87.500\n",
      "Train step: 63000\tLoss: 1.675\tAccuracy: 78.125\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.596\tAccuracy: 87.500\n",
      "Train step: 64000\tLoss: 1.613\tAccuracy: 84.375\n",
      "Train step: 64500\tLoss: 1.562\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.584\tAccuracy: 87.500\n",
      "Train step: 65500\tLoss: 1.612\tAccuracy: 84.375\n",
      "Train step: 66000\tLoss: 1.759\tAccuracy: 68.750\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.637\tAccuracy: 81.250\n",
      "Train step: 67000\tLoss: 1.629\tAccuracy: 84.375\n",
      "Train step: 67500\tLoss: 1.603\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.701\tAccuracy: 75.000\n",
      "Train step: 68500\tLoss: 1.618\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.508\tAccuracy: 93.750\n",
      "Train step: 69500\tLoss: 1.755\tAccuracy: 71.875\n",
      "Train step: 70000\tLoss: 1.559\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.624\tAccuracy: 84.375\n",
      "Train step: 71000\tLoss: 1.628\tAccuracy: 81.250\n",
      "Train step: 71500\tLoss: 1.721\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 1.711\tAccuracy: 75.000\n",
      "Train step: 72500\tLoss: 1.588\tAccuracy: 87.500\n",
      "Train step: 73000\tLoss: 1.644\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 74000\tLoss: 1.653\tAccuracy: 81.250\n",
      "Train step: 74500\tLoss: 1.706\tAccuracy: 75.000\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.676\tAccuracy: 78.125\n",
      "Train step: 75500\tLoss: 1.616\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.556\tAccuracy: 90.625\n",
      "Train step: 76500\tLoss: 1.643\tAccuracy: 81.250\n",
      "Train step: 77000\tLoss: 1.613\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.728\tAccuracy: 71.875\n",
      "Train step: 78000\tLoss: 1.604\tAccuracy: 87.500\n",
      "Train step: 78500\tLoss: 1.614\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.612\tAccuracy: 87.500\n",
      "Train step: 79500\tLoss: 1.627\tAccuracy: 84.375\n",
      "Train step: 80000\tLoss: 1.571\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.575\tAccuracy: 87.500\n",
      "Train step: 81000\tLoss: 1.600\tAccuracy: 87.500\n",
      "Train step: 81500\tLoss: 1.518\tAccuracy: 93.750\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.619\tAccuracy: 84.375\n",
      "Train step: 82500\tLoss: 1.680\tAccuracy: 78.125\n",
      "Train step: 83000\tLoss: 1.595\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.752\tAccuracy: 71.875\n",
      "Train step: 84000\tLoss: 1.565\tAccuracy: 87.500\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 60/n\n",
      "1e-05\n",
      "Train step: 84500\tLoss: 1.578\tAccuracy: 90.625\n",
      "Train step: 85000\tLoss: 1.595\tAccuracy: 87.500\n",
      "Train step: 85500\tLoss: 1.708\tAccuracy: 75.000\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.640\tAccuracy: 81.250\n",
      "Train step: 86500\tLoss: 1.694\tAccuracy: 78.125\n",
      "Train step: 87000\tLoss: 1.661\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.620\tAccuracy: 84.375\n",
      "Train step: 88000\tLoss: 1.596\tAccuracy: 87.500\n",
      "Train step: 88500\tLoss: 1.622\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.543\tAccuracy: 93.750\n",
      "Train step: 89500\tLoss: 1.581\tAccuracy: 87.500\n",
      "Train step: 90000\tLoss: 1.588\tAccuracy: 87.500\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.682\tAccuracy: 78.125\n",
      "Train step: 91000\tLoss: 1.648\tAccuracy: 81.250\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 1.641\tAccuracy: 84.375\n",
      "Train step: 92000\tLoss: 1.580\tAccuracy: 87.500\n",
      "Train step: 92500\tLoss: 1.560\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 93500\tLoss: 1.607\tAccuracy: 87.500\n",
      "Train step: 94000\tLoss: 1.589\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.664\tAccuracy: 78.125\n",
      "Train step: 95000\tLoss: 1.697\tAccuracy: 78.125\n",
      "Train step: 95500\tLoss: 1.602\tAccuracy: 84.375\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.656\tAccuracy: 78.125\n",
      "Train step: 96500\tLoss: 1.745\tAccuracy: 71.875\n",
      "Train step: 97000\tLoss: 1.684\tAccuracy: 78.125\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.687\tAccuracy: 78.125\n",
      "Train step: 98000\tLoss: 1.563\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.639\tAccuracy: 84.375\n",
      "Train step: 99000\tLoss: 1.676\tAccuracy: 78.125\n",
      "Train step: 99500\tLoss: 1.616\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.672\tAccuracy: 78.125\n",
      "Train step: 100500\tLoss: 1.565\tAccuracy: 90.625\n",
      "Train step: 101000\tLoss: 1.655\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.671\tAccuracy: 78.125\n",
      "Train step: 102000\tLoss: 1.616\tAccuracy: 84.375\n",
      "Train step: 102500\tLoss: 1.553\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 1.690\tAccuracy: 78.125\n",
      "Train step: 103500\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 104000\tLoss: 1.622\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.617\tAccuracy: 84.375\n",
      "Train step: 105000\tLoss: 1.667\tAccuracy: 78.125\n",
      "Train step: 105500\tLoss: 1.565\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.710\tAccuracy: 75.000\n",
      "Train step: 106500\tLoss: 1.582\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.711\tAccuracy: 75.000\n",
      "Train step: 107500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 108000\tLoss: 1.814\tAccuracy: 62.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 1.647\tAccuracy: 81.250\n",
      "Train step: 109000\tLoss: 1.639\tAccuracy: 84.375\n",
      "Train step: 109500\tLoss: 1.694\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.590\tAccuracy: 87.500\n",
      "Train step: 110500\tLoss: 1.570\tAccuracy: 90.625\n",
      "Train step: 111000\tLoss: 1.609\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.674\tAccuracy: 78.125\n",
      "Train step: 112000\tLoss: 1.536\tAccuracy: 90.625\n",
      "Train step: 112500\tLoss: 1.671\tAccuracy: 78.125\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.628\tAccuracy: 84.375\n",
      "Train step: 113500\tLoss: 1.562\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.613\tAccuracy: 84.375\n",
      "Train step: 114500\tLoss: 1.570\tAccuracy: 87.500\n",
      "Train step: 115000\tLoss: 1.645\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.780\tAccuracy: 68.750\n",
      "Train step: 116000\tLoss: 1.708\tAccuracy: 75.000\n",
      "Train step: 116500\tLoss: 1.567\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.612\tAccuracy: 84.375\n",
      "Train step: 117500\tLoss: 1.564\tAccuracy: 90.625\n",
      "Train step: 118000\tLoss: 1.539\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.645\tAccuracy: 81.250\n",
      "Train step: 119000\tLoss: 1.531\tAccuracy: 93.750\n",
      "Train step: 119500\tLoss: 1.558\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.616\tAccuracy: 84.375\n",
      "Train step: 120500\tLoss: 1.588\tAccuracy: 87.500\n",
      "Train step: 121000\tLoss: 1.507\tAccuracy: 96.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 122000\tLoss: 1.658\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.669\tAccuracy: 81.250\n",
      "Train step: 123000\tLoss: 1.542\tAccuracy: 90.625\n",
      "Train step: 123500\tLoss: 1.627\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 124500\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 125000\tLoss: 1.652\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.656\tAccuracy: 81.250\n",
      "Train step: 126000\tLoss: 1.514\tAccuracy: 96.875\n",
      "Train step: 126500\tLoss: 1.543\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 90/n\n",
      "1.0000000000000002e-06\n",
      "Train step: 127000\tLoss: 1.617\tAccuracy: 84.375\n",
      "Train step: 127500\tLoss: 1.618\tAccuracy: 84.375\n",
      "Train step: 128000\tLoss: 1.613\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.527\tAccuracy: 93.750\n",
      "Train step: 129000\tLoss: 1.623\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.676\tAccuracy: 78.125\n",
      "Train step: 130000\tLoss: 1.540\tAccuracy: 93.750\n",
      "Train step: 130500\tLoss: 1.620\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.677\tAccuracy: 78.125\n",
      "Train step: 131500\tLoss: 1.554\tAccuracy: 90.625\n",
      "Train step: 132000\tLoss: 1.509\tAccuracy: 96.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.611\tAccuracy: 87.500\n",
      "Train step: 133000\tLoss: 1.614\tAccuracy: 87.500\n",
      "Train step: 133500\tLoss: 1.567\tAccuracy: 90.625\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.699\tAccuracy: 75.000\n",
      "Train step: 134500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 135000\tLoss: 1.558\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.556\tAccuracy: 90.625\n",
      "Train step: 136000\tLoss: 1.701\tAccuracy: 75.000\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.623\tAccuracy: 84.375\n",
      "Train step: 137000\tLoss: 1.586\tAccuracy: 87.500\n",
      "Train step: 137500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.697\tAccuracy: 75.000\n",
      "Train step: 138500\tLoss: 1.597\tAccuracy: 87.500\n",
      "Train step: 139000\tLoss: 1.514\tAccuracy: 93.750\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.521\tAccuracy: 93.750\n",
      "Train step: 140000\tLoss: 1.625\tAccuracy: 84.375\n",
      "Train step: 140500\tLoss: 1.657\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 100/n\n",
      "Train step: 141000\tLoss: 1.574\tAccuracy: 87.500\n",
      "Train step: 141500\tLoss: 1.629\tAccuracy: 84.375\n",
      "Train step: 142000\tLoss: 1.574\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 101/n\n",
      "Train step: 142500\tLoss: 1.587\tAccuracy: 87.500\n",
      "Train step: 143000\tLoss: 1.539\tAccuracy: 93.750\n",
      "Train step: 143500\tLoss: 1.539\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 102/n\n",
      "Train step: 144000\tLoss: 1.655\tAccuracy: 81.250\n",
      "Train step: 144500\tLoss: 1.505\tAccuracy: 96.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 103/n\n",
      "Train step: 145000\tLoss: 1.677\tAccuracy: 78.125\n",
      "Train step: 145500\tLoss: 1.637\tAccuracy: 84.375\n",
      "Train step: 146000\tLoss: 1.736\tAccuracy: 71.875\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 104/n\n",
      "Train step: 146500\tLoss: 1.602\tAccuracy: 84.375\n",
      "Train step: 147000\tLoss: 1.573\tAccuracy: 90.625\n",
      "Train step: 147500\tLoss: 1.609\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 105/n\n",
      "Train step: 148000\tLoss: 1.574\tAccuracy: 87.500\n",
      "Train step: 148500\tLoss: 1.640\tAccuracy: 84.375\n",
      "Train step: 149000\tLoss: 1.551\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 106/n\n",
      "Train step: 149500\tLoss: 1.585\tAccuracy: 87.500\n",
      "Train step: 150000\tLoss: 1.555\tAccuracy: 90.625\n",
      "Train step: 150500\tLoss: 1.601\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 107/n\n",
      "Train step: 151000\tLoss: 1.586\tAccuracy: 87.500\n",
      "Train step: 151500\tLoss: 1.613\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 108/n\n",
      "Train step: 152000\tLoss: 1.601\tAccuracy: 84.375\n",
      "Train step: 152500\tLoss: 1.657\tAccuracy: 81.250\n",
      "Train step: 153000\tLoss: 1.625\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 109/n\n",
      "Train step: 153500\tLoss: 1.576\tAccuracy: 87.500\n",
      "Train step: 154000\tLoss: 1.619\tAccuracy: 84.375\n",
      "Train step: 154500\tLoss: 1.553\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 110/n\n",
      "Train step: 155000\tLoss: 1.741\tAccuracy: 71.875\n",
      "Train step: 155500\tLoss: 1.660\tAccuracy: 84.375\n",
      "Train step: 156000\tLoss: 1.714\tAccuracy: 75.000\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 111/n\n",
      "Train step: 156500\tLoss: 1.678\tAccuracy: 78.125\n",
      "Train step: 157000\tLoss: 1.568\tAccuracy: 90.625\n",
      "Train step: 157500\tLoss: 1.585\tAccuracy: 87.500\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 112/n\n",
      "Train step: 158000\tLoss: 1.593\tAccuracy: 87.500\n",
      "Train step: 158500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 113/n\n",
      "Train step: 159000\tLoss: 1.659\tAccuracy: 81.250\n",
      "Train step: 159500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 160000\tLoss: 1.668\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 114/n\n",
      "Train step: 160500\tLoss: 1.609\tAccuracy: 84.375\n",
      "Train step: 161000\tLoss: 1.528\tAccuracy: 93.750\n",
      "Train step: 161500\tLoss: 1.579\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 115/n\n",
      "Train step: 162000\tLoss: 1.562\tAccuracy: 90.625\n",
      "Train step: 162500\tLoss: 1.622\tAccuracy: 84.375\n",
      "Train step: 163000\tLoss: 1.577\tAccuracy: 87.500\n",
      "Validation set accuracy: 72.00%\n",
      "Current Epoch: 116/n\n",
      "Train step: 163500\tLoss: 1.547\tAccuracy: 93.750\n",
      "Train step: 164000\tLoss: 1.613\tAccuracy: 84.375\n",
      "Train step: 164500\tLoss: 1.548\tAccuracy: 90.625\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 117/n\n",
      "Train step: 165000\tLoss: 1.705\tAccuracy: 75.000\n",
      "Train step: 165500\tLoss: 1.616\tAccuracy: 87.500\n",
      "Train step: 166000\tLoss: 1.619\tAccuracy: 84.375\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 118/n\n",
      "Train step: 166500\tLoss: 1.629\tAccuracy: 84.375\n",
      "Train step: 167000\tLoss: 1.516\tAccuracy: 93.750\n",
      "Validation set accuracy: 73.00%\n",
      "Current Epoch: 119/n\n",
      "Train step: 167500\tLoss: 1.541\tAccuracy: 90.625\n",
      "Train step: 168000\tLoss: 1.610\tAccuracy: 84.375\n",
      "Train step: 168500\tLoss: 1.632\tAccuracy: 81.250\n",
      "Validation set accuracy: 73.00%\n",
      "Training finished, took 5038.80s\n"
     ]
    }
   ],
   "source": [
    "#optimizer: ADAM\n",
    "CNN9 = CNN()\n",
    "trainNet(CNN9, batch_size=32, n_epochs=120, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3254
    },
    "colab_type": "code",
    "id": "QV-cI_Yt_hP5",
    "outputId": "805ddc3f-9068-4618-8f29-2fe4ce2c4bcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 45\n",
      "learning_rate= 0.015\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.303\tAccuracy: 18.750\n",
      "Train step: 500\tLoss: 2.249\tAccuracy: 25.000\n",
      "Train step: 1000\tLoss: 2.117\tAccuracy: 37.500\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.074\tAccuracy: 40.625\n",
      "Train step: 2000\tLoss: 2.158\tAccuracy: 25.000\n",
      "Train step: 2500\tLoss: 1.995\tAccuracy: 53.125\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 2.092\tAccuracy: 37.500\n",
      "Train step: 3500\tLoss: 2.085\tAccuracy: 43.750\n",
      "Train step: 4000\tLoss: 1.956\tAccuracy: 50.000\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 2.058\tAccuracy: 34.375\n",
      "Train step: 5000\tLoss: 1.875\tAccuracy: 59.375\n",
      "Train step: 5500\tLoss: 2.010\tAccuracy: 46.875\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 2.002\tAccuracy: 46.875\n",
      "Train step: 6500\tLoss: 1.922\tAccuracy: 56.250\n",
      "Train step: 7000\tLoss: 1.837\tAccuracy: 62.500\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 2.049\tAccuracy: 37.500\n",
      "Train step: 8000\tLoss: 1.998\tAccuracy: 46.875\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.857\tAccuracy: 59.375\n",
      "Train step: 9000\tLoss: 1.842\tAccuracy: 65.625\n",
      "Train step: 9500\tLoss: 1.848\tAccuracy: 62.500\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 1.804\tAccuracy: 65.625\n",
      "Train step: 10500\tLoss: 1.980\tAccuracy: 50.000\n",
      "Train step: 11000\tLoss: 1.931\tAccuracy: 46.875\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.931\tAccuracy: 53.125\n",
      "Train step: 12000\tLoss: 1.944\tAccuracy: 53.125\n",
      "Train step: 12500\tLoss: 1.784\tAccuracy: 65.625\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 1.914\tAccuracy: 56.250\n",
      "Train step: 13500\tLoss: 1.891\tAccuracy: 56.250\n",
      "Train step: 14000\tLoss: 2.031\tAccuracy: 43.750\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.747\tAccuracy: 75.000\n",
      "Train step: 15000\tLoss: 1.732\tAccuracy: 75.000\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.861\tAccuracy: 59.375\n",
      "Train step: 16000\tLoss: 1.852\tAccuracy: 62.500\n",
      "Train step: 16500\tLoss: 1.920\tAccuracy: 53.125\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.769\tAccuracy: 78.125\n",
      "Train step: 17500\tLoss: 1.851\tAccuracy: 62.500\n",
      "Train step: 18000\tLoss: 1.746\tAccuracy: 71.875\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.769\tAccuracy: 68.750\n",
      "Train step: 19000\tLoss: 1.772\tAccuracy: 68.750\n",
      "Train step: 19500\tLoss: 1.827\tAccuracy: 59.375\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.914\tAccuracy: 56.250\n",
      "Train step: 20500\tLoss: 1.759\tAccuracy: 68.750\n",
      "Train step: 21000\tLoss: 1.680\tAccuracy: 78.125\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.846\tAccuracy: 59.375\n",
      "Train step: 22000\tLoss: 1.984\tAccuracy: 50.000\n",
      "Train step: 22500\tLoss: 1.857\tAccuracy: 62.500\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.864\tAccuracy: 59.375\n",
      "Train step: 23500\tLoss: 1.755\tAccuracy: 71.875\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.713\tAccuracy: 75.000\n",
      "Train step: 24500\tLoss: 1.768\tAccuracy: 71.875\n",
      "Train step: 25000\tLoss: 1.836\tAccuracy: 62.500\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.826\tAccuracy: 62.500\n",
      "Train step: 26000\tLoss: 1.804\tAccuracy: 65.625\n",
      "Train step: 26500\tLoss: 1.810\tAccuracy: 62.500\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.796\tAccuracy: 65.625\n",
      "Train step: 27500\tLoss: 1.694\tAccuracy: 81.250\n",
      "Train step: 28000\tLoss: 1.776\tAccuracy: 68.750\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.795\tAccuracy: 68.750\n",
      "Train step: 29000\tLoss: 1.874\tAccuracy: 59.375\n",
      "Train step: 29500\tLoss: 1.829\tAccuracy: 59.375\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.724\tAccuracy: 81.250\n",
      "Train step: 30500\tLoss: 1.766\tAccuracy: 68.750\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.752\tAccuracy: 75.000\n",
      "Train step: 31500\tLoss: 1.847\tAccuracy: 62.500\n",
      "Train step: 32000\tLoss: 1.816\tAccuracy: 62.500\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.811\tAccuracy: 65.625\n",
      "Train step: 33000\tLoss: 1.831\tAccuracy: 62.500\n",
      "Train step: 33500\tLoss: 1.646\tAccuracy: 84.375\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.756\tAccuracy: 65.625\n",
      "Train step: 34500\tLoss: 1.790\tAccuracy: 68.750\n",
      "Train step: 35000\tLoss: 1.766\tAccuracy: 75.000\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.783\tAccuracy: 68.750\n",
      "Train step: 36000\tLoss: 1.790\tAccuracy: 65.625\n",
      "Train step: 36500\tLoss: 1.799\tAccuracy: 65.625\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.753\tAccuracy: 71.875\n",
      "Train step: 37500\tLoss: 1.663\tAccuracy: 84.375\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.710\tAccuracy: 75.000\n",
      "Train step: 38500\tLoss: 1.746\tAccuracy: 71.875\n",
      "Train step: 39000\tLoss: 1.736\tAccuracy: 71.875\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.745\tAccuracy: 68.750\n",
      "Train step: 40000\tLoss: 1.658\tAccuracy: 84.375\n",
      "Train step: 40500\tLoss: 1.762\tAccuracy: 65.625\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.728\tAccuracy: 75.000\n",
      "Train step: 41500\tLoss: 1.769\tAccuracy: 68.750\n",
      "Train step: 42000\tLoss: 1.635\tAccuracy: 84.375\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.830\tAccuracy: 59.375\n",
      "Train step: 43000\tLoss: 1.554\tAccuracy: 93.750\n",
      "Train step: 43500\tLoss: 1.768\tAccuracy: 71.875\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.594\tAccuracy: 90.625\n",
      "Train step: 44500\tLoss: 1.646\tAccuracy: 81.250\n",
      "Train step: 45000\tLoss: 1.676\tAccuracy: 84.375\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.740\tAccuracy: 75.000\n",
      "Train step: 46000\tLoss: 1.638\tAccuracy: 87.500\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.769\tAccuracy: 68.750\n",
      "Train step: 47000\tLoss: 1.758\tAccuracy: 75.000\n",
      "Train step: 47500\tLoss: 1.744\tAccuracy: 71.875\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.686\tAccuracy: 78.125\n",
      "Train step: 48500\tLoss: 1.558\tAccuracy: 93.750\n",
      "Train step: 49000\tLoss: 1.754\tAccuracy: 71.875\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.655\tAccuracy: 81.250\n",
      "Train step: 50000\tLoss: 1.710\tAccuracy: 75.000\n",
      "Train step: 50500\tLoss: 1.762\tAccuracy: 68.750\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.629\tAccuracy: 87.500\n",
      "Train step: 51500\tLoss: 1.738\tAccuracy: 71.875\n",
      "Train step: 52000\tLoss: 1.627\tAccuracy: 84.375\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.706\tAccuracy: 71.875\n",
      "Train step: 53000\tLoss: 1.640\tAccuracy: 84.375\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.710\tAccuracy: 81.250\n",
      "Train step: 54000\tLoss: 1.681\tAccuracy: 78.125\n",
      "Train step: 54500\tLoss: 1.614\tAccuracy: 87.500\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.604\tAccuracy: 87.500\n",
      "Train step: 55500\tLoss: 1.684\tAccuracy: 75.000\n",
      "Train step: 56000\tLoss: 1.624\tAccuracy: 84.375\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.703\tAccuracy: 78.125\n",
      "Train step: 57000\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 57500\tLoss: 1.827\tAccuracy: 65.625\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.611\tAccuracy: 87.500\n",
      "Train step: 58500\tLoss: 1.722\tAccuracy: 78.125\n",
      "Train step: 59000\tLoss: 1.545\tAccuracy: 90.625\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Train step: 60000\tLoss: 1.758\tAccuracy: 71.875\n",
      "Train step: 60500\tLoss: 1.710\tAccuracy: 18.750\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.760\tAccuracy: 71.875\n",
      "Train step: 61500\tLoss: 1.630\tAccuracy: 87.500\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.740\tAccuracy: 71.875\n",
      "Train step: 62500\tLoss: 1.778\tAccuracy: 71.875\n",
      "Train step: 63000\tLoss: 1.635\tAccuracy: 84.375\n",
      "Training finished, took 792.23s\n"
     ]
    }
   ],
   "source": [
    "#no adaptive learning rate, optimizer is SGD \n",
    "CNN8 = CNN()\n",
    "trainNet(CNN8, batch_size=32, n_epochs=45, learning_rate=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7072
    },
    "colab_type": "code",
    "id": "2ujx44Hku5dL",
    "outputId": "25b13ba9-1dc0-4ef9-b72b-2b97f66e5416"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 100\n",
      "learning_rate= 0.015\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.305\tAccuracy: 12.500\n",
      "Train step: 500\tLoss: 2.233\tAccuracy: 25.000\n",
      "Train step: 1000\tLoss: 2.184\tAccuracy: 37.500\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.085\tAccuracy: 34.375\n",
      "Train step: 2000\tLoss: 2.015\tAccuracy: 46.875\n",
      "Train step: 2500\tLoss: 1.998\tAccuracy: 46.875\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 2.179\tAccuracy: 25.000\n",
      "Train step: 3500\tLoss: 1.995\tAccuracy: 46.875\n",
      "Train step: 4000\tLoss: 2.101\tAccuracy: 37.500\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 1.898\tAccuracy: 56.250\n",
      "Train step: 5000\tLoss: 1.819\tAccuracy: 62.500\n",
      "Train step: 5500\tLoss: 2.010\tAccuracy: 43.750\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 1.966\tAccuracy: 50.000\n",
      "Train step: 6500\tLoss: 1.899\tAccuracy: 53.125\n",
      "Train step: 7000\tLoss: 1.776\tAccuracy: 68.750\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 1.869\tAccuracy: 59.375\n",
      "Train step: 8000\tLoss: 1.848\tAccuracy: 62.500\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.909\tAccuracy: 56.250\n",
      "Train step: 9000\tLoss: 1.832\tAccuracy: 65.625\n",
      "Train step: 9500\tLoss: 1.849\tAccuracy: 59.375\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 2.046\tAccuracy: 40.625\n",
      "Train step: 10500\tLoss: 1.863\tAccuracy: 62.500\n",
      "Train step: 11000\tLoss: 1.831\tAccuracy: 68.750\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.781\tAccuracy: 71.875\n",
      "Train step: 12000\tLoss: 1.999\tAccuracy: 46.875\n",
      "Train step: 12500\tLoss: 1.910\tAccuracy: 56.250\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 1.863\tAccuracy: 59.375\n",
      "Train step: 13500\tLoss: 1.806\tAccuracy: 62.500\n",
      "Train step: 14000\tLoss: 1.911\tAccuracy: 59.375\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.793\tAccuracy: 68.750\n",
      "Train step: 15000\tLoss: 1.773\tAccuracy: 71.875\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.911\tAccuracy: 56.250\n",
      "Train step: 16000\tLoss: 1.833\tAccuracy: 59.375\n",
      "Train step: 16500\tLoss: 1.796\tAccuracy: 65.625\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.811\tAccuracy: 65.625\n",
      "Train step: 17500\tLoss: 1.967\tAccuracy: 53.125\n",
      "Train step: 18000\tLoss: 1.741\tAccuracy: 71.875\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.717\tAccuracy: 75.000\n",
      "Train step: 19000\tLoss: 1.790\tAccuracy: 68.750\n",
      "Train step: 19500\tLoss: 1.868\tAccuracy: 62.500\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.797\tAccuracy: 68.750\n",
      "Train step: 20500\tLoss: 1.792\tAccuracy: 68.750\n",
      "Train step: 21000\tLoss: 1.758\tAccuracy: 71.875\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.914\tAccuracy: 59.375\n",
      "Train step: 22000\tLoss: 1.930\tAccuracy: 50.000\n",
      "Train step: 22500\tLoss: 1.743\tAccuracy: 71.875\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.956\tAccuracy: 50.000\n",
      "Train step: 23500\tLoss: 1.836\tAccuracy: 62.500\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.836\tAccuracy: 65.625\n",
      "Train step: 24500\tLoss: 1.708\tAccuracy: 78.125\n",
      "Train step: 25000\tLoss: 1.924\tAccuracy: 50.000\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.832\tAccuracy: 62.500\n",
      "Train step: 26000\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 26500\tLoss: 1.895\tAccuracy: 53.125\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.779\tAccuracy: 71.875\n",
      "Train step: 27500\tLoss: 1.752\tAccuracy: 71.875\n",
      "Train step: 28000\tLoss: 1.956\tAccuracy: 46.875\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.688\tAccuracy: 81.250\n",
      "Train step: 29000\tLoss: 1.677\tAccuracy: 78.125\n",
      "Train step: 29500\tLoss: 1.808\tAccuracy: 65.625\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.784\tAccuracy: 68.750\n",
      "Train step: 30500\tLoss: 1.755\tAccuracy: 71.875\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.818\tAccuracy: 65.625\n",
      "Train step: 31500\tLoss: 1.724\tAccuracy: 75.000\n",
      "Train step: 32000\tLoss: 1.705\tAccuracy: 78.125\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.715\tAccuracy: 75.000\n",
      "Train step: 33000\tLoss: 1.694\tAccuracy: 78.125\n",
      "Train step: 33500\tLoss: 1.724\tAccuracy: 71.875\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.733\tAccuracy: 71.875\n",
      "Train step: 34500\tLoss: 1.763\tAccuracy: 71.875\n",
      "Train step: 35000\tLoss: 1.716\tAccuracy: 75.000\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.838\tAccuracy: 62.500\n",
      "Train step: 36000\tLoss: 1.742\tAccuracy: 71.875\n",
      "Train step: 36500\tLoss: 1.730\tAccuracy: 71.875\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.738\tAccuracy: 75.000\n",
      "Train step: 37500\tLoss: 1.751\tAccuracy: 71.875\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.818\tAccuracy: 62.500\n",
      "Train step: 38500\tLoss: 1.785\tAccuracy: 68.750\n",
      "Train step: 39000\tLoss: 1.797\tAccuracy: 68.750\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.819\tAccuracy: 68.750\n",
      "Train step: 40000\tLoss: 1.660\tAccuracy: 81.250\n",
      "Train step: 40500\tLoss: 1.745\tAccuracy: 71.875\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.716\tAccuracy: 71.875\n",
      "Train step: 41500\tLoss: 1.672\tAccuracy: 84.375\n",
      "Train step: 42000\tLoss: 1.748\tAccuracy: 68.750\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.661\tAccuracy: 81.250\n",
      "Train step: 43000\tLoss: 1.736\tAccuracy: 71.875\n",
      "Train step: 43500\tLoss: 1.657\tAccuracy: 81.250\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.643\tAccuracy: 81.250\n",
      "Train step: 44500\tLoss: 1.733\tAccuracy: 71.875\n",
      "Train step: 45000\tLoss: 1.650\tAccuracy: 81.250\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.746\tAccuracy: 68.750\n",
      "Train step: 46000\tLoss: 1.751\tAccuracy: 68.750\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.643\tAccuracy: 84.375\n",
      "Train step: 47000\tLoss: 1.747\tAccuracy: 68.750\n",
      "Train step: 47500\tLoss: 1.661\tAccuracy: 84.375\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.697\tAccuracy: 71.875\n",
      "Train step: 48500\tLoss: 1.665\tAccuracy: 81.250\n",
      "Train step: 49000\tLoss: 1.685\tAccuracy: 75.000\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.669\tAccuracy: 84.375\n",
      "Train step: 50000\tLoss: 1.728\tAccuracy: 78.125\n",
      "Train step: 50500\tLoss: 1.699\tAccuracy: 78.125\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.706\tAccuracy: 75.000\n",
      "Train step: 51500\tLoss: 1.665\tAccuracy: 81.250\n",
      "Train step: 52000\tLoss: 1.721\tAccuracy: 71.875\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.630\tAccuracy: 84.375\n",
      "Train step: 53000\tLoss: 1.700\tAccuracy: 78.125\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.693\tAccuracy: 78.125\n",
      "Train step: 54000\tLoss: 1.724\tAccuracy: 71.875\n",
      "Train step: 54500\tLoss: 1.639\tAccuracy: 84.375\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.769\tAccuracy: 68.750\n",
      "Train step: 55500\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 56000\tLoss: 1.690\tAccuracy: 78.125\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.736\tAccuracy: 71.875\n",
      "Train step: 57000\tLoss: 1.683\tAccuracy: 81.250\n",
      "Train step: 57500\tLoss: 1.808\tAccuracy: 65.625\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.715\tAccuracy: 75.000\n",
      "Train step: 58500\tLoss: 1.612\tAccuracy: 87.500\n",
      "Train step: 59000\tLoss: 1.847\tAccuracy: 62.500\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.724\tAccuracy: 75.000\n",
      "Train step: 60000\tLoss: 1.629\tAccuracy: 84.375\n",
      "Train step: 60500\tLoss: 1.648\tAccuracy: 21.875\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.649\tAccuracy: 84.375\n",
      "Train step: 61500\tLoss: 1.539\tAccuracy: 93.750\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.732\tAccuracy: 71.875\n",
      "Train step: 62500\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 63000\tLoss: 1.745\tAccuracy: 78.125\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Train step: 64000\tLoss: 1.689\tAccuracy: 78.125\n",
      "Train step: 64500\tLoss: 1.761\tAccuracy: 68.750\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.627\tAccuracy: 84.375\n",
      "Train step: 65500\tLoss: 1.904\tAccuracy: 59.375\n",
      "Train step: 66000\tLoss: 1.721\tAccuracy: 78.125\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.780\tAccuracy: 65.625\n",
      "Train step: 67000\tLoss: 1.724\tAccuracy: 71.875\n",
      "Train step: 67500\tLoss: 1.742\tAccuracy: 75.000\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.675\tAccuracy: 78.125\n",
      "Train step: 68500\tLoss: 1.731\tAccuracy: 75.000\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.617\tAccuracy: 84.375\n",
      "Train step: 69500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Train step: 70000\tLoss: 1.663\tAccuracy: 78.125\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.745\tAccuracy: 75.000\n",
      "Train step: 71000\tLoss: 1.729\tAccuracy: 71.875\n",
      "Train step: 71500\tLoss: 1.695\tAccuracy: 78.125\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 1.750\tAccuracy: 65.625\n",
      "Train step: 72500\tLoss: 1.654\tAccuracy: 81.250\n",
      "Train step: 73000\tLoss: 1.742\tAccuracy: 71.875\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.781\tAccuracy: 68.750\n",
      "Train step: 74000\tLoss: 1.821\tAccuracy: 62.500\n",
      "Train step: 74500\tLoss: 1.760\tAccuracy: 68.750\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.856\tAccuracy: 62.500\n",
      "Train step: 75500\tLoss: 1.787\tAccuracy: 65.625\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.719\tAccuracy: 78.125\n",
      "Train step: 76500\tLoss: 1.617\tAccuracy: 87.500\n",
      "Train step: 77000\tLoss: 1.777\tAccuracy: 68.750\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.660\tAccuracy: 81.250\n",
      "Train step: 78000\tLoss: 1.530\tAccuracy: 96.875\n",
      "Train step: 78500\tLoss: 1.798\tAccuracy: 65.625\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.711\tAccuracy: 78.125\n",
      "Train step: 79500\tLoss: 1.747\tAccuracy: 75.000\n",
      "Train step: 80000\tLoss: 1.715\tAccuracy: 75.000\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.645\tAccuracy: 87.500\n",
      "Train step: 81000\tLoss: 1.572\tAccuracy: 93.750\n",
      "Train step: 81500\tLoss: 1.741\tAccuracy: 75.000\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.680\tAccuracy: 78.125\n",
      "Train step: 82500\tLoss: 1.729\tAccuracy: 71.875\n",
      "Train step: 83000\tLoss: 1.709\tAccuracy: 75.000\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.745\tAccuracy: 71.875\n",
      "Train step: 84000\tLoss: 1.728\tAccuracy: 75.000\n",
      "Current Epoch: 60/n\n",
      "Train step: 84500\tLoss: 1.644\tAccuracy: 87.500\n",
      "Train step: 85000\tLoss: 1.604\tAccuracy: 87.500\n",
      "Train step: 85500\tLoss: 1.603\tAccuracy: 90.625\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.736\tAccuracy: 71.875\n",
      "Train step: 86500\tLoss: 1.795\tAccuracy: 68.750\n",
      "Train step: 87000\tLoss: 1.620\tAccuracy: 84.375\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.624\tAccuracy: 84.375\n",
      "Train step: 88000\tLoss: 1.857\tAccuracy: 65.625\n",
      "Train step: 88500\tLoss: 1.649\tAccuracy: 81.250\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.728\tAccuracy: 75.000\n",
      "Train step: 89500\tLoss: 1.615\tAccuracy: 84.375\n",
      "Train step: 90000\tLoss: 1.684\tAccuracy: 78.125\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.712\tAccuracy: 75.000\n",
      "Train step: 91000\tLoss: 1.724\tAccuracy: 75.000\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 1.671\tAccuracy: 78.125\n",
      "Train step: 92000\tLoss: 1.606\tAccuracy: 87.500\n",
      "Train step: 92500\tLoss: 1.673\tAccuracy: 78.125\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.706\tAccuracy: 75.000\n",
      "Train step: 93500\tLoss: 1.703\tAccuracy: 78.125\n",
      "Train step: 94000\tLoss: 1.734\tAccuracy: 75.000\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.712\tAccuracy: 71.875\n",
      "Train step: 95000\tLoss: 1.717\tAccuracy: 75.000\n",
      "Train step: 95500\tLoss: 1.720\tAccuracy: 71.875\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.606\tAccuracy: 90.625\n",
      "Train step: 96500\tLoss: 1.743\tAccuracy: 71.875\n",
      "Train step: 97000\tLoss: 1.680\tAccuracy: 78.125\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.750\tAccuracy: 68.750\n",
      "Train step: 98000\tLoss: 1.614\tAccuracy: 87.500\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.678\tAccuracy: 81.250\n",
      "Train step: 99000\tLoss: 1.620\tAccuracy: 87.500\n",
      "Train step: 99500\tLoss: 1.630\tAccuracy: 84.375\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.701\tAccuracy: 75.000\n",
      "Train step: 100500\tLoss: 1.758\tAccuracy: 68.750\n",
      "Train step: 101000\tLoss: 1.773\tAccuracy: 71.875\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.675\tAccuracy: 78.125\n",
      "Train step: 102000\tLoss: 1.669\tAccuracy: 81.250\n",
      "Train step: 102500\tLoss: 1.711\tAccuracy: 75.000\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 1.723\tAccuracy: 75.000\n",
      "Train step: 103500\tLoss: 1.613\tAccuracy: 87.500\n",
      "Train step: 104000\tLoss: 1.642\tAccuracy: 84.375\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.676\tAccuracy: 78.125\n",
      "Train step: 105000\tLoss: 1.688\tAccuracy: 81.250\n",
      "Train step: 105500\tLoss: 1.647\tAccuracy: 81.250\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.655\tAccuracy: 84.375\n",
      "Train step: 106500\tLoss: 1.698\tAccuracy: 75.000\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.703\tAccuracy: 78.125\n",
      "Train step: 107500\tLoss: 1.654\tAccuracy: 81.250\n",
      "Train step: 108000\tLoss: 1.706\tAccuracy: 75.000\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 1.688\tAccuracy: 78.125\n",
      "Train step: 109000\tLoss: 1.636\tAccuracy: 81.250\n",
      "Train step: 109500\tLoss: 1.701\tAccuracy: 78.125\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.718\tAccuracy: 78.125\n",
      "Train step: 110500\tLoss: 1.609\tAccuracy: 87.500\n",
      "Train step: 111000\tLoss: 1.763\tAccuracy: 71.875\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.698\tAccuracy: 75.000\n",
      "Train step: 112000\tLoss: 1.723\tAccuracy: 68.750\n",
      "Train step: 112500\tLoss: 1.649\tAccuracy: 81.250\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.711\tAccuracy: 78.125\n",
      "Train step: 113500\tLoss: 1.765\tAccuracy: 68.750\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.523\tAccuracy: 93.750\n",
      "Train step: 114500\tLoss: 1.674\tAccuracy: 81.250\n",
      "Train step: 115000\tLoss: 1.712\tAccuracy: 75.000\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.646\tAccuracy: 84.375\n",
      "Train step: 116000\tLoss: 1.594\tAccuracy: 90.625\n",
      "Train step: 116500\tLoss: 1.711\tAccuracy: 71.875\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.605\tAccuracy: 87.500\n",
      "Train step: 117500\tLoss: 1.681\tAccuracy: 78.125\n",
      "Train step: 118000\tLoss: 1.599\tAccuracy: 87.500\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.740\tAccuracy: 71.875\n",
      "Train step: 119000\tLoss: 1.583\tAccuracy: 90.625\n",
      "Train step: 119500\tLoss: 1.763\tAccuracy: 68.750\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.615\tAccuracy: 84.375\n",
      "Train step: 120500\tLoss: 1.734\tAccuracy: 75.000\n",
      "Train step: 121000\tLoss: 1.682\tAccuracy: 81.250\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.667\tAccuracy: 84.375\n",
      "Train step: 122000\tLoss: 1.693\tAccuracy: 81.250\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.708\tAccuracy: 78.125\n",
      "Train step: 123000\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 123500\tLoss: 1.704\tAccuracy: 81.250\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.664\tAccuracy: 81.250\n",
      "Train step: 124500\tLoss: 1.643\tAccuracy: 84.375\n",
      "Train step: 125000\tLoss: 1.645\tAccuracy: 84.375\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.704\tAccuracy: 75.000\n",
      "Train step: 126000\tLoss: 1.701\tAccuracy: 78.125\n",
      "Train step: 126500\tLoss: 1.675\tAccuracy: 81.250\n",
      "Current Epoch: 90/n\n",
      "Train step: 127000\tLoss: 1.634\tAccuracy: 84.375\n",
      "Train step: 127500\tLoss: 1.684\tAccuracy: 78.125\n",
      "Train step: 128000\tLoss: 1.738\tAccuracy: 75.000\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.768\tAccuracy: 71.875\n",
      "Train step: 129000\tLoss: 1.616\tAccuracy: 87.500\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.661\tAccuracy: 81.250\n",
      "Train step: 130000\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 130500\tLoss: 1.649\tAccuracy: 81.250\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.663\tAccuracy: 87.500\n",
      "Train step: 131500\tLoss: 1.745\tAccuracy: 75.000\n",
      "Train step: 132000\tLoss: 1.613\tAccuracy: 87.500\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.648\tAccuracy: 84.375\n",
      "Train step: 133000\tLoss: 1.773\tAccuracy: 68.750\n",
      "Train step: 133500\tLoss: 1.643\tAccuracy: 84.375\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.574\tAccuracy: 90.625\n",
      "Train step: 134500\tLoss: 1.607\tAccuracy: 90.625\n",
      "Train step: 135000\tLoss: 1.691\tAccuracy: 78.125\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Train step: 136000\tLoss: 1.664\tAccuracy: 81.250\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.623\tAccuracy: 84.375\n",
      "Train step: 137000\tLoss: 1.748\tAccuracy: 71.875\n",
      "Train step: 137500\tLoss: 1.794\tAccuracy: 65.625\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.716\tAccuracy: 78.125\n",
      "Train step: 138500\tLoss: 1.611\tAccuracy: 87.500\n",
      "Train step: 139000\tLoss: 1.716\tAccuracy: 75.000\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.803\tAccuracy: 65.625\n",
      "Train step: 140000\tLoss: 1.714\tAccuracy: 75.000\n",
      "Train step: 140500\tLoss: 1.766\tAccuracy: 71.875\n",
      "Training finished, took 1840.83s\n"
     ]
    }
   ],
   "source": [
    "CNN7 = CNN()\n",
    "trainNet(CNN7, batch_size=32, n_epochs=100, learning_rate=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8454
    },
    "colab_type": "code",
    "id": "gp6jUrhzlfn6",
    "outputId": "5b594e81-f490-4121-8f3c-083f56b40270"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 120\n",
      "learning_rate= 0.01\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.305\tAccuracy: 6.250\n",
      "Train step: 500\tLoss: 2.283\tAccuracy: 6.250\n",
      "Train step: 1000\tLoss: 2.203\tAccuracy: 34.375\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.179\tAccuracy: 40.625\n",
      "Train step: 2000\tLoss: 2.116\tAccuracy: 40.625\n",
      "Train step: 2500\tLoss: 2.096\tAccuracy: 43.750\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 1.992\tAccuracy: 46.875\n",
      "Train step: 3500\tLoss: 2.095\tAccuracy: 34.375\n",
      "Train step: 4000\tLoss: 1.931\tAccuracy: 59.375\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 2.030\tAccuracy: 50.000\n",
      "Train step: 5000\tLoss: 2.018\tAccuracy: 43.750\n",
      "Train step: 5500\tLoss: 2.002\tAccuracy: 43.750\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 2.015\tAccuracy: 46.875\n",
      "Train step: 6500\tLoss: 1.955\tAccuracy: 50.000\n",
      "Train step: 7000\tLoss: 1.845\tAccuracy: 62.500\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 2.004\tAccuracy: 50.000\n",
      "Train step: 8000\tLoss: 1.954\tAccuracy: 53.125\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.779\tAccuracy: 71.875\n",
      "Train step: 9000\tLoss: 1.921\tAccuracy: 56.250\n",
      "Train step: 9500\tLoss: 1.945\tAccuracy: 50.000\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 2.036\tAccuracy: 46.875\n",
      "Train step: 10500\tLoss: 1.884\tAccuracy: 62.500\n",
      "Train step: 11000\tLoss: 1.890\tAccuracy: 56.250\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.856\tAccuracy: 59.375\n",
      "Train step: 12000\tLoss: 1.857\tAccuracy: 62.500\n",
      "Train step: 12500\tLoss: 1.841\tAccuracy: 59.375\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 1.950\tAccuracy: 53.125\n",
      "Train step: 13500\tLoss: 1.928\tAccuracy: 53.125\n",
      "Train step: 14000\tLoss: 1.860\tAccuracy: 65.625\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.900\tAccuracy: 59.375\n",
      "Train step: 15000\tLoss: 1.786\tAccuracy: 68.750\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.848\tAccuracy: 65.625\n",
      "Train step: 16000\tLoss: 1.862\tAccuracy: 62.500\n",
      "Train step: 16500\tLoss: 1.850\tAccuracy: 62.500\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.860\tAccuracy: 62.500\n",
      "Train step: 17500\tLoss: 1.895\tAccuracy: 56.250\n",
      "Train step: 18000\tLoss: 1.766\tAccuracy: 68.750\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.885\tAccuracy: 59.375\n",
      "Train step: 19000\tLoss: 1.747\tAccuracy: 75.000\n",
      "Train step: 19500\tLoss: 1.884\tAccuracy: 59.375\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.746\tAccuracy: 68.750\n",
      "Train step: 20500\tLoss: 1.815\tAccuracy: 65.625\n",
      "Train step: 21000\tLoss: 1.847\tAccuracy: 62.500\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.750\tAccuracy: 75.000\n",
      "Train step: 22000\tLoss: 1.934\tAccuracy: 53.125\n",
      "Train step: 22500\tLoss: 1.818\tAccuracy: 62.500\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.787\tAccuracy: 65.625\n",
      "Train step: 23500\tLoss: 1.914\tAccuracy: 53.125\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.820\tAccuracy: 65.625\n",
      "Train step: 24500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Train step: 25000\tLoss: 1.798\tAccuracy: 68.750\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.716\tAccuracy: 75.000\n",
      "Train step: 26000\tLoss: 1.747\tAccuracy: 71.875\n",
      "Train step: 26500\tLoss: 1.705\tAccuracy: 75.000\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.723\tAccuracy: 75.000\n",
      "Train step: 27500\tLoss: 1.605\tAccuracy: 87.500\n",
      "Train step: 28000\tLoss: 1.812\tAccuracy: 62.500\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.984\tAccuracy: 50.000\n",
      "Train step: 29000\tLoss: 1.791\tAccuracy: 65.625\n",
      "Train step: 29500\tLoss: 1.728\tAccuracy: 75.000\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.757\tAccuracy: 71.875\n",
      "Train step: 30500\tLoss: 1.755\tAccuracy: 75.000\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.649\tAccuracy: 84.375\n",
      "Train step: 31500\tLoss: 1.803\tAccuracy: 62.500\n",
      "Train step: 32000\tLoss: 1.828\tAccuracy: 65.625\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.704\tAccuracy: 78.125\n",
      "Train step: 33000\tLoss: 1.702\tAccuracy: 78.125\n",
      "Train step: 33500\tLoss: 1.705\tAccuracy: 75.000\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.735\tAccuracy: 75.000\n",
      "Train step: 34500\tLoss: 1.581\tAccuracy: 93.750\n",
      "Train step: 35000\tLoss: 1.760\tAccuracy: 71.875\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Train step: 36000\tLoss: 1.672\tAccuracy: 78.125\n",
      "Train step: 36500\tLoss: 1.821\tAccuracy: 65.625\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.873\tAccuracy: 56.250\n",
      "Train step: 37500\tLoss: 1.777\tAccuracy: 71.875\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.641\tAccuracy: 84.375\n",
      "Train step: 38500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Train step: 39000\tLoss: 1.815\tAccuracy: 62.500\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.838\tAccuracy: 62.500\n",
      "Train step: 40000\tLoss: 1.742\tAccuracy: 75.000\n",
      "Train step: 40500\tLoss: 1.747\tAccuracy: 71.875\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.693\tAccuracy: 81.250\n",
      "Train step: 41500\tLoss: 1.812\tAccuracy: 62.500\n",
      "Train step: 42000\tLoss: 1.702\tAccuracy: 78.125\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 43000\tLoss: 1.821\tAccuracy: 65.625\n",
      "Train step: 43500\tLoss: 1.861\tAccuracy: 59.375\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.699\tAccuracy: 78.125\n",
      "Train step: 44500\tLoss: 1.746\tAccuracy: 71.875\n",
      "Train step: 45000\tLoss: 1.713\tAccuracy: 81.250\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.711\tAccuracy: 75.000\n",
      "Train step: 46000\tLoss: 1.901\tAccuracy: 56.250\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.788\tAccuracy: 68.750\n",
      "Train step: 47000\tLoss: 1.747\tAccuracy: 75.000\n",
      "Train step: 47500\tLoss: 1.660\tAccuracy: 78.125\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.813\tAccuracy: 68.750\n",
      "Train step: 48500\tLoss: 1.810\tAccuracy: 68.750\n",
      "Train step: 49000\tLoss: 1.665\tAccuracy: 81.250\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.713\tAccuracy: 78.125\n",
      "Train step: 50000\tLoss: 1.767\tAccuracy: 68.750\n",
      "Train step: 50500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.666\tAccuracy: 84.375\n",
      "Train step: 51500\tLoss: 1.625\tAccuracy: 84.375\n",
      "Train step: 52000\tLoss: 1.713\tAccuracy: 75.000\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.669\tAccuracy: 81.250\n",
      "Train step: 53000\tLoss: 1.748\tAccuracy: 71.875\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.743\tAccuracy: 71.875\n",
      "Train step: 54000\tLoss: 1.634\tAccuracy: 90.625\n",
      "Train step: 54500\tLoss: 1.546\tAccuracy: 93.750\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.605\tAccuracy: 90.625\n",
      "Train step: 55500\tLoss: 1.730\tAccuracy: 75.000\n",
      "Train step: 56000\tLoss: 1.729\tAccuracy: 75.000\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.680\tAccuracy: 78.125\n",
      "Train step: 57000\tLoss: 1.718\tAccuracy: 75.000\n",
      "Train step: 57500\tLoss: 1.682\tAccuracy: 78.125\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.797\tAccuracy: 65.625\n",
      "Train step: 58500\tLoss: 1.598\tAccuracy: 87.500\n",
      "Train step: 59000\tLoss: 1.614\tAccuracy: 87.500\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.713\tAccuracy: 78.125\n",
      "Train step: 60000\tLoss: 1.645\tAccuracy: 84.375\n",
      "Train step: 60500\tLoss: 1.739\tAccuracy: 18.750\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.909\tAccuracy: 56.250\n",
      "Train step: 61500\tLoss: 1.758\tAccuracy: 71.875\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.784\tAccuracy: 65.625\n",
      "Train step: 62500\tLoss: 1.715\tAccuracy: 75.000\n",
      "Train step: 63000\tLoss: 1.801\tAccuracy: 65.625\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.598\tAccuracy: 90.625\n",
      "Train step: 64000\tLoss: 1.724\tAccuracy: 75.000\n",
      "Train step: 64500\tLoss: 1.852\tAccuracy: 56.250\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.849\tAccuracy: 59.375\n",
      "Train step: 65500\tLoss: 1.639\tAccuracy: 87.500\n",
      "Train step: 66000\tLoss: 1.645\tAccuracy: 81.250\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.718\tAccuracy: 75.000\n",
      "Train step: 67000\tLoss: 1.692\tAccuracy: 81.250\n",
      "Train step: 67500\tLoss: 1.651\tAccuracy: 81.250\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.614\tAccuracy: 87.500\n",
      "Train step: 68500\tLoss: 1.622\tAccuracy: 84.375\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.602\tAccuracy: 87.500\n",
      "Train step: 69500\tLoss: 1.771\tAccuracy: 71.875\n",
      "Train step: 70000\tLoss: 1.761\tAccuracy: 68.750\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.622\tAccuracy: 87.500\n",
      "Train step: 71000\tLoss: 1.706\tAccuracy: 78.125\n",
      "Train step: 71500\tLoss: 1.604\tAccuracy: 87.500\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 1.653\tAccuracy: 84.375\n",
      "Train step: 72500\tLoss: 1.729\tAccuracy: 75.000\n",
      "Train step: 73000\tLoss: 1.760\tAccuracy: 71.875\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.601\tAccuracy: 87.500\n",
      "Train step: 74000\tLoss: 1.559\tAccuracy: 93.750\n",
      "Train step: 74500\tLoss: 1.765\tAccuracy: 71.875\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.716\tAccuracy: 75.000\n",
      "Train step: 75500\tLoss: 1.729\tAccuracy: 75.000\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.777\tAccuracy: 68.750\n",
      "Train step: 76500\tLoss: 1.660\tAccuracy: 81.250\n",
      "Train step: 77000\tLoss: 1.706\tAccuracy: 75.000\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.641\tAccuracy: 87.500\n",
      "Train step: 78000\tLoss: 1.769\tAccuracy: 71.875\n",
      "Train step: 78500\tLoss: 1.692\tAccuracy: 78.125\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.817\tAccuracy: 62.500\n",
      "Train step: 79500\tLoss: 1.648\tAccuracy: 84.375\n",
      "Train step: 80000\tLoss: 1.664\tAccuracy: 84.375\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.732\tAccuracy: 75.000\n",
      "Train step: 81000\tLoss: 1.749\tAccuracy: 71.875\n",
      "Train step: 81500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.580\tAccuracy: 87.500\n",
      "Train step: 82500\tLoss: 1.620\tAccuracy: 87.500\n",
      "Train step: 83000\tLoss: 1.639\tAccuracy: 84.375\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.635\tAccuracy: 84.375\n",
      "Train step: 84000\tLoss: 1.653\tAccuracy: 81.250\n",
      "Current Epoch: 60/n\n",
      "Train step: 84500\tLoss: 1.725\tAccuracy: 71.875\n",
      "Train step: 85000\tLoss: 1.663\tAccuracy: 81.250\n",
      "Train step: 85500\tLoss: 1.703\tAccuracy: 71.875\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.653\tAccuracy: 81.250\n",
      "Train step: 86500\tLoss: 1.727\tAccuracy: 75.000\n",
      "Train step: 87000\tLoss: 1.607\tAccuracy: 90.625\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.676\tAccuracy: 75.000\n",
      "Train step: 88000\tLoss: 1.618\tAccuracy: 84.375\n",
      "Train step: 88500\tLoss: 1.533\tAccuracy: 93.750\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.705\tAccuracy: 78.125\n",
      "Train step: 89500\tLoss: 1.758\tAccuracy: 75.000\n",
      "Train step: 90000\tLoss: 1.605\tAccuracy: 87.500\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.607\tAccuracy: 90.625\n",
      "Train step: 91000\tLoss: 1.769\tAccuracy: 68.750\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 1.923\tAccuracy: 53.125\n",
      "Train step: 92000\tLoss: 1.688\tAccuracy: 78.125\n",
      "Train step: 92500\tLoss: 1.777\tAccuracy: 68.750\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 93500\tLoss: 1.667\tAccuracy: 81.250\n",
      "Train step: 94000\tLoss: 1.703\tAccuracy: 78.125\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.726\tAccuracy: 75.000\n",
      "Train step: 95000\tLoss: 1.735\tAccuracy: 78.125\n",
      "Train step: 95500\tLoss: 1.652\tAccuracy: 84.375\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.691\tAccuracy: 81.250\n",
      "Train step: 96500\tLoss: 1.785\tAccuracy: 68.750\n",
      "Train step: 97000\tLoss: 1.509\tAccuracy: 96.875\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.722\tAccuracy: 71.875\n",
      "Train step: 98000\tLoss: 1.663\tAccuracy: 81.250\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.728\tAccuracy: 71.875\n",
      "Train step: 99000\tLoss: 1.761\tAccuracy: 75.000\n",
      "Train step: 99500\tLoss: 1.637\tAccuracy: 84.375\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.748\tAccuracy: 75.000\n",
      "Train step: 100500\tLoss: 1.753\tAccuracy: 75.000\n",
      "Train step: 101000\tLoss: 1.675\tAccuracy: 78.125\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.723\tAccuracy: 71.875\n",
      "Train step: 102000\tLoss: 1.717\tAccuracy: 75.000\n",
      "Train step: 102500\tLoss: 1.710\tAccuracy: 78.125\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 1.631\tAccuracy: 87.500\n",
      "Train step: 103500\tLoss: 1.682\tAccuracy: 78.125\n",
      "Train step: 104000\tLoss: 1.818\tAccuracy: 65.625\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.687\tAccuracy: 78.125\n",
      "Train step: 105000\tLoss: 1.688\tAccuracy: 84.375\n",
      "Train step: 105500\tLoss: 1.742\tAccuracy: 75.000\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.594\tAccuracy: 90.625\n",
      "Train step: 106500\tLoss: 1.682\tAccuracy: 81.250\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.753\tAccuracy: 68.750\n",
      "Train step: 107500\tLoss: 1.564\tAccuracy: 93.750\n",
      "Train step: 108000\tLoss: 1.807\tAccuracy: 68.750\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 109000\tLoss: 1.726\tAccuracy: 71.875\n",
      "Train step: 109500\tLoss: 1.758\tAccuracy: 68.750\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.750\tAccuracy: 75.000\n",
      "Train step: 110500\tLoss: 1.672\tAccuracy: 81.250\n",
      "Train step: 111000\tLoss: 1.655\tAccuracy: 81.250\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.812\tAccuracy: 65.625\n",
      "Train step: 112000\tLoss: 1.620\tAccuracy: 84.375\n",
      "Train step: 112500\tLoss: 1.716\tAccuracy: 78.125\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.704\tAccuracy: 78.125\n",
      "Train step: 113500\tLoss: 1.777\tAccuracy: 71.875\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.736\tAccuracy: 78.125\n",
      "Train step: 114500\tLoss: 1.738\tAccuracy: 71.875\n",
      "Train step: 115000\tLoss: 1.706\tAccuracy: 78.125\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.581\tAccuracy: 93.750\n",
      "Train step: 116000\tLoss: 1.651\tAccuracy: 84.375\n",
      "Train step: 116500\tLoss: 1.562\tAccuracy: 93.750\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.564\tAccuracy: 93.750\n",
      "Train step: 117500\tLoss: 1.661\tAccuracy: 81.250\n",
      "Train step: 118000\tLoss: 1.730\tAccuracy: 75.000\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Train step: 119000\tLoss: 1.689\tAccuracy: 81.250\n",
      "Train step: 119500\tLoss: 1.732\tAccuracy: 71.875\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.690\tAccuracy: 78.125\n",
      "Train step: 120500\tLoss: 1.647\tAccuracy: 84.375\n",
      "Train step: 121000\tLoss: 1.677\tAccuracy: 78.125\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.602\tAccuracy: 87.500\n",
      "Train step: 122000\tLoss: 1.706\tAccuracy: 75.000\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.777\tAccuracy: 68.750\n",
      "Train step: 123000\tLoss: 1.737\tAccuracy: 75.000\n",
      "Train step: 123500\tLoss: 1.686\tAccuracy: 78.125\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.696\tAccuracy: 78.125\n",
      "Train step: 124500\tLoss: 1.694\tAccuracy: 78.125\n",
      "Train step: 125000\tLoss: 1.598\tAccuracy: 90.625\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.720\tAccuracy: 78.125\n",
      "Train step: 126000\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 126500\tLoss: 1.695\tAccuracy: 78.125\n",
      "Current Epoch: 90/n\n",
      "Train step: 127000\tLoss: 1.733\tAccuracy: 78.125\n",
      "Train step: 127500\tLoss: 1.787\tAccuracy: 71.875\n",
      "Train step: 128000\tLoss: 1.775\tAccuracy: 68.750\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.771\tAccuracy: 68.750\n",
      "Train step: 129000\tLoss: 1.683\tAccuracy: 78.125\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.697\tAccuracy: 81.250\n",
      "Train step: 130000\tLoss: 1.648\tAccuracy: 84.375\n",
      "Train step: 130500\tLoss: 1.562\tAccuracy: 93.750\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.764\tAccuracy: 68.750\n",
      "Train step: 131500\tLoss: 1.762\tAccuracy: 71.875\n",
      "Train step: 132000\tLoss: 1.727\tAccuracy: 75.000\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.744\tAccuracy: 75.000\n",
      "Train step: 133000\tLoss: 1.601\tAccuracy: 87.500\n",
      "Train step: 133500\tLoss: 1.675\tAccuracy: 78.125\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.695\tAccuracy: 78.125\n",
      "Train step: 134500\tLoss: 1.673\tAccuracy: 81.250\n",
      "Train step: 135000\tLoss: 1.802\tAccuracy: 65.625\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.732\tAccuracy: 75.000\n",
      "Train step: 136000\tLoss: 1.879\tAccuracy: 53.125\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.653\tAccuracy: 78.125\n",
      "Train step: 137000\tLoss: 1.557\tAccuracy: 93.750\n",
      "Train step: 137500\tLoss: 1.800\tAccuracy: 65.625\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.679\tAccuracy: 81.250\n",
      "Train step: 138500\tLoss: 1.726\tAccuracy: 75.000\n",
      "Train step: 139000\tLoss: 1.692\tAccuracy: 78.125\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.822\tAccuracy: 65.625\n",
      "Train step: 140000\tLoss: 1.700\tAccuracy: 78.125\n",
      "Train step: 140500\tLoss: 1.660\tAccuracy: 81.250\n",
      "Current Epoch: 100/n\n",
      "Train step: 141000\tLoss: 1.688\tAccuracy: 81.250\n",
      "Train step: 141500\tLoss: 1.656\tAccuracy: 81.250\n",
      "Train step: 142000\tLoss: 1.761\tAccuracy: 71.875\n",
      "Current Epoch: 101/n\n",
      "Train step: 142500\tLoss: 1.754\tAccuracy: 71.875\n",
      "Train step: 143000\tLoss: 1.617\tAccuracy: 84.375\n",
      "Train step: 143500\tLoss: 1.831\tAccuracy: 65.625\n",
      "Current Epoch: 102/n\n",
      "Train step: 144000\tLoss: 1.690\tAccuracy: 78.125\n",
      "Train step: 144500\tLoss: 1.599\tAccuracy: 87.500\n",
      "Current Epoch: 103/n\n",
      "Train step: 145000\tLoss: 1.570\tAccuracy: 87.500\n",
      "Train step: 145500\tLoss: 1.710\tAccuracy: 75.000\n",
      "Train step: 146000\tLoss: 1.641\tAccuracy: 87.500\n",
      "Current Epoch: 104/n\n",
      "Train step: 146500\tLoss: 1.637\tAccuracy: 84.375\n",
      "Train step: 147000\tLoss: 1.642\tAccuracy: 84.375\n",
      "Train step: 147500\tLoss: 1.715\tAccuracy: 75.000\n",
      "Current Epoch: 105/n\n",
      "Train step: 148000\tLoss: 1.712\tAccuracy: 75.000\n",
      "Train step: 148500\tLoss: 1.569\tAccuracy: 93.750\n",
      "Train step: 149000\tLoss: 1.608\tAccuracy: 87.500\n",
      "Current Epoch: 106/n\n",
      "Train step: 149500\tLoss: 1.689\tAccuracy: 78.125\n",
      "Train step: 150000\tLoss: 1.686\tAccuracy: 84.375\n",
      "Train step: 150500\tLoss: 1.628\tAccuracy: 84.375\n",
      "Current Epoch: 107/n\n",
      "Train step: 151000\tLoss: 1.839\tAccuracy: 59.375\n",
      "Train step: 151500\tLoss: 1.607\tAccuracy: 87.500\n",
      "Current Epoch: 108/n\n",
      "Train step: 152000\tLoss: 1.670\tAccuracy: 78.125\n",
      "Train step: 152500\tLoss: 1.644\tAccuracy: 81.250\n",
      "Train step: 153000\tLoss: 1.641\tAccuracy: 84.375\n",
      "Current Epoch: 109/n\n",
      "Train step: 153500\tLoss: 1.708\tAccuracy: 78.125\n",
      "Train step: 154000\tLoss: 1.599\tAccuracy: 87.500\n",
      "Train step: 154500\tLoss: 1.685\tAccuracy: 81.250\n",
      "Current Epoch: 110/n\n",
      "Train step: 155000\tLoss: 1.725\tAccuracy: 71.875\n",
      "Train step: 155500\tLoss: 1.693\tAccuracy: 78.125\n",
      "Train step: 156000\tLoss: 1.720\tAccuracy: 75.000\n",
      "Current Epoch: 111/n\n",
      "Train step: 156500\tLoss: 1.722\tAccuracy: 75.000\n",
      "Train step: 157000\tLoss: 1.704\tAccuracy: 78.125\n",
      "Train step: 157500\tLoss: 1.792\tAccuracy: 68.750\n",
      "Current Epoch: 112/n\n",
      "Train step: 158000\tLoss: 1.694\tAccuracy: 81.250\n",
      "Train step: 158500\tLoss: 1.752\tAccuracy: 71.875\n",
      "Current Epoch: 113/n\n",
      "Train step: 159000\tLoss: 1.571\tAccuracy: 90.625\n",
      "Train step: 159500\tLoss: 1.593\tAccuracy: 87.500\n",
      "Train step: 160000\tLoss: 1.619\tAccuracy: 84.375\n",
      "Current Epoch: 114/n\n",
      "Train step: 160500\tLoss: 1.730\tAccuracy: 75.000\n",
      "Train step: 161000\tLoss: 1.628\tAccuracy: 84.375\n",
      "Train step: 161500\tLoss: 1.690\tAccuracy: 78.125\n",
      "Current Epoch: 115/n\n",
      "Train step: 162000\tLoss: 1.658\tAccuracy: 78.125\n",
      "Train step: 162500\tLoss: 1.607\tAccuracy: 87.500\n",
      "Train step: 163000\tLoss: 1.728\tAccuracy: 75.000\n",
      "Current Epoch: 116/n\n",
      "Train step: 163500\tLoss: 1.663\tAccuracy: 81.250\n",
      "Train step: 164000\tLoss: 1.653\tAccuracy: 84.375\n",
      "Train step: 164500\tLoss: 1.737\tAccuracy: 71.875\n",
      "Current Epoch: 117/n\n",
      "Train step: 165000\tLoss: 1.813\tAccuracy: 65.625\n",
      "Train step: 165500\tLoss: 1.807\tAccuracy: 68.750\n",
      "Train step: 166000\tLoss: 1.658\tAccuracy: 81.250\n",
      "Current Epoch: 118/n\n",
      "Train step: 166500\tLoss: 1.784\tAccuracy: 65.625\n",
      "Train step: 167000\tLoss: 1.581\tAccuracy: 90.625\n",
      "Current Epoch: 119/n\n",
      "Train step: 167500\tLoss: 1.737\tAccuracy: 75.000\n",
      "Train step: 168000\tLoss: 1.692\tAccuracy: 84.375\n",
      "Train step: 168500\tLoss: 1.608\tAccuracy: 87.500\n",
      "Training finished, took 2190.00s\n"
     ]
    }
   ],
   "source": [
    "CNN6 = CNN()\n",
    "trainNet(CNN6, batch_size=32, n_epochs=120, learning_rate=0.010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7072
    },
    "colab_type": "code",
    "id": "ZYkuTxiOvt1G",
    "outputId": "90b9e2dc-1df6-4613-b1c3-5b0c61412c2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 100\n",
      "learning_rate= 0.03\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.305\tAccuracy: 3.125\n",
      "Train step: 500\tLoss: 2.218\tAccuracy: 18.750\n",
      "Train step: 1000\tLoss: 2.144\tAccuracy: 34.375\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 1.983\tAccuracy: 50.000\n",
      "Train step: 2000\tLoss: 2.049\tAccuracy: 46.875\n",
      "Train step: 2500\tLoss: 1.877\tAccuracy: 68.750\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 1.859\tAccuracy: 62.500\n",
      "Train step: 3500\tLoss: 1.984\tAccuracy: 46.875\n",
      "Train step: 4000\tLoss: 1.892\tAccuracy: 56.250\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 1.868\tAccuracy: 62.500\n",
      "Train step: 5000\tLoss: 1.913\tAccuracy: 59.375\n",
      "Train step: 5500\tLoss: 1.903\tAccuracy: 56.250\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 1.912\tAccuracy: 56.250\n",
      "Train step: 6500\tLoss: 1.874\tAccuracy: 59.375\n",
      "Train step: 7000\tLoss: 1.926\tAccuracy: 46.875\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 1.865\tAccuracy: 62.500\n",
      "Train step: 8000\tLoss: 1.855\tAccuracy: 65.625\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.910\tAccuracy: 53.125\n",
      "Train step: 9000\tLoss: 1.903\tAccuracy: 56.250\n",
      "Train step: 9500\tLoss: 1.820\tAccuracy: 68.750\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 1.700\tAccuracy: 81.250\n",
      "Train step: 10500\tLoss: 1.882\tAccuracy: 56.250\n",
      "Train step: 11000\tLoss: 1.840\tAccuracy: 65.625\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.837\tAccuracy: 62.500\n",
      "Train step: 12000\tLoss: 1.827\tAccuracy: 65.625\n",
      "Train step: 12500\tLoss: 1.833\tAccuracy: 62.500\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 1.789\tAccuracy: 68.750\n",
      "Train step: 13500\tLoss: 1.866\tAccuracy: 59.375\n",
      "Train step: 14000\tLoss: 1.877\tAccuracy: 56.250\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.772\tAccuracy: 71.875\n",
      "Train step: 15000\tLoss: 1.837\tAccuracy: 59.375\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.788\tAccuracy: 65.625\n",
      "Train step: 16000\tLoss: 1.742\tAccuracy: 68.750\n",
      "Train step: 16500\tLoss: 1.839\tAccuracy: 62.500\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.792\tAccuracy: 65.625\n",
      "Train step: 17500\tLoss: 1.869\tAccuracy: 59.375\n",
      "Train step: 18000\tLoss: 1.850\tAccuracy: 59.375\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.757\tAccuracy: 68.750\n",
      "Train step: 19000\tLoss: 1.901\tAccuracy: 53.125\n",
      "Train step: 19500\tLoss: 1.710\tAccuracy: 75.000\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.788\tAccuracy: 65.625\n",
      "Train step: 20500\tLoss: 1.861\tAccuracy: 65.625\n",
      "Train step: 21000\tLoss: 1.849\tAccuracy: 59.375\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.747\tAccuracy: 75.000\n",
      "Train step: 22000\tLoss: 1.785\tAccuracy: 65.625\n",
      "Train step: 22500\tLoss: 1.693\tAccuracy: 78.125\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.815\tAccuracy: 65.625\n",
      "Train step: 23500\tLoss: 1.812\tAccuracy: 68.750\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.799\tAccuracy: 65.625\n",
      "Train step: 24500\tLoss: 1.816\tAccuracy: 65.625\n",
      "Train step: 25000\tLoss: 1.905\tAccuracy: 53.125\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.749\tAccuracy: 68.750\n",
      "Train step: 26000\tLoss: 1.722\tAccuracy: 75.000\n",
      "Train step: 26500\tLoss: 1.771\tAccuracy: 68.750\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.696\tAccuracy: 78.125\n",
      "Train step: 27500\tLoss: 1.611\tAccuracy: 84.375\n",
      "Train step: 28000\tLoss: 1.731\tAccuracy: 71.875\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.702\tAccuracy: 75.000\n",
      "Train step: 29000\tLoss: 1.783\tAccuracy: 65.625\n",
      "Train step: 29500\tLoss: 1.804\tAccuracy: 68.750\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.730\tAccuracy: 75.000\n",
      "Train step: 30500\tLoss: 1.708\tAccuracy: 75.000\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.686\tAccuracy: 78.125\n",
      "Train step: 31500\tLoss: 1.740\tAccuracy: 75.000\n",
      "Train step: 32000\tLoss: 1.579\tAccuracy: 90.625\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.711\tAccuracy: 75.000\n",
      "Train step: 33000\tLoss: 1.642\tAccuracy: 84.375\n",
      "Train step: 33500\tLoss: 1.758\tAccuracy: 75.000\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.718\tAccuracy: 71.875\n",
      "Train step: 34500\tLoss: 1.766\tAccuracy: 68.750\n",
      "Train step: 35000\tLoss: 1.753\tAccuracy: 68.750\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.802\tAccuracy: 68.750\n",
      "Train step: 36000\tLoss: 1.667\tAccuracy: 78.125\n",
      "Train step: 36500\tLoss: 1.862\tAccuracy: 56.250\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.859\tAccuracy: 59.375\n",
      "Train step: 37500\tLoss: 1.734\tAccuracy: 71.875\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.651\tAccuracy: 81.250\n",
      "Train step: 38500\tLoss: 1.711\tAccuracy: 71.875\n",
      "Train step: 39000\tLoss: 1.727\tAccuracy: 71.875\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.825\tAccuracy: 62.500\n",
      "Train step: 40000\tLoss: 1.679\tAccuracy: 75.000\n",
      "Train step: 40500\tLoss: 1.706\tAccuracy: 75.000\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.584\tAccuracy: 87.500\n",
      "Train step: 41500\tLoss: 1.642\tAccuracy: 84.375\n",
      "Train step: 42000\tLoss: 1.716\tAccuracy: 75.000\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.599\tAccuracy: 87.500\n",
      "Train step: 43000\tLoss: 1.663\tAccuracy: 81.250\n",
      "Train step: 43500\tLoss: 1.772\tAccuracy: 68.750\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.597\tAccuracy: 87.500\n",
      "Train step: 44500\tLoss: 1.709\tAccuracy: 78.125\n",
      "Train step: 45000\tLoss: 1.759\tAccuracy: 71.875\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.644\tAccuracy: 81.250\n",
      "Train step: 46000\tLoss: 1.615\tAccuracy: 87.500\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.657\tAccuracy: 81.250\n",
      "Train step: 47000\tLoss: 1.669\tAccuracy: 78.125\n",
      "Train step: 47500\tLoss: 1.761\tAccuracy: 71.875\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.499\tAccuracy: 96.875\n",
      "Train step: 48500\tLoss: 1.703\tAccuracy: 75.000\n",
      "Train step: 49000\tLoss: 1.592\tAccuracy: 87.500\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.719\tAccuracy: 75.000\n",
      "Train step: 50000\tLoss: 1.554\tAccuracy: 93.750\n",
      "Train step: 50500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.657\tAccuracy: 81.250\n",
      "Train step: 51500\tLoss: 1.760\tAccuracy: 71.875\n",
      "Train step: 52000\tLoss: 1.621\tAccuracy: 84.375\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.536\tAccuracy: 93.750\n",
      "Train step: 53000\tLoss: 1.638\tAccuracy: 84.375\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.568\tAccuracy: 90.625\n",
      "Train step: 54000\tLoss: 1.665\tAccuracy: 81.250\n",
      "Train step: 54500\tLoss: 1.677\tAccuracy: 81.250\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.646\tAccuracy: 81.250\n",
      "Train step: 55500\tLoss: 1.701\tAccuracy: 78.125\n",
      "Train step: 56000\tLoss: 1.570\tAccuracy: 90.625\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.699\tAccuracy: 75.000\n",
      "Train step: 57000\tLoss: 1.715\tAccuracy: 75.000\n",
      "Train step: 57500\tLoss: 1.734\tAccuracy: 75.000\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.531\tAccuracy: 93.750\n",
      "Train step: 58500\tLoss: 1.599\tAccuracy: 87.500\n",
      "Train step: 59000\tLoss: 1.688\tAccuracy: 78.125\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.672\tAccuracy: 75.000\n",
      "Train step: 60000\tLoss: 1.590\tAccuracy: 90.625\n",
      "Train step: 60500\tLoss: 1.491\tAccuracy: 25.000\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.582\tAccuracy: 90.625\n",
      "Train step: 61500\tLoss: 1.568\tAccuracy: 90.625\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.623\tAccuracy: 84.375\n",
      "Train step: 62500\tLoss: 1.612\tAccuracy: 84.375\n",
      "Train step: 63000\tLoss: 1.665\tAccuracy: 81.250\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.623\tAccuracy: 84.375\n",
      "Train step: 64000\tLoss: 1.549\tAccuracy: 90.625\n",
      "Train step: 64500\tLoss: 1.642\tAccuracy: 81.250\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.698\tAccuracy: 78.125\n",
      "Train step: 65500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 66000\tLoss: 1.816\tAccuracy: 68.750\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.624\tAccuracy: 84.375\n",
      "Train step: 67000\tLoss: 1.761\tAccuracy: 71.875\n",
      "Train step: 67500\tLoss: 1.622\tAccuracy: 84.375\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.557\tAccuracy: 90.625\n",
      "Train step: 68500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.639\tAccuracy: 84.375\n",
      "Train step: 69500\tLoss: 1.738\tAccuracy: 75.000\n",
      "Train step: 70000\tLoss: 1.623\tAccuracy: 84.375\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.696\tAccuracy: 75.000\n",
      "Train step: 71000\tLoss: 1.527\tAccuracy: 93.750\n",
      "Train step: 71500\tLoss: 1.603\tAccuracy: 87.500\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 1.769\tAccuracy: 65.625\n",
      "Train step: 72500\tLoss: 1.590\tAccuracy: 90.625\n",
      "Train step: 73000\tLoss: 1.823\tAccuracy: 62.500\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.506\tAccuracy: 96.875\n",
      "Train step: 74000\tLoss: 1.757\tAccuracy: 71.875\n",
      "Train step: 74500\tLoss: 1.711\tAccuracy: 75.000\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.727\tAccuracy: 75.000\n",
      "Train step: 75500\tLoss: 1.742\tAccuracy: 68.750\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.637\tAccuracy: 84.375\n",
      "Train step: 76500\tLoss: 1.614\tAccuracy: 87.500\n",
      "Train step: 77000\tLoss: 1.655\tAccuracy: 84.375\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.673\tAccuracy: 78.125\n",
      "Train step: 78000\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 78500\tLoss: 1.627\tAccuracy: 84.375\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.692\tAccuracy: 71.875\n",
      "Train step: 79500\tLoss: 1.578\tAccuracy: 90.625\n",
      "Train step: 80000\tLoss: 1.619\tAccuracy: 87.500\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.565\tAccuracy: 87.500\n",
      "Train step: 81000\tLoss: 1.585\tAccuracy: 87.500\n",
      "Train step: 81500\tLoss: 1.563\tAccuracy: 90.625\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.752\tAccuracy: 71.875\n",
      "Train step: 82500\tLoss: 1.643\tAccuracy: 84.375\n",
      "Train step: 83000\tLoss: 1.746\tAccuracy: 71.875\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.769\tAccuracy: 68.750\n",
      "Train step: 84000\tLoss: 1.633\tAccuracy: 87.500\n",
      "Current Epoch: 60/n\n",
      "Train step: 84500\tLoss: 1.569\tAccuracy: 90.625\n",
      "Train step: 85000\tLoss: 1.579\tAccuracy: 90.625\n",
      "Train step: 85500\tLoss: 1.654\tAccuracy: 78.125\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.676\tAccuracy: 78.125\n",
      "Train step: 86500\tLoss: 1.583\tAccuracy: 90.625\n",
      "Train step: 87000\tLoss: 1.631\tAccuracy: 84.375\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 88000\tLoss: 1.658\tAccuracy: 81.250\n",
      "Train step: 88500\tLoss: 1.739\tAccuracy: 71.875\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.663\tAccuracy: 81.250\n",
      "Train step: 89500\tLoss: 1.514\tAccuracy: 93.750\n",
      "Train step: 90000\tLoss: 1.635\tAccuracy: 81.250\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.694\tAccuracy: 78.125\n",
      "Train step: 91000\tLoss: 1.644\tAccuracy: 81.250\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 1.693\tAccuracy: 78.125\n",
      "Train step: 92000\tLoss: 1.702\tAccuracy: 75.000\n",
      "Train step: 92500\tLoss: 1.615\tAccuracy: 87.500\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.619\tAccuracy: 84.375\n",
      "Train step: 93500\tLoss: 1.721\tAccuracy: 75.000\n",
      "Train step: 94000\tLoss: 1.687\tAccuracy: 75.000\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.664\tAccuracy: 78.125\n",
      "Train step: 95000\tLoss: 1.754\tAccuracy: 71.875\n",
      "Train step: 95500\tLoss: 1.657\tAccuracy: 87.500\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.608\tAccuracy: 84.375\n",
      "Train step: 96500\tLoss: 1.615\tAccuracy: 84.375\n",
      "Train step: 97000\tLoss: 1.564\tAccuracy: 90.625\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 98000\tLoss: 1.675\tAccuracy: 78.125\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.568\tAccuracy: 90.625\n",
      "Train step: 99000\tLoss: 1.694\tAccuracy: 78.125\n",
      "Train step: 99500\tLoss: 1.544\tAccuracy: 93.750\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.667\tAccuracy: 81.250\n",
      "Train step: 100500\tLoss: 1.668\tAccuracy: 81.250\n",
      "Train step: 101000\tLoss: 1.648\tAccuracy: 84.375\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.689\tAccuracy: 78.125\n",
      "Train step: 102000\tLoss: 1.585\tAccuracy: 87.500\n",
      "Train step: 102500\tLoss: 1.580\tAccuracy: 87.500\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 1.665\tAccuracy: 81.250\n",
      "Train step: 103500\tLoss: 1.647\tAccuracy: 81.250\n",
      "Train step: 104000\tLoss: 1.583\tAccuracy: 87.500\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.617\tAccuracy: 87.500\n",
      "Train step: 105000\tLoss: 1.656\tAccuracy: 81.250\n",
      "Train step: 105500\tLoss: 1.669\tAccuracy: 78.125\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.731\tAccuracy: 75.000\n",
      "Train step: 106500\tLoss: 1.606\tAccuracy: 84.375\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.603\tAccuracy: 84.375\n",
      "Train step: 107500\tLoss: 1.673\tAccuracy: 81.250\n",
      "Train step: 108000\tLoss: 1.595\tAccuracy: 87.500\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 1.651\tAccuracy: 81.250\n",
      "Train step: 109000\tLoss: 1.590\tAccuracy: 87.500\n",
      "Train step: 109500\tLoss: 1.639\tAccuracy: 84.375\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.757\tAccuracy: 71.875\n",
      "Train step: 110500\tLoss: 1.510\tAccuracy: 96.875\n",
      "Train step: 111000\tLoss: 1.643\tAccuracy: 81.250\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.586\tAccuracy: 87.500\n",
      "Train step: 112000\tLoss: 1.661\tAccuracy: 78.125\n",
      "Train step: 112500\tLoss: 1.681\tAccuracy: 78.125\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.666\tAccuracy: 81.250\n",
      "Train step: 113500\tLoss: 1.598\tAccuracy: 84.375\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.672\tAccuracy: 84.375\n",
      "Train step: 114500\tLoss: 1.688\tAccuracy: 81.250\n",
      "Train step: 115000\tLoss: 1.776\tAccuracy: 68.750\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.771\tAccuracy: 65.625\n",
      "Train step: 116000\tLoss: 1.735\tAccuracy: 68.750\n",
      "Train step: 116500\tLoss: 1.656\tAccuracy: 81.250\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.578\tAccuracy: 90.625\n",
      "Train step: 117500\tLoss: 1.616\tAccuracy: 84.375\n",
      "Train step: 118000\tLoss: 1.544\tAccuracy: 93.750\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.594\tAccuracy: 84.375\n",
      "Train step: 119000\tLoss: 1.694\tAccuracy: 78.125\n",
      "Train step: 119500\tLoss: 1.749\tAccuracy: 75.000\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.727\tAccuracy: 75.000\n",
      "Train step: 120500\tLoss: 1.597\tAccuracy: 90.625\n",
      "Train step: 121000\tLoss: 1.654\tAccuracy: 84.375\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.727\tAccuracy: 71.875\n",
      "Train step: 122000\tLoss: 1.590\tAccuracy: 87.500\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.637\tAccuracy: 84.375\n",
      "Train step: 123000\tLoss: 1.726\tAccuracy: 71.875\n",
      "Train step: 123500\tLoss: 1.601\tAccuracy: 84.375\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.703\tAccuracy: 75.000\n",
      "Train step: 124500\tLoss: 1.663\tAccuracy: 81.250\n",
      "Train step: 125000\tLoss: 1.552\tAccuracy: 93.750\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.581\tAccuracy: 87.500\n",
      "Train step: 126000\tLoss: 1.605\tAccuracy: 87.500\n",
      "Train step: 126500\tLoss: 1.734\tAccuracy: 71.875\n",
      "Current Epoch: 90/n\n",
      "Train step: 127000\tLoss: 1.779\tAccuracy: 68.750\n",
      "Train step: 127500\tLoss: 1.679\tAccuracy: 78.125\n",
      "Train step: 128000\tLoss: 1.571\tAccuracy: 90.625\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 129000\tLoss: 1.588\tAccuracy: 90.625\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.787\tAccuracy: 68.750\n",
      "Train step: 130000\tLoss: 1.668\tAccuracy: 78.125\n",
      "Train step: 130500\tLoss: 1.580\tAccuracy: 87.500\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.591\tAccuracy: 87.500\n",
      "Train step: 131500\tLoss: 1.714\tAccuracy: 75.000\n",
      "Train step: 132000\tLoss: 1.653\tAccuracy: 84.375\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.602\tAccuracy: 87.500\n",
      "Train step: 133000\tLoss: 1.586\tAccuracy: 90.625\n",
      "Train step: 133500\tLoss: 1.664\tAccuracy: 81.250\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.648\tAccuracy: 84.375\n",
      "Train step: 134500\tLoss: 1.632\tAccuracy: 81.250\n",
      "Train step: 135000\tLoss: 1.644\tAccuracy: 84.375\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.634\tAccuracy: 87.500\n",
      "Train step: 136000\tLoss: 1.695\tAccuracy: 78.125\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.639\tAccuracy: 84.375\n",
      "Train step: 137000\tLoss: 1.644\tAccuracy: 84.375\n",
      "Train step: 137500\tLoss: 1.694\tAccuracy: 75.000\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.598\tAccuracy: 87.500\n",
      "Train step: 138500\tLoss: 1.685\tAccuracy: 78.125\n",
      "Train step: 139000\tLoss: 1.680\tAccuracy: 81.250\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.585\tAccuracy: 87.500\n",
      "Train step: 140000\tLoss: 1.776\tAccuracy: 71.875\n",
      "Train step: 140500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Training finished, took 1840.41s\n"
     ]
    }
   ],
   "source": [
    "CNN8 = CNN()\n",
    "trainNet(CNN8, batch_size=32, n_epochs=100, learning_rate=0.030)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7072
    },
    "colab_type": "code",
    "id": "Pg153EaT0xGO",
    "outputId": "71458dfa-5668-40c8-8f97-3bcff05fcadd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 100\n",
      "learning_rate= 0.05\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.303\tAccuracy: 6.250\n",
      "Train step: 500\tLoss: 2.099\tAccuracy: 37.500\n",
      "Train step: 1000\tLoss: 2.024\tAccuracy: 50.000\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.084\tAccuracy: 40.625\n",
      "Train step: 2000\tLoss: 2.011\tAccuracy: 40.625\n",
      "Train step: 2500\tLoss: 1.951\tAccuracy: 53.125\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 1.860\tAccuracy: 65.625\n",
      "Train step: 3500\tLoss: 1.912\tAccuracy: 53.125\n",
      "Train step: 4000\tLoss: 1.898\tAccuracy: 56.250\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 1.922\tAccuracy: 56.250\n",
      "Train step: 5000\tLoss: 1.934\tAccuracy: 53.125\n",
      "Train step: 5500\tLoss: 1.881\tAccuracy: 56.250\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 1.895\tAccuracy: 59.375\n",
      "Train step: 6500\tLoss: 1.881\tAccuracy: 62.500\n",
      "Train step: 7000\tLoss: 1.996\tAccuracy: 46.875\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 1.915\tAccuracy: 53.125\n",
      "Train step: 8000\tLoss: 1.922\tAccuracy: 53.125\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.851\tAccuracy: 59.375\n",
      "Train step: 9000\tLoss: 1.900\tAccuracy: 59.375\n",
      "Train step: 9500\tLoss: 1.678\tAccuracy: 81.250\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 1.985\tAccuracy: 46.875\n",
      "Train step: 10500\tLoss: 1.823\tAccuracy: 65.625\n",
      "Train step: 11000\tLoss: 1.888\tAccuracy: 56.250\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.806\tAccuracy: 65.625\n",
      "Train step: 12000\tLoss: 1.888\tAccuracy: 62.500\n",
      "Train step: 12500\tLoss: 1.790\tAccuracy: 65.625\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 1.855\tAccuracy: 59.375\n",
      "Train step: 13500\tLoss: 1.865\tAccuracy: 59.375\n",
      "Train step: 14000\tLoss: 1.847\tAccuracy: 59.375\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.798\tAccuracy: 65.625\n",
      "Train step: 15000\tLoss: 2.001\tAccuracy: 46.875\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.850\tAccuracy: 59.375\n",
      "Train step: 16000\tLoss: 1.787\tAccuracy: 71.875\n",
      "Train step: 16500\tLoss: 1.735\tAccuracy: 75.000\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.732\tAccuracy: 71.875\n",
      "Train step: 17500\tLoss: 1.769\tAccuracy: 71.875\n",
      "Train step: 18000\tLoss: 1.935\tAccuracy: 53.125\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.880\tAccuracy: 56.250\n",
      "Train step: 19000\tLoss: 1.928\tAccuracy: 53.125\n",
      "Train step: 19500\tLoss: 1.805\tAccuracy: 68.750\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.739\tAccuracy: 71.875\n",
      "Train step: 20500\tLoss: 1.626\tAccuracy: 87.500\n",
      "Train step: 21000\tLoss: 1.885\tAccuracy: 53.125\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.737\tAccuracy: 68.750\n",
      "Train step: 22000\tLoss: 1.918\tAccuracy: 53.125\n",
      "Train step: 22500\tLoss: 1.828\tAccuracy: 62.500\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.890\tAccuracy: 59.375\n",
      "Train step: 23500\tLoss: 1.791\tAccuracy: 68.750\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.816\tAccuracy: 62.500\n",
      "Train step: 24500\tLoss: 1.790\tAccuracy: 65.625\n",
      "Train step: 25000\tLoss: 1.583\tAccuracy: 87.500\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.596\tAccuracy: 87.500\n",
      "Train step: 26000\tLoss: 1.776\tAccuracy: 68.750\n",
      "Train step: 26500\tLoss: 1.765\tAccuracy: 68.750\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.692\tAccuracy: 78.125\n",
      "Train step: 27500\tLoss: 1.735\tAccuracy: 71.875\n",
      "Train step: 28000\tLoss: 1.710\tAccuracy: 75.000\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.719\tAccuracy: 71.875\n",
      "Train step: 29000\tLoss: 1.790\tAccuracy: 65.625\n",
      "Train step: 29500\tLoss: 1.715\tAccuracy: 71.875\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.648\tAccuracy: 78.125\n",
      "Train step: 30500\tLoss: 1.702\tAccuracy: 78.125\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.722\tAccuracy: 71.875\n",
      "Train step: 31500\tLoss: 1.802\tAccuracy: 68.750\n",
      "Train step: 32000\tLoss: 1.689\tAccuracy: 78.125\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.733\tAccuracy: 75.000\n",
      "Train step: 33000\tLoss: 1.902\tAccuracy: 56.250\n",
      "Train step: 33500\tLoss: 1.591\tAccuracy: 87.500\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.819\tAccuracy: 59.375\n",
      "Train step: 34500\tLoss: 1.738\tAccuracy: 71.875\n",
      "Train step: 35000\tLoss: 1.690\tAccuracy: 78.125\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.615\tAccuracy: 84.375\n",
      "Train step: 36000\tLoss: 1.742\tAccuracy: 75.000\n",
      "Train step: 36500\tLoss: 1.677\tAccuracy: 81.250\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.702\tAccuracy: 78.125\n",
      "Train step: 37500\tLoss: 1.622\tAccuracy: 84.375\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.692\tAccuracy: 78.125\n",
      "Train step: 38500\tLoss: 1.711\tAccuracy: 78.125\n",
      "Train step: 39000\tLoss: 1.638\tAccuracy: 84.375\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 40000\tLoss: 1.819\tAccuracy: 65.625\n",
      "Train step: 40500\tLoss: 1.686\tAccuracy: 78.125\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.634\tAccuracy: 84.375\n",
      "Train step: 41500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Train step: 42000\tLoss: 1.651\tAccuracy: 81.250\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.674\tAccuracy: 78.125\n",
      "Train step: 43000\tLoss: 1.781\tAccuracy: 68.750\n",
      "Train step: 43500\tLoss: 1.677\tAccuracy: 81.250\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.690\tAccuracy: 78.125\n",
      "Train step: 44500\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 45000\tLoss: 1.713\tAccuracy: 75.000\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.666\tAccuracy: 81.250\n",
      "Train step: 46000\tLoss: 1.536\tAccuracy: 93.750\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 47000\tLoss: 1.667\tAccuracy: 78.125\n",
      "Train step: 47500\tLoss: 1.695\tAccuracy: 78.125\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.699\tAccuracy: 78.125\n",
      "Train step: 48500\tLoss: 1.609\tAccuracy: 87.500\n",
      "Train step: 49000\tLoss: 1.585\tAccuracy: 90.625\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 50000\tLoss: 1.599\tAccuracy: 87.500\n",
      "Train step: 50500\tLoss: 1.788\tAccuracy: 68.750\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.634\tAccuracy: 84.375\n",
      "Train step: 51500\tLoss: 1.573\tAccuracy: 90.625\n",
      "Train step: 52000\tLoss: 1.624\tAccuracy: 84.375\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.573\tAccuracy: 90.625\n",
      "Train step: 53000\tLoss: 1.685\tAccuracy: 75.000\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.734\tAccuracy: 75.000\n",
      "Train step: 54000\tLoss: 1.799\tAccuracy: 68.750\n",
      "Train step: 54500\tLoss: 1.621\tAccuracy: 90.625\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.735\tAccuracy: 71.875\n",
      "Train step: 55500\tLoss: 1.632\tAccuracy: 84.375\n",
      "Train step: 56000\tLoss: 1.692\tAccuracy: 78.125\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.593\tAccuracy: 90.625\n",
      "Train step: 57000\tLoss: 1.576\tAccuracy: 87.500\n",
      "Train step: 57500\tLoss: 1.705\tAccuracy: 75.000\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.637\tAccuracy: 84.375\n",
      "Train step: 58500\tLoss: 1.476\tAccuracy: 100.000\n",
      "Train step: 59000\tLoss: 1.677\tAccuracy: 78.125\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.695\tAccuracy: 78.125\n",
      "Train step: 60000\tLoss: 1.611\tAccuracy: 84.375\n",
      "Train step: 60500\tLoss: 1.692\tAccuracy: 21.875\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.666\tAccuracy: 78.125\n",
      "Train step: 61500\tLoss: 1.624\tAccuracy: 84.375\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.596\tAccuracy: 87.500\n",
      "Train step: 62500\tLoss: 1.692\tAccuracy: 75.000\n",
      "Train step: 63000\tLoss: 1.619\tAccuracy: 87.500\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 64000\tLoss: 1.669\tAccuracy: 78.125\n",
      "Train step: 64500\tLoss: 1.643\tAccuracy: 84.375\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.600\tAccuracy: 87.500\n",
      "Train step: 65500\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 66000\tLoss: 1.645\tAccuracy: 81.250\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.572\tAccuracy: 90.625\n",
      "Train step: 67000\tLoss: 1.647\tAccuracy: 81.250\n",
      "Train step: 67500\tLoss: 1.520\tAccuracy: 96.875\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.665\tAccuracy: 81.250\n",
      "Train step: 68500\tLoss: 1.662\tAccuracy: 81.250\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.567\tAccuracy: 90.625\n",
      "Train step: 69500\tLoss: 1.587\tAccuracy: 90.625\n",
      "Train step: 70000\tLoss: 1.621\tAccuracy: 84.375\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.689\tAccuracy: 75.000\n",
      "Train step: 71000\tLoss: 1.557\tAccuracy: 90.625\n",
      "Train step: 71500\tLoss: 1.521\tAccuracy: 96.875\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 1.649\tAccuracy: 81.250\n",
      "Train step: 72500\tLoss: 1.533\tAccuracy: 93.750\n",
      "Train step: 73000\tLoss: 1.695\tAccuracy: 75.000\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 74000\tLoss: 1.692\tAccuracy: 78.125\n",
      "Train step: 74500\tLoss: 1.687\tAccuracy: 78.125\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.716\tAccuracy: 75.000\n",
      "Train step: 75500\tLoss: 1.541\tAccuracy: 93.750\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.604\tAccuracy: 84.375\n",
      "Train step: 76500\tLoss: 1.699\tAccuracy: 78.125\n",
      "Train step: 77000\tLoss: 1.624\tAccuracy: 84.375\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.595\tAccuracy: 87.500\n",
      "Train step: 78000\tLoss: 1.651\tAccuracy: 81.250\n",
      "Train step: 78500\tLoss: 1.603\tAccuracy: 87.500\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.576\tAccuracy: 87.500\n",
      "Train step: 79500\tLoss: 1.611\tAccuracy: 84.375\n",
      "Train step: 80000\tLoss: 1.634\tAccuracy: 81.250\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.553\tAccuracy: 90.625\n",
      "Train step: 81000\tLoss: 1.619\tAccuracy: 87.500\n",
      "Train step: 81500\tLoss: 1.605\tAccuracy: 87.500\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.515\tAccuracy: 93.750\n",
      "Train step: 82500\tLoss: 1.663\tAccuracy: 78.125\n",
      "Train step: 83000\tLoss: 1.651\tAccuracy: 81.250\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.571\tAccuracy: 90.625\n",
      "Train step: 84000\tLoss: 1.536\tAccuracy: 93.750\n",
      "Current Epoch: 60/n\n",
      "Train step: 84500\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 85000\tLoss: 1.626\tAccuracy: 84.375\n",
      "Train step: 85500\tLoss: 1.699\tAccuracy: 78.125\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.546\tAccuracy: 93.750\n",
      "Train step: 86500\tLoss: 1.559\tAccuracy: 90.625\n",
      "Train step: 87000\tLoss: 1.577\tAccuracy: 87.500\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.535\tAccuracy: 93.750\n",
      "Train step: 88000\tLoss: 1.664\tAccuracy: 81.250\n",
      "Train step: 88500\tLoss: 1.647\tAccuracy: 81.250\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.559\tAccuracy: 93.750\n",
      "Train step: 89500\tLoss: 1.646\tAccuracy: 81.250\n",
      "Train step: 90000\tLoss: 1.583\tAccuracy: 90.625\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.584\tAccuracy: 90.625\n",
      "Train step: 91000\tLoss: 1.655\tAccuracy: 84.375\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 92000\tLoss: 1.608\tAccuracy: 84.375\n",
      "Train step: 92500\tLoss: 1.545\tAccuracy: 93.750\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.543\tAccuracy: 93.750\n",
      "Train step: 93500\tLoss: 1.577\tAccuracy: 90.625\n",
      "Train step: 94000\tLoss: 1.620\tAccuracy: 84.375\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.626\tAccuracy: 84.375\n",
      "Train step: 95000\tLoss: 1.642\tAccuracy: 81.250\n",
      "Train step: 95500\tLoss: 1.609\tAccuracy: 87.500\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.545\tAccuracy: 93.750\n",
      "Train step: 96500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Train step: 97000\tLoss: 1.570\tAccuracy: 90.625\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 98000\tLoss: 1.571\tAccuracy: 90.625\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.583\tAccuracy: 87.500\n",
      "Train step: 99000\tLoss: 1.581\tAccuracy: 90.625\n",
      "Train step: 99500\tLoss: 1.648\tAccuracy: 84.375\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.654\tAccuracy: 81.250\n",
      "Train step: 100500\tLoss: 1.659\tAccuracy: 81.250\n",
      "Train step: 101000\tLoss: 1.683\tAccuracy: 78.125\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.596\tAccuracy: 84.375\n",
      "Train step: 102000\tLoss: 1.591\tAccuracy: 87.500\n",
      "Train step: 102500\tLoss: 1.550\tAccuracy: 90.625\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 1.686\tAccuracy: 78.125\n",
      "Train step: 103500\tLoss: 1.524\tAccuracy: 93.750\n",
      "Train step: 104000\tLoss: 1.545\tAccuracy: 93.750\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.535\tAccuracy: 93.750\n",
      "Train step: 105000\tLoss: 1.640\tAccuracy: 81.250\n",
      "Train step: 105500\tLoss: 1.512\tAccuracy: 93.750\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.705\tAccuracy: 75.000\n",
      "Train step: 106500\tLoss: 1.673\tAccuracy: 78.125\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.576\tAccuracy: 90.625\n",
      "Train step: 107500\tLoss: 1.681\tAccuracy: 78.125\n",
      "Train step: 108000\tLoss: 1.609\tAccuracy: 84.375\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 1.561\tAccuracy: 87.500\n",
      "Train step: 109000\tLoss: 1.623\tAccuracy: 84.375\n",
      "Train step: 109500\tLoss: 1.661\tAccuracy: 81.250\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.532\tAccuracy: 96.875\n",
      "Train step: 110500\tLoss: 1.645\tAccuracy: 81.250\n",
      "Train step: 111000\tLoss: 1.689\tAccuracy: 78.125\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.767\tAccuracy: 68.750\n",
      "Train step: 112000\tLoss: 1.606\tAccuracy: 84.375\n",
      "Train step: 112500\tLoss: 1.616\tAccuracy: 87.500\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.540\tAccuracy: 93.750\n",
      "Train step: 113500\tLoss: 1.617\tAccuracy: 81.250\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.558\tAccuracy: 90.625\n",
      "Train step: 114500\tLoss: 1.682\tAccuracy: 81.250\n",
      "Train step: 115000\tLoss: 1.653\tAccuracy: 84.375\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.588\tAccuracy: 84.375\n",
      "Train step: 116000\tLoss: 1.564\tAccuracy: 87.500\n",
      "Train step: 116500\tLoss: 1.601\tAccuracy: 87.500\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.601\tAccuracy: 87.500\n",
      "Train step: 117500\tLoss: 1.530\tAccuracy: 93.750\n",
      "Train step: 118000\tLoss: 1.675\tAccuracy: 78.125\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.666\tAccuracy: 78.125\n",
      "Train step: 119000\tLoss: 1.625\tAccuracy: 84.375\n",
      "Train step: 119500\tLoss: 1.558\tAccuracy: 90.625\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.742\tAccuracy: 75.000\n",
      "Train step: 120500\tLoss: 1.661\tAccuracy: 78.125\n",
      "Train step: 121000\tLoss: 1.555\tAccuracy: 93.750\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.558\tAccuracy: 93.750\n",
      "Train step: 122000\tLoss: 1.715\tAccuracy: 75.000\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.700\tAccuracy: 75.000\n",
      "Train step: 123000\tLoss: 1.606\tAccuracy: 87.500\n",
      "Train step: 123500\tLoss: 1.539\tAccuracy: 93.750\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.556\tAccuracy: 90.625\n",
      "Train step: 124500\tLoss: 1.669\tAccuracy: 78.125\n",
      "Train step: 125000\tLoss: 1.642\tAccuracy: 84.375\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 126000\tLoss: 1.563\tAccuracy: 93.750\n",
      "Train step: 126500\tLoss: 1.590\tAccuracy: 87.500\n",
      "Current Epoch: 90/n\n",
      "Train step: 127000\tLoss: 1.619\tAccuracy: 87.500\n",
      "Train step: 127500\tLoss: 1.618\tAccuracy: 81.250\n",
      "Train step: 128000\tLoss: 1.654\tAccuracy: 81.250\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.625\tAccuracy: 84.375\n",
      "Train step: 129000\tLoss: 1.569\tAccuracy: 87.500\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.647\tAccuracy: 81.250\n",
      "Train step: 130000\tLoss: 1.613\tAccuracy: 84.375\n",
      "Train step: 130500\tLoss: 1.620\tAccuracy: 84.375\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.543\tAccuracy: 90.625\n",
      "Train step: 131500\tLoss: 1.705\tAccuracy: 75.000\n",
      "Train step: 132000\tLoss: 1.585\tAccuracy: 87.500\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.529\tAccuracy: 93.750\n",
      "Train step: 133000\tLoss: 1.664\tAccuracy: 78.125\n",
      "Train step: 133500\tLoss: 1.669\tAccuracy: 78.125\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.676\tAccuracy: 81.250\n",
      "Train step: 134500\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 135000\tLoss: 1.544\tAccuracy: 93.750\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.603\tAccuracy: 87.500\n",
      "Train step: 136000\tLoss: 1.637\tAccuracy: 81.250\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.566\tAccuracy: 90.625\n",
      "Train step: 137000\tLoss: 1.630\tAccuracy: 81.250\n",
      "Train step: 137500\tLoss: 1.605\tAccuracy: 87.500\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.649\tAccuracy: 81.250\n",
      "Train step: 138500\tLoss: 1.570\tAccuracy: 90.625\n",
      "Train step: 139000\tLoss: 1.698\tAccuracy: 78.125\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.639\tAccuracy: 84.375\n",
      "Train step: 140000\tLoss: 1.678\tAccuracy: 78.125\n",
      "Train step: 140500\tLoss: 1.679\tAccuracy: 78.125\n",
      "Training finished, took 1841.29s\n"
     ]
    }
   ],
   "source": [
    "CNN9 = CNN()\n",
    "trainNet(CNN9, batch_size=32, n_epochs=100, learning_rate=0.050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z0oGJC-WvuOV"
   },
   "outputs": [],
   "source": [
    "#NOTE CNN6 DOES NOT USE DROPOUT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8454
    },
    "colab_type": "code",
    "id": "9KBa9zEP6KBt",
    "outputId": "74bcb286-0b6a-45d9-fd07-c965ccde60c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 120\n",
      "learning_rate= 0.01\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.303\tAccuracy: 9.375\n",
      "Train step: 500\tLoss: 2.299\tAccuracy: 9.375\n",
      "Train step: 1000\tLoss: 2.244\tAccuracy: 25.000\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.156\tAccuracy: 40.625\n",
      "Train step: 2000\tLoss: 2.123\tAccuracy: 31.250\n",
      "Train step: 2500\tLoss: 2.110\tAccuracy: 43.750\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 2.022\tAccuracy: 40.625\n",
      "Train step: 3500\tLoss: 1.994\tAccuracy: 50.000\n",
      "Train step: 4000\tLoss: 2.029\tAccuracy: 40.625\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 1.970\tAccuracy: 53.125\n",
      "Train step: 5000\tLoss: 2.028\tAccuracy: 46.875\n",
      "Train step: 5500\tLoss: 2.017\tAccuracy: 46.875\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 2.078\tAccuracy: 37.500\n",
      "Train step: 6500\tLoss: 2.029\tAccuracy: 46.875\n",
      "Train step: 7000\tLoss: 2.044\tAccuracy: 37.500\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 1.875\tAccuracy: 65.625\n",
      "Train step: 8000\tLoss: 1.994\tAccuracy: 46.875\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 1.918\tAccuracy: 56.250\n",
      "Train step: 9000\tLoss: 1.893\tAccuracy: 50.000\n",
      "Train step: 9500\tLoss: 1.766\tAccuracy: 68.750\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 1.907\tAccuracy: 56.250\n",
      "Train step: 10500\tLoss: 1.955\tAccuracy: 53.125\n",
      "Train step: 11000\tLoss: 1.878\tAccuracy: 59.375\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 1.921\tAccuracy: 59.375\n",
      "Train step: 12000\tLoss: 1.844\tAccuracy: 62.500\n",
      "Train step: 12500\tLoss: 1.810\tAccuracy: 68.750\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 2.101\tAccuracy: 34.375\n",
      "Train step: 13500\tLoss: 1.976\tAccuracy: 50.000\n",
      "Train step: 14000\tLoss: 1.934\tAccuracy: 46.875\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 1.868\tAccuracy: 59.375\n",
      "Train step: 15000\tLoss: 1.824\tAccuracy: 62.500\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 1.918\tAccuracy: 53.125\n",
      "Train step: 16000\tLoss: 1.910\tAccuracy: 53.125\n",
      "Train step: 16500\tLoss: 1.853\tAccuracy: 62.500\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 1.923\tAccuracy: 46.875\n",
      "Train step: 17500\tLoss: 1.893\tAccuracy: 56.250\n",
      "Train step: 18000\tLoss: 1.873\tAccuracy: 59.375\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 1.830\tAccuracy: 68.750\n",
      "Train step: 19000\tLoss: 1.726\tAccuracy: 71.875\n",
      "Train step: 19500\tLoss: 1.751\tAccuracy: 75.000\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 1.896\tAccuracy: 56.250\n",
      "Train step: 20500\tLoss: 1.949\tAccuracy: 53.125\n",
      "Train step: 21000\tLoss: 1.760\tAccuracy: 71.875\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 1.769\tAccuracy: 71.875\n",
      "Train step: 22000\tLoss: 1.957\tAccuracy: 53.125\n",
      "Train step: 22500\tLoss: 1.808\tAccuracy: 62.500\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 1.757\tAccuracy: 71.875\n",
      "Train step: 23500\tLoss: 1.749\tAccuracy: 71.875\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 1.799\tAccuracy: 65.625\n",
      "Train step: 24500\tLoss: 1.804\tAccuracy: 65.625\n",
      "Train step: 25000\tLoss: 1.681\tAccuracy: 78.125\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 1.830\tAccuracy: 65.625\n",
      "Train step: 26000\tLoss: 1.714\tAccuracy: 75.000\n",
      "Train step: 26500\tLoss: 1.729\tAccuracy: 71.875\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 1.795\tAccuracy: 65.625\n",
      "Train step: 27500\tLoss: 1.742\tAccuracy: 71.875\n",
      "Train step: 28000\tLoss: 1.718\tAccuracy: 75.000\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 1.673\tAccuracy: 78.125\n",
      "Train step: 29000\tLoss: 1.865\tAccuracy: 59.375\n",
      "Train step: 29500\tLoss: 1.702\tAccuracy: 78.125\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 1.873\tAccuracy: 56.250\n",
      "Train step: 30500\tLoss: 1.656\tAccuracy: 81.250\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 1.744\tAccuracy: 71.875\n",
      "Train step: 31500\tLoss: 1.792\tAccuracy: 65.625\n",
      "Train step: 32000\tLoss: 1.784\tAccuracy: 71.875\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 1.808\tAccuracy: 65.625\n",
      "Train step: 33000\tLoss: 1.725\tAccuracy: 75.000\n",
      "Train step: 33500\tLoss: 1.745\tAccuracy: 78.125\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 1.838\tAccuracy: 62.500\n",
      "Train step: 34500\tLoss: 1.732\tAccuracy: 75.000\n",
      "Train step: 35000\tLoss: 1.763\tAccuracy: 71.875\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 1.742\tAccuracy: 78.125\n",
      "Train step: 36000\tLoss: 1.802\tAccuracy: 68.750\n",
      "Train step: 36500\tLoss: 1.646\tAccuracy: 84.375\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 1.679\tAccuracy: 81.250\n",
      "Train step: 37500\tLoss: 1.802\tAccuracy: 71.875\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.785\tAccuracy: 71.875\n",
      "Train step: 38500\tLoss: 1.724\tAccuracy: 75.000\n",
      "Train step: 39000\tLoss: 1.744\tAccuracy: 75.000\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.822\tAccuracy: 65.625\n",
      "Train step: 40000\tLoss: 1.781\tAccuracy: 68.750\n",
      "Train step: 40500\tLoss: 1.682\tAccuracy: 78.125\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.810\tAccuracy: 65.625\n",
      "Train step: 41500\tLoss: 1.877\tAccuracy: 56.250\n",
      "Train step: 42000\tLoss: 1.648\tAccuracy: 84.375\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Train step: 43000\tLoss: 1.834\tAccuracy: 59.375\n",
      "Train step: 43500\tLoss: 1.779\tAccuracy: 68.750\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 1.709\tAccuracy: 75.000\n",
      "Train step: 44500\tLoss: 1.734\tAccuracy: 71.875\n",
      "Train step: 45000\tLoss: 1.667\tAccuracy: 81.250\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 1.766\tAccuracy: 68.750\n",
      "Train step: 46000\tLoss: 1.849\tAccuracy: 59.375\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.722\tAccuracy: 75.000\n",
      "Train step: 47000\tLoss: 1.792\tAccuracy: 68.750\n",
      "Train step: 47500\tLoss: 1.779\tAccuracy: 68.750\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.612\tAccuracy: 87.500\n",
      "Train step: 48500\tLoss: 1.834\tAccuracy: 65.625\n",
      "Train step: 49000\tLoss: 1.684\tAccuracy: 75.000\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 1.722\tAccuracy: 71.875\n",
      "Train step: 50000\tLoss: 1.740\tAccuracy: 75.000\n",
      "Train step: 50500\tLoss: 1.622\tAccuracy: 84.375\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.806\tAccuracy: 65.625\n",
      "Train step: 51500\tLoss: 1.700\tAccuracy: 78.125\n",
      "Train step: 52000\tLoss: 1.729\tAccuracy: 71.875\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.802\tAccuracy: 65.625\n",
      "Train step: 53000\tLoss: 1.658\tAccuracy: 81.250\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.715\tAccuracy: 75.000\n",
      "Train step: 54000\tLoss: 1.739\tAccuracy: 71.875\n",
      "Train step: 54500\tLoss: 1.770\tAccuracy: 71.875\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 1.747\tAccuracy: 71.875\n",
      "Train step: 55500\tLoss: 1.749\tAccuracy: 71.875\n",
      "Train step: 56000\tLoss: 1.736\tAccuracy: 71.875\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.697\tAccuracy: 81.250\n",
      "Train step: 57000\tLoss: 1.626\tAccuracy: 84.375\n",
      "Train step: 57500\tLoss: 1.708\tAccuracy: 71.875\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 1.609\tAccuracy: 87.500\n",
      "Train step: 58500\tLoss: 1.780\tAccuracy: 65.625\n",
      "Train step: 59000\tLoss: 1.714\tAccuracy: 75.000\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.667\tAccuracy: 81.250\n",
      "Train step: 60000\tLoss: 1.715\tAccuracy: 75.000\n",
      "Train step: 60500\tLoss: 1.797\tAccuracy: 15.625\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.637\tAccuracy: 84.375\n",
      "Train step: 61500\tLoss: 1.640\tAccuracy: 84.375\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 1.602\tAccuracy: 90.625\n",
      "Train step: 62500\tLoss: 1.622\tAccuracy: 84.375\n",
      "Train step: 63000\tLoss: 1.672\tAccuracy: 81.250\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Train step: 64000\tLoss: 1.778\tAccuracy: 68.750\n",
      "Train step: 64500\tLoss: 1.774\tAccuracy: 71.875\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.811\tAccuracy: 65.625\n",
      "Train step: 65500\tLoss: 1.716\tAccuracy: 71.875\n",
      "Train step: 66000\tLoss: 1.727\tAccuracy: 75.000\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.774\tAccuracy: 68.750\n",
      "Train step: 67000\tLoss: 1.623\tAccuracy: 84.375\n",
      "Train step: 67500\tLoss: 1.632\tAccuracy: 84.375\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.692\tAccuracy: 78.125\n",
      "Train step: 68500\tLoss: 1.631\tAccuracy: 84.375\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.696\tAccuracy: 75.000\n",
      "Train step: 69500\tLoss: 1.666\tAccuracy: 81.250\n",
      "Train step: 70000\tLoss: 1.724\tAccuracy: 78.125\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.714\tAccuracy: 75.000\n",
      "Train step: 71000\tLoss: 1.628\tAccuracy: 84.375\n",
      "Train step: 71500\tLoss: 1.710\tAccuracy: 75.000\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 1.701\tAccuracy: 78.125\n",
      "Train step: 72500\tLoss: 1.628\tAccuracy: 81.250\n",
      "Train step: 73000\tLoss: 1.714\tAccuracy: 71.875\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.628\tAccuracy: 90.625\n",
      "Train step: 74000\tLoss: 1.720\tAccuracy: 75.000\n",
      "Train step: 74500\tLoss: 1.726\tAccuracy: 75.000\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.584\tAccuracy: 87.500\n",
      "Train step: 75500\tLoss: 1.748\tAccuracy: 71.875\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.733\tAccuracy: 75.000\n",
      "Train step: 76500\tLoss: 1.634\tAccuracy: 84.375\n",
      "Train step: 77000\tLoss: 1.687\tAccuracy: 81.250\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.716\tAccuracy: 75.000\n",
      "Train step: 78000\tLoss: 1.552\tAccuracy: 93.750\n",
      "Train step: 78500\tLoss: 1.540\tAccuracy: 93.750\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.591\tAccuracy: 87.500\n",
      "Train step: 79500\tLoss: 1.658\tAccuracy: 81.250\n",
      "Train step: 80000\tLoss: 1.663\tAccuracy: 81.250\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.596\tAccuracy: 87.500\n",
      "Train step: 81000\tLoss: 1.562\tAccuracy: 90.625\n",
      "Train step: 81500\tLoss: 1.663\tAccuracy: 81.250\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.746\tAccuracy: 71.875\n",
      "Train step: 82500\tLoss: 1.659\tAccuracy: 81.250\n",
      "Train step: 83000\tLoss: 1.510\tAccuracy: 96.875\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.622\tAccuracy: 87.500\n",
      "Train step: 84000\tLoss: 1.617\tAccuracy: 87.500\n",
      "Current Epoch: 60/n\n",
      "Train step: 84500\tLoss: 1.662\tAccuracy: 81.250\n",
      "Train step: 85000\tLoss: 1.623\tAccuracy: 87.500\n",
      "Train step: 85500\tLoss: 1.795\tAccuracy: 68.750\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.489\tAccuracy: 100.000\n",
      "Train step: 86500\tLoss: 1.597\tAccuracy: 87.500\n",
      "Train step: 87000\tLoss: 1.617\tAccuracy: 84.375\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.569\tAccuracy: 90.625\n",
      "Train step: 88000\tLoss: 1.731\tAccuracy: 75.000\n",
      "Train step: 88500\tLoss: 1.597\tAccuracy: 90.625\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.582\tAccuracy: 87.500\n",
      "Train step: 89500\tLoss: 1.669\tAccuracy: 84.375\n",
      "Train step: 90000\tLoss: 1.746\tAccuracy: 75.000\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.571\tAccuracy: 90.625\n",
      "Train step: 91000\tLoss: 1.639\tAccuracy: 84.375\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 1.574\tAccuracy: 90.625\n",
      "Train step: 92000\tLoss: 1.517\tAccuracy: 96.875\n",
      "Train step: 92500\tLoss: 1.761\tAccuracy: 71.875\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.712\tAccuracy: 75.000\n",
      "Train step: 93500\tLoss: 1.680\tAccuracy: 81.250\n",
      "Train step: 94000\tLoss: 1.578\tAccuracy: 90.625\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.667\tAccuracy: 78.125\n",
      "Train step: 95000\tLoss: 1.601\tAccuracy: 87.500\n",
      "Train step: 95500\tLoss: 1.653\tAccuracy: 81.250\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.622\tAccuracy: 84.375\n",
      "Train step: 96500\tLoss: 1.578\tAccuracy: 90.625\n",
      "Train step: 97000\tLoss: 1.536\tAccuracy: 93.750\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.570\tAccuracy: 90.625\n",
      "Train step: 98000\tLoss: 1.627\tAccuracy: 84.375\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.614\tAccuracy: 84.375\n",
      "Train step: 99000\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 99500\tLoss: 1.578\tAccuracy: 93.750\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.630\tAccuracy: 84.375\n",
      "Train step: 100500\tLoss: 1.507\tAccuracy: 96.875\n",
      "Train step: 101000\tLoss: 1.566\tAccuracy: 90.625\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.613\tAccuracy: 84.375\n",
      "Train step: 102000\tLoss: 1.720\tAccuracy: 75.000\n",
      "Train step: 102500\tLoss: 1.597\tAccuracy: 87.500\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 1.841\tAccuracy: 62.500\n",
      "Train step: 103500\tLoss: 1.682\tAccuracy: 78.125\n",
      "Train step: 104000\tLoss: 1.674\tAccuracy: 78.125\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.718\tAccuracy: 75.000\n",
      "Train step: 105000\tLoss: 1.507\tAccuracy: 96.875\n",
      "Train step: 105500\tLoss: 1.624\tAccuracy: 84.375\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.620\tAccuracy: 84.375\n",
      "Train step: 106500\tLoss: 1.557\tAccuracy: 90.625\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.652\tAccuracy: 81.250\n",
      "Train step: 107500\tLoss: 1.592\tAccuracy: 87.500\n",
      "Train step: 108000\tLoss: 1.628\tAccuracy: 84.375\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 1.626\tAccuracy: 84.375\n",
      "Train step: 109000\tLoss: 1.606\tAccuracy: 87.500\n",
      "Train step: 109500\tLoss: 1.525\tAccuracy: 93.750\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.584\tAccuracy: 90.625\n",
      "Train step: 110500\tLoss: 1.580\tAccuracy: 90.625\n",
      "Train step: 111000\tLoss: 1.592\tAccuracy: 87.500\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.597\tAccuracy: 87.500\n",
      "Train step: 112000\tLoss: 1.594\tAccuracy: 87.500\n",
      "Train step: 112500\tLoss: 1.564\tAccuracy: 90.625\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.628\tAccuracy: 84.375\n",
      "Train step: 113500\tLoss: 1.654\tAccuracy: 81.250\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.559\tAccuracy: 90.625\n",
      "Train step: 114500\tLoss: 1.576\tAccuracy: 90.625\n",
      "Train step: 115000\tLoss: 1.594\tAccuracy: 87.500\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.568\tAccuracy: 90.625\n",
      "Train step: 116000\tLoss: 1.646\tAccuracy: 81.250\n",
      "Train step: 116500\tLoss: 1.529\tAccuracy: 93.750\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.561\tAccuracy: 90.625\n",
      "Train step: 117500\tLoss: 1.555\tAccuracy: 90.625\n",
      "Train step: 118000\tLoss: 1.557\tAccuracy: 90.625\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.637\tAccuracy: 81.250\n",
      "Train step: 119000\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 119500\tLoss: 1.625\tAccuracy: 84.375\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.534\tAccuracy: 93.750\n",
      "Train step: 120500\tLoss: 1.501\tAccuracy: 96.875\n",
      "Train step: 121000\tLoss: 1.621\tAccuracy: 84.375\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.504\tAccuracy: 96.875\n",
      "Train step: 122000\tLoss: 1.712\tAccuracy: 75.000\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.505\tAccuracy: 96.875\n",
      "Train step: 123000\tLoss: 1.558\tAccuracy: 90.625\n",
      "Train step: 123500\tLoss: 1.558\tAccuracy: 90.625\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 124500\tLoss: 1.621\tAccuracy: 84.375\n",
      "Train step: 125000\tLoss: 1.557\tAccuracy: 90.625\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.542\tAccuracy: 93.750\n",
      "Train step: 126000\tLoss: 1.561\tAccuracy: 90.625\n",
      "Train step: 126500\tLoss: 1.608\tAccuracy: 87.500\n",
      "Current Epoch: 90/n\n",
      "Train step: 127000\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 127500\tLoss: 1.656\tAccuracy: 81.250\n",
      "Train step: 128000\tLoss: 1.633\tAccuracy: 81.250\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.612\tAccuracy: 84.375\n",
      "Train step: 129000\tLoss: 1.588\tAccuracy: 87.500\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.571\tAccuracy: 90.625\n",
      "Train step: 130000\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 130500\tLoss: 1.569\tAccuracy: 87.500\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.529\tAccuracy: 93.750\n",
      "Train step: 131500\tLoss: 1.560\tAccuracy: 90.625\n",
      "Train step: 132000\tLoss: 1.634\tAccuracy: 84.375\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.538\tAccuracy: 93.750\n",
      "Train step: 133000\tLoss: 1.513\tAccuracy: 96.875\n",
      "Train step: 133500\tLoss: 1.561\tAccuracy: 90.625\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.556\tAccuracy: 90.625\n",
      "Train step: 134500\tLoss: 1.535\tAccuracy: 93.750\n",
      "Train step: 135000\tLoss: 1.563\tAccuracy: 90.625\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.708\tAccuracy: 75.000\n",
      "Train step: 136000\tLoss: 1.567\tAccuracy: 90.625\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.497\tAccuracy: 96.875\n",
      "Train step: 137000\tLoss: 1.507\tAccuracy: 96.875\n",
      "Train step: 137500\tLoss: 1.627\tAccuracy: 84.375\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.557\tAccuracy: 90.625\n",
      "Train step: 138500\tLoss: 1.563\tAccuracy: 90.625\n",
      "Train step: 139000\tLoss: 1.525\tAccuracy: 93.750\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.529\tAccuracy: 93.750\n",
      "Train step: 140000\tLoss: 1.510\tAccuracy: 96.875\n",
      "Train step: 140500\tLoss: 1.589\tAccuracy: 87.500\n",
      "Current Epoch: 100/n\n",
      "Train step: 141000\tLoss: 1.618\tAccuracy: 84.375\n",
      "Train step: 141500\tLoss: 1.617\tAccuracy: 84.375\n",
      "Train step: 142000\tLoss: 1.514\tAccuracy: 96.875\n",
      "Current Epoch: 101/n\n",
      "Train step: 142500\tLoss: 1.528\tAccuracy: 93.750\n",
      "Train step: 143000\tLoss: 1.619\tAccuracy: 84.375\n",
      "Train step: 143500\tLoss: 1.556\tAccuracy: 90.625\n",
      "Current Epoch: 102/n\n",
      "Train step: 144000\tLoss: 1.528\tAccuracy: 93.750\n",
      "Train step: 144500\tLoss: 1.557\tAccuracy: 90.625\n",
      "Current Epoch: 103/n\n",
      "Train step: 145000\tLoss: 1.525\tAccuracy: 93.750\n",
      "Train step: 145500\tLoss: 1.559\tAccuracy: 90.625\n",
      "Train step: 146000\tLoss: 1.566\tAccuracy: 90.625\n",
      "Current Epoch: 104/n\n",
      "Train step: 146500\tLoss: 1.648\tAccuracy: 81.250\n",
      "Train step: 147000\tLoss: 1.588\tAccuracy: 87.500\n",
      "Train step: 147500\tLoss: 1.500\tAccuracy: 96.875\n",
      "Current Epoch: 105/n\n",
      "Train step: 148000\tLoss: 1.561\tAccuracy: 90.625\n",
      "Train step: 148500\tLoss: 1.566\tAccuracy: 90.625\n",
      "Train step: 149000\tLoss: 1.628\tAccuracy: 84.375\n",
      "Current Epoch: 106/n\n",
      "Train step: 149500\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 150000\tLoss: 1.571\tAccuracy: 90.625\n",
      "Train step: 150500\tLoss: 1.565\tAccuracy: 90.625\n",
      "Current Epoch: 107/n\n",
      "Train step: 151000\tLoss: 1.623\tAccuracy: 84.375\n",
      "Train step: 151500\tLoss: 1.650\tAccuracy: 81.250\n",
      "Current Epoch: 108/n\n",
      "Train step: 152000\tLoss: 1.555\tAccuracy: 90.625\n",
      "Train step: 152500\tLoss: 1.558\tAccuracy: 90.625\n",
      "Train step: 153000\tLoss: 1.589\tAccuracy: 87.500\n",
      "Current Epoch: 109/n\n",
      "Train step: 153500\tLoss: 1.619\tAccuracy: 84.375\n",
      "Train step: 154000\tLoss: 1.550\tAccuracy: 90.625\n",
      "Train step: 154500\tLoss: 1.504\tAccuracy: 96.875\n",
      "Current Epoch: 110/n\n",
      "Train step: 155000\tLoss: 1.494\tAccuracy: 96.875\n",
      "Train step: 155500\tLoss: 1.592\tAccuracy: 87.500\n",
      "Train step: 156000\tLoss: 1.557\tAccuracy: 90.625\n",
      "Current Epoch: 111/n\n",
      "Train step: 156500\tLoss: 1.495\tAccuracy: 96.875\n",
      "Train step: 157000\tLoss: 1.553\tAccuracy: 90.625\n",
      "Train step: 157500\tLoss: 1.562\tAccuracy: 90.625\n",
      "Current Epoch: 112/n\n",
      "Train step: 158000\tLoss: 1.526\tAccuracy: 93.750\n",
      "Train step: 158500\tLoss: 1.616\tAccuracy: 84.375\n",
      "Current Epoch: 113/n\n",
      "Train step: 159000\tLoss: 1.525\tAccuracy: 93.750\n",
      "Train step: 159500\tLoss: 1.525\tAccuracy: 93.750\n",
      "Train step: 160000\tLoss: 1.504\tAccuracy: 96.875\n",
      "Current Epoch: 114/n\n",
      "Train step: 160500\tLoss: 1.495\tAccuracy: 96.875\n",
      "Train step: 161000\tLoss: 1.555\tAccuracy: 90.625\n",
      "Train step: 161500\tLoss: 1.615\tAccuracy: 84.375\n",
      "Current Epoch: 115/n\n",
      "Train step: 162000\tLoss: 1.560\tAccuracy: 90.625\n",
      "Train step: 162500\tLoss: 1.529\tAccuracy: 93.750\n",
      "Train step: 163000\tLoss: 1.467\tAccuracy: 100.000\n",
      "Current Epoch: 116/n\n",
      "Train step: 163500\tLoss: 1.467\tAccuracy: 100.000\n",
      "Train step: 164000\tLoss: 1.684\tAccuracy: 78.125\n",
      "Train step: 164500\tLoss: 1.619\tAccuracy: 84.375\n",
      "Current Epoch: 117/n\n",
      "Train step: 165000\tLoss: 1.497\tAccuracy: 96.875\n",
      "Train step: 165500\tLoss: 1.494\tAccuracy: 96.875\n",
      "Train step: 166000\tLoss: 1.493\tAccuracy: 96.875\n",
      "Current Epoch: 118/n\n",
      "Train step: 166500\tLoss: 1.502\tAccuracy: 96.875\n",
      "Train step: 167000\tLoss: 1.494\tAccuracy: 96.875\n",
      "Current Epoch: 119/n\n",
      "Train step: 167500\tLoss: 1.523\tAccuracy: 93.750\n",
      "Train step: 168000\tLoss: 1.527\tAccuracy: 93.750\n",
      "Train step: 168500\tLoss: 1.618\tAccuracy: 84.375\n",
      "Training finished, took 2145.04s\n"
     ]
    }
   ],
   "source": [
    "#BEST MODEL SO FAR1\n",
    "CNN6 = CNN()\n",
    "trainNet(CNN6, batch_size=32, n_epochs=120, learning_rate=0.010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 7072
    },
    "colab_type": "code",
    "id": "pRUlBVAJd4SM",
    "outputId": "4fdd031c-6865-4275-8c05-5a2ba032b145"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 100\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.302\tAccuracy: 12.500\n",
      "Train step: 500\tLoss: 2.297\tAccuracy: 12.500\n",
      "Train step: 1000\tLoss: 2.301\tAccuracy: 6.250\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.288\tAccuracy: 15.625\n",
      "Train step: 2000\tLoss: 2.280\tAccuracy: 12.500\n",
      "Train step: 2500\tLoss: 2.309\tAccuracy: 0.000\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 2.315\tAccuracy: 0.000\n",
      "Train step: 3500\tLoss: 2.265\tAccuracy: 9.375\n",
      "Train step: 4000\tLoss: 2.238\tAccuracy: 21.875\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 2.257\tAccuracy: 21.875\n",
      "Train step: 5000\tLoss: 2.288\tAccuracy: 15.625\n",
      "Train step: 5500\tLoss: 2.314\tAccuracy: 12.500\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 2.325\tAccuracy: 12.500\n",
      "Train step: 6500\tLoss: 2.245\tAccuracy: 21.875\n",
      "Train step: 7000\tLoss: 2.253\tAccuracy: 15.625\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 2.227\tAccuracy: 15.625\n",
      "Train step: 8000\tLoss: 2.184\tAccuracy: 25.000\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 2.197\tAccuracy: 25.000\n",
      "Train step: 9000\tLoss: 2.233\tAccuracy: 18.750\n",
      "Train step: 9500\tLoss: 2.123\tAccuracy: 37.500\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 2.175\tAccuracy: 28.125\n",
      "Train step: 10500\tLoss: 2.258\tAccuracy: 15.625\n",
      "Train step: 11000\tLoss: 2.193\tAccuracy: 25.000\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 2.242\tAccuracy: 18.750\n",
      "Train step: 12000\tLoss: 2.184\tAccuracy: 28.125\n",
      "Train step: 12500\tLoss: 2.212\tAccuracy: 25.000\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 2.112\tAccuracy: 50.000\n",
      "Train step: 13500\tLoss: 2.214\tAccuracy: 28.125\n",
      "Train step: 14000\tLoss: 2.104\tAccuracy: 40.625\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 2.222\tAccuracy: 25.000\n",
      "Train step: 15000\tLoss: 2.164\tAccuracy: 31.250\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 2.183\tAccuracy: 40.625\n",
      "Train step: 16000\tLoss: 2.165\tAccuracy: 28.125\n",
      "Train step: 16500\tLoss: 2.124\tAccuracy: 37.500\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 2.119\tAccuracy: 37.500\n",
      "Train step: 17500\tLoss: 2.155\tAccuracy: 28.125\n",
      "Train step: 18000\tLoss: 2.213\tAccuracy: 25.000\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 2.115\tAccuracy: 37.500\n",
      "Train step: 19000\tLoss: 2.225\tAccuracy: 21.875\n",
      "Train step: 19500\tLoss: 2.093\tAccuracy: 37.500\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 2.182\tAccuracy: 34.375\n",
      "Train step: 20500\tLoss: 2.067\tAccuracy: 43.750\n",
      "Train step: 21000\tLoss: 2.054\tAccuracy: 46.875\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 2.102\tAccuracy: 40.625\n",
      "Train step: 22000\tLoss: 2.058\tAccuracy: 34.375\n",
      "Train step: 22500\tLoss: 2.086\tAccuracy: 31.250\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 2.139\tAccuracy: 31.250\n",
      "Train step: 23500\tLoss: 2.020\tAccuracy: 50.000\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 2.079\tAccuracy: 40.625\n",
      "Train step: 24500\tLoss: 2.161\tAccuracy: 28.125\n",
      "Train step: 25000\tLoss: 2.054\tAccuracy: 46.875\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 2.173\tAccuracy: 25.000\n",
      "Train step: 26000\tLoss: 2.046\tAccuracy: 37.500\n",
      "Train step: 26500\tLoss: 2.169\tAccuracy: 25.000\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 2.028\tAccuracy: 46.875\n",
      "Train step: 27500\tLoss: 2.025\tAccuracy: 40.625\n",
      "Train step: 28000\tLoss: 2.047\tAccuracy: 43.750\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 2.040\tAccuracy: 43.750\n",
      "Train step: 29000\tLoss: 1.932\tAccuracy: 56.250\n",
      "Train step: 29500\tLoss: 2.041\tAccuracy: 40.625\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 2.142\tAccuracy: 28.125\n",
      "Train step: 30500\tLoss: 2.124\tAccuracy: 28.125\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 2.074\tAccuracy: 40.625\n",
      "Train step: 31500\tLoss: 2.131\tAccuracy: 40.625\n",
      "Train step: 32000\tLoss: 1.968\tAccuracy: 56.250\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 2.017\tAccuracy: 43.750\n",
      "Train step: 33000\tLoss: 2.041\tAccuracy: 46.875\n",
      "Train step: 33500\tLoss: 1.959\tAccuracy: 56.250\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 2.081\tAccuracy: 37.500\n",
      "Train step: 34500\tLoss: 2.085\tAccuracy: 34.375\n",
      "Train step: 35000\tLoss: 2.087\tAccuracy: 37.500\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 2.067\tAccuracy: 34.375\n",
      "Train step: 36000\tLoss: 2.000\tAccuracy: 46.875\n",
      "Train step: 36500\tLoss: 2.129\tAccuracy: 25.000\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 2.010\tAccuracy: 50.000\n",
      "Train step: 37500\tLoss: 2.058\tAccuracy: 37.500\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.968\tAccuracy: 50.000\n",
      "Train step: 38500\tLoss: 2.009\tAccuracy: 43.750\n",
      "Train step: 39000\tLoss: 2.051\tAccuracy: 40.625\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 1.859\tAccuracy: 71.875\n",
      "Train step: 40000\tLoss: 2.057\tAccuracy: 46.875\n",
      "Train step: 40500\tLoss: 1.979\tAccuracy: 50.000\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 2.094\tAccuracy: 37.500\n",
      "Train step: 41500\tLoss: 2.035\tAccuracy: 43.750\n",
      "Train step: 42000\tLoss: 1.915\tAccuracy: 62.500\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.984\tAccuracy: 59.375\n",
      "Train step: 43000\tLoss: 2.039\tAccuracy: 40.625\n",
      "Train step: 43500\tLoss: 2.167\tAccuracy: 34.375\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 2.114\tAccuracy: 34.375\n",
      "Train step: 44500\tLoss: 2.031\tAccuracy: 46.875\n",
      "Train step: 45000\tLoss: 2.035\tAccuracy: 40.625\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 2.019\tAccuracy: 43.750\n",
      "Train step: 46000\tLoss: 1.910\tAccuracy: 59.375\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.968\tAccuracy: 50.000\n",
      "Train step: 47000\tLoss: 1.988\tAccuracy: 50.000\n",
      "Train step: 47500\tLoss: 1.933\tAccuracy: 53.125\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.975\tAccuracy: 53.125\n",
      "Train step: 48500\tLoss: 2.093\tAccuracy: 34.375\n",
      "Train step: 49000\tLoss: 1.992\tAccuracy: 53.125\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 2.047\tAccuracy: 40.625\n",
      "Train step: 50000\tLoss: 2.070\tAccuracy: 37.500\n",
      "Train step: 50500\tLoss: 1.984\tAccuracy: 50.000\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.941\tAccuracy: 53.125\n",
      "Train step: 51500\tLoss: 2.056\tAccuracy: 34.375\n",
      "Train step: 52000\tLoss: 1.941\tAccuracy: 53.125\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 1.962\tAccuracy: 50.000\n",
      "Train step: 53000\tLoss: 1.919\tAccuracy: 50.000\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.986\tAccuracy: 53.125\n",
      "Train step: 54000\tLoss: 1.901\tAccuracy: 68.750\n",
      "Train step: 54500\tLoss: 1.962\tAccuracy: 46.875\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 2.022\tAccuracy: 46.875\n",
      "Train step: 55500\tLoss: 1.939\tAccuracy: 53.125\n",
      "Train step: 56000\tLoss: 2.019\tAccuracy: 46.875\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 1.909\tAccuracy: 56.250\n",
      "Train step: 57000\tLoss: 2.002\tAccuracy: 43.750\n",
      "Train step: 57500\tLoss: 2.041\tAccuracy: 40.625\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 2.027\tAccuracy: 43.750\n",
      "Train step: 58500\tLoss: 2.027\tAccuracy: 50.000\n",
      "Train step: 59000\tLoss: 2.004\tAccuracy: 50.000\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 2.057\tAccuracy: 43.750\n",
      "Train step: 60000\tLoss: 1.861\tAccuracy: 62.500\n",
      "Train step: 60500\tLoss: 2.041\tAccuracy: 12.500\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.932\tAccuracy: 53.125\n",
      "Train step: 61500\tLoss: 2.115\tAccuracy: 28.125\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 2.070\tAccuracy: 34.375\n",
      "Train step: 62500\tLoss: 1.983\tAccuracy: 50.000\n",
      "Train step: 63000\tLoss: 2.136\tAccuracy: 31.250\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 1.933\tAccuracy: 53.125\n",
      "Train step: 64000\tLoss: 2.030\tAccuracy: 43.750\n",
      "Train step: 64500\tLoss: 2.030\tAccuracy: 40.625\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.986\tAccuracy: 46.875\n",
      "Train step: 65500\tLoss: 2.013\tAccuracy: 43.750\n",
      "Train step: 66000\tLoss: 1.986\tAccuracy: 50.000\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.951\tAccuracy: 53.125\n",
      "Train step: 67000\tLoss: 1.961\tAccuracy: 56.250\n",
      "Train step: 67500\tLoss: 2.020\tAccuracy: 53.125\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 2.046\tAccuracy: 46.875\n",
      "Train step: 68500\tLoss: 2.052\tAccuracy: 43.750\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.934\tAccuracy: 53.125\n",
      "Train step: 69500\tLoss: 1.947\tAccuracy: 53.125\n",
      "Train step: 70000\tLoss: 2.088\tAccuracy: 40.625\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 1.911\tAccuracy: 56.250\n",
      "Train step: 71000\tLoss: 1.937\tAccuracy: 56.250\n",
      "Train step: 71500\tLoss: 1.954\tAccuracy: 50.000\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 2.066\tAccuracy: 37.500\n",
      "Train step: 72500\tLoss: 1.987\tAccuracy: 46.875\n",
      "Train step: 73000\tLoss: 1.956\tAccuracy: 50.000\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.869\tAccuracy: 62.500\n",
      "Train step: 74000\tLoss: 2.084\tAccuracy: 34.375\n",
      "Train step: 74500\tLoss: 1.956\tAccuracy: 50.000\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 1.979\tAccuracy: 46.875\n",
      "Train step: 75500\tLoss: 1.954\tAccuracy: 53.125\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.980\tAccuracy: 46.875\n",
      "Train step: 76500\tLoss: 2.094\tAccuracy: 34.375\n",
      "Train step: 77000\tLoss: 1.888\tAccuracy: 62.500\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 2.005\tAccuracy: 46.875\n",
      "Train step: 78000\tLoss: 1.894\tAccuracy: 56.250\n",
      "Train step: 78500\tLoss: 1.959\tAccuracy: 53.125\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.893\tAccuracy: 62.500\n",
      "Train step: 79500\tLoss: 2.009\tAccuracy: 46.875\n",
      "Train step: 80000\tLoss: 1.928\tAccuracy: 56.250\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.933\tAccuracy: 46.875\n",
      "Train step: 81000\tLoss: 1.910\tAccuracy: 56.250\n",
      "Train step: 81500\tLoss: 2.026\tAccuracy: 43.750\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.892\tAccuracy: 65.625\n",
      "Train step: 82500\tLoss: 2.028\tAccuracy: 43.750\n",
      "Train step: 83000\tLoss: 2.015\tAccuracy: 50.000\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 1.900\tAccuracy: 53.125\n",
      "Train step: 84000\tLoss: 2.003\tAccuracy: 50.000\n",
      "Current Epoch: 60/n\n",
      "Train step: 84500\tLoss: 2.014\tAccuracy: 43.750\n",
      "Train step: 85000\tLoss: 1.982\tAccuracy: 46.875\n",
      "Train step: 85500\tLoss: 1.926\tAccuracy: 53.125\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.915\tAccuracy: 53.125\n",
      "Train step: 86500\tLoss: 1.975\tAccuracy: 53.125\n",
      "Train step: 87000\tLoss: 1.986\tAccuracy: 50.000\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.818\tAccuracy: 65.625\n",
      "Train step: 88000\tLoss: 1.892\tAccuracy: 65.625\n",
      "Train step: 88500\tLoss: 1.956\tAccuracy: 50.000\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.864\tAccuracy: 65.625\n",
      "Train step: 89500\tLoss: 1.952\tAccuracy: 46.875\n",
      "Train step: 90000\tLoss: 1.931\tAccuracy: 56.250\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 1.902\tAccuracy: 56.250\n",
      "Train step: 91000\tLoss: 1.902\tAccuracy: 59.375\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 2.005\tAccuracy: 40.625\n",
      "Train step: 92000\tLoss: 2.064\tAccuracy: 43.750\n",
      "Train step: 92500\tLoss: 1.904\tAccuracy: 56.250\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.875\tAccuracy: 56.250\n",
      "Train step: 93500\tLoss: 1.859\tAccuracy: 65.625\n",
      "Train step: 94000\tLoss: 2.027\tAccuracy: 40.625\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.930\tAccuracy: 53.125\n",
      "Train step: 95000\tLoss: 1.921\tAccuracy: 56.250\n",
      "Train step: 95500\tLoss: 1.871\tAccuracy: 59.375\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.940\tAccuracy: 56.250\n",
      "Train step: 96500\tLoss: 1.922\tAccuracy: 56.250\n",
      "Train step: 97000\tLoss: 1.925\tAccuracy: 59.375\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.959\tAccuracy: 50.000\n",
      "Train step: 98000\tLoss: 1.875\tAccuracy: 59.375\n",
      "Current Epoch: 70/n\n",
      "Train step: 98500\tLoss: 1.925\tAccuracy: 56.250\n",
      "Train step: 99000\tLoss: 1.866\tAccuracy: 65.625\n",
      "Train step: 99500\tLoss: 1.921\tAccuracy: 56.250\n",
      "Current Epoch: 71/n\n",
      "Train step: 100000\tLoss: 1.779\tAccuracy: 71.875\n",
      "Train step: 100500\tLoss: 1.977\tAccuracy: 50.000\n",
      "Train step: 101000\tLoss: 1.999\tAccuracy: 46.875\n",
      "Current Epoch: 72/n\n",
      "Train step: 101500\tLoss: 1.854\tAccuracy: 59.375\n",
      "Train step: 102000\tLoss: 1.842\tAccuracy: 59.375\n",
      "Train step: 102500\tLoss: 1.898\tAccuracy: 56.250\n",
      "Current Epoch: 73/n\n",
      "Train step: 103000\tLoss: 2.003\tAccuracy: 46.875\n",
      "Train step: 103500\tLoss: 1.944\tAccuracy: 53.125\n",
      "Train step: 104000\tLoss: 1.800\tAccuracy: 68.750\n",
      "Current Epoch: 74/n\n",
      "Train step: 104500\tLoss: 1.875\tAccuracy: 56.250\n",
      "Train step: 105000\tLoss: 1.803\tAccuracy: 71.875\n",
      "Train step: 105500\tLoss: 1.958\tAccuracy: 53.125\n",
      "Current Epoch: 75/n\n",
      "Train step: 106000\tLoss: 1.917\tAccuracy: 56.250\n",
      "Train step: 106500\tLoss: 2.003\tAccuracy: 46.875\n",
      "Current Epoch: 76/n\n",
      "Train step: 107000\tLoss: 1.978\tAccuracy: 50.000\n",
      "Train step: 107500\tLoss: 1.806\tAccuracy: 71.875\n",
      "Train step: 108000\tLoss: 1.970\tAccuracy: 46.875\n",
      "Current Epoch: 77/n\n",
      "Train step: 108500\tLoss: 2.048\tAccuracy: 46.875\n",
      "Train step: 109000\tLoss: 1.953\tAccuracy: 46.875\n",
      "Train step: 109500\tLoss: 1.821\tAccuracy: 65.625\n",
      "Current Epoch: 78/n\n",
      "Train step: 110000\tLoss: 1.993\tAccuracy: 43.750\n",
      "Train step: 110500\tLoss: 1.794\tAccuracy: 68.750\n",
      "Train step: 111000\tLoss: 2.048\tAccuracy: 37.500\n",
      "Current Epoch: 79/n\n",
      "Train step: 111500\tLoss: 1.801\tAccuracy: 65.625\n",
      "Train step: 112000\tLoss: 1.989\tAccuracy: 50.000\n",
      "Train step: 112500\tLoss: 1.769\tAccuracy: 75.000\n",
      "Current Epoch: 80/n\n",
      "Train step: 113000\tLoss: 1.869\tAccuracy: 62.500\n",
      "Train step: 113500\tLoss: 1.926\tAccuracy: 59.375\n",
      "Current Epoch: 81/n\n",
      "Train step: 114000\tLoss: 1.993\tAccuracy: 46.875\n",
      "Train step: 114500\tLoss: 1.963\tAccuracy: 50.000\n",
      "Train step: 115000\tLoss: 1.883\tAccuracy: 56.250\n",
      "Current Epoch: 82/n\n",
      "Train step: 115500\tLoss: 1.997\tAccuracy: 46.875\n",
      "Train step: 116000\tLoss: 1.866\tAccuracy: 59.375\n",
      "Train step: 116500\tLoss: 1.913\tAccuracy: 56.250\n",
      "Current Epoch: 83/n\n",
      "Train step: 117000\tLoss: 1.875\tAccuracy: 59.375\n",
      "Train step: 117500\tLoss: 1.843\tAccuracy: 68.750\n",
      "Train step: 118000\tLoss: 1.954\tAccuracy: 50.000\n",
      "Current Epoch: 84/n\n",
      "Train step: 118500\tLoss: 1.889\tAccuracy: 56.250\n",
      "Train step: 119000\tLoss: 1.843\tAccuracy: 62.500\n",
      "Train step: 119500\tLoss: 1.913\tAccuracy: 59.375\n",
      "Current Epoch: 85/n\n",
      "Train step: 120000\tLoss: 1.934\tAccuracy: 53.125\n",
      "Train step: 120500\tLoss: 1.849\tAccuracy: 62.500\n",
      "Train step: 121000\tLoss: 1.820\tAccuracy: 62.500\n",
      "Current Epoch: 86/n\n",
      "Train step: 121500\tLoss: 1.978\tAccuracy: 50.000\n",
      "Train step: 122000\tLoss: 1.788\tAccuracy: 65.625\n",
      "Current Epoch: 87/n\n",
      "Train step: 122500\tLoss: 1.782\tAccuracy: 71.875\n",
      "Train step: 123000\tLoss: 1.953\tAccuracy: 53.125\n",
      "Train step: 123500\tLoss: 1.777\tAccuracy: 71.875\n",
      "Current Epoch: 88/n\n",
      "Train step: 124000\tLoss: 1.925\tAccuracy: 53.125\n",
      "Train step: 124500\tLoss: 1.891\tAccuracy: 59.375\n",
      "Train step: 125000\tLoss: 1.897\tAccuracy: 56.250\n",
      "Current Epoch: 89/n\n",
      "Train step: 125500\tLoss: 1.970\tAccuracy: 53.125\n",
      "Train step: 126000\tLoss: 1.819\tAccuracy: 62.500\n",
      "Train step: 126500\tLoss: 1.928\tAccuracy: 53.125\n",
      "Current Epoch: 90/n\n",
      "Train step: 127000\tLoss: 1.969\tAccuracy: 46.875\n",
      "Train step: 127500\tLoss: 1.879\tAccuracy: 62.500\n",
      "Train step: 128000\tLoss: 1.893\tAccuracy: 59.375\n",
      "Current Epoch: 91/n\n",
      "Train step: 128500\tLoss: 1.831\tAccuracy: 59.375\n",
      "Train step: 129000\tLoss: 1.928\tAccuracy: 56.250\n",
      "Current Epoch: 92/n\n",
      "Train step: 129500\tLoss: 1.719\tAccuracy: 78.125\n",
      "Train step: 130000\tLoss: 1.914\tAccuracy: 59.375\n",
      "Train step: 130500\tLoss: 1.934\tAccuracy: 50.000\n",
      "Current Epoch: 93/n\n",
      "Train step: 131000\tLoss: 1.890\tAccuracy: 62.500\n",
      "Train step: 131500\tLoss: 1.990\tAccuracy: 50.000\n",
      "Train step: 132000\tLoss: 1.881\tAccuracy: 56.250\n",
      "Current Epoch: 94/n\n",
      "Train step: 132500\tLoss: 1.866\tAccuracy: 59.375\n",
      "Train step: 133000\tLoss: 1.797\tAccuracy: 71.875\n",
      "Train step: 133500\tLoss: 1.868\tAccuracy: 59.375\n",
      "Current Epoch: 95/n\n",
      "Train step: 134000\tLoss: 1.960\tAccuracy: 50.000\n",
      "Train step: 134500\tLoss: 1.918\tAccuracy: 56.250\n",
      "Train step: 135000\tLoss: 1.926\tAccuracy: 53.125\n",
      "Current Epoch: 96/n\n",
      "Train step: 135500\tLoss: 1.934\tAccuracy: 53.125\n",
      "Train step: 136000\tLoss: 1.859\tAccuracy: 62.500\n",
      "Current Epoch: 97/n\n",
      "Train step: 136500\tLoss: 1.790\tAccuracy: 71.875\n",
      "Train step: 137000\tLoss: 1.843\tAccuracy: 65.625\n",
      "Train step: 137500\tLoss: 1.961\tAccuracy: 53.125\n",
      "Current Epoch: 98/n\n",
      "Train step: 138000\tLoss: 1.836\tAccuracy: 62.500\n",
      "Train step: 138500\tLoss: 1.856\tAccuracy: 59.375\n",
      "Train step: 139000\tLoss: 1.787\tAccuracy: 68.750\n",
      "Current Epoch: 99/n\n",
      "Train step: 139500\tLoss: 1.842\tAccuracy: 65.625\n",
      "Train step: 140000\tLoss: 2.029\tAccuracy: 40.625\n",
      "Train step: 140500\tLoss: 1.867\tAccuracy: 62.500\n",
      "Training finished, took 1818.59s\n"
     ]
    }
   ],
   "source": [
    "CNN5 = CNN()\n",
    "trainNet(CNN5, batch_size=32, n_epochs=100, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eR4iXT8o6RPS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2563
    },
    "colab_type": "code",
    "id": "-ERwCmokd4KH",
    "outputId": "c595c06e-0104-40b6-f399-3386c9b8053c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 35\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.302\tAccuracy: 9.375\n",
      "Train step: 500\tLoss: 2.302\tAccuracy: 12.500\n",
      "Train step: 1000\tLoss: 2.299\tAccuracy: 6.250\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.301\tAccuracy: 15.625\n",
      "Train step: 2000\tLoss: 2.295\tAccuracy: 21.875\n",
      "Train step: 2500\tLoss: 2.298\tAccuracy: 12.500\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 2.295\tAccuracy: 12.500\n",
      "Train step: 3500\tLoss: 2.299\tAccuracy: 9.375\n",
      "Train step: 4000\tLoss: 2.291\tAccuracy: 15.625\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 2.288\tAccuracy: 18.750\n",
      "Train step: 5000\tLoss: 2.299\tAccuracy: 6.250\n",
      "Train step: 5500\tLoss: 2.298\tAccuracy: 18.750\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 2.288\tAccuracy: 15.625\n",
      "Train step: 6500\tLoss: 2.287\tAccuracy: 18.750\n",
      "Train step: 7000\tLoss: 2.280\tAccuracy: 15.625\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 2.284\tAccuracy: 18.750\n",
      "Train step: 8000\tLoss: 2.280\tAccuracy: 18.750\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 2.273\tAccuracy: 18.750\n",
      "Train step: 9000\tLoss: 2.251\tAccuracy: 15.625\n",
      "Train step: 9500\tLoss: 2.248\tAccuracy: 25.000\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 2.280\tAccuracy: 6.250\n",
      "Train step: 10500\tLoss: 2.246\tAccuracy: 28.125\n",
      "Train step: 11000\tLoss: 2.219\tAccuracy: 28.125\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 2.248\tAccuracy: 21.875\n",
      "Train step: 12000\tLoss: 2.275\tAccuracy: 15.625\n",
      "Train step: 12500\tLoss: 2.292\tAccuracy: 3.125\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 2.214\tAccuracy: 28.125\n",
      "Train step: 13500\tLoss: 2.267\tAccuracy: 12.500\n",
      "Train step: 14000\tLoss: 2.186\tAccuracy: 28.125\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 2.217\tAccuracy: 21.875\n",
      "Train step: 15000\tLoss: 2.165\tAccuracy: 34.375\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 2.237\tAccuracy: 18.750\n",
      "Train step: 16000\tLoss: 2.247\tAccuracy: 21.875\n",
      "Train step: 16500\tLoss: 2.244\tAccuracy: 25.000\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 2.198\tAccuracy: 21.875\n",
      "Train step: 17500\tLoss: 2.196\tAccuracy: 21.875\n",
      "Train step: 18000\tLoss: 2.254\tAccuracy: 15.625\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 2.209\tAccuracy: 21.875\n",
      "Train step: 19000\tLoss: 2.180\tAccuracy: 28.125\n",
      "Train step: 19500\tLoss: 2.150\tAccuracy: 31.250\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 2.190\tAccuracy: 31.250\n",
      "Train step: 20500\tLoss: 2.147\tAccuracy: 34.375\n",
      "Train step: 21000\tLoss: 2.225\tAccuracy: 18.750\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 2.125\tAccuracy: 34.375\n",
      "Train step: 22000\tLoss: 2.094\tAccuracy: 40.625\n",
      "Train step: 22500\tLoss: 2.087\tAccuracy: 40.625\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 2.126\tAccuracy: 34.375\n",
      "Train step: 23500\tLoss: 2.167\tAccuracy: 21.875\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 2.093\tAccuracy: 43.750\n",
      "Train step: 24500\tLoss: 2.195\tAccuracy: 25.000\n",
      "Train step: 25000\tLoss: 2.210\tAccuracy: 37.500\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 2.171\tAccuracy: 34.375\n",
      "Train step: 26000\tLoss: 2.143\tAccuracy: 31.250\n",
      "Train step: 26500\tLoss: 2.214\tAccuracy: 28.125\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 2.138\tAccuracy: 43.750\n",
      "Train step: 27500\tLoss: 2.205\tAccuracy: 37.500\n",
      "Train step: 28000\tLoss: 2.210\tAccuracy: 18.750\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 2.057\tAccuracy: 43.750\n",
      "Train step: 29000\tLoss: 2.112\tAccuracy: 37.500\n",
      "Train step: 29500\tLoss: 2.124\tAccuracy: 37.500\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 2.098\tAccuracy: 40.625\n",
      "Train step: 30500\tLoss: 2.066\tAccuracy: 56.250\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 2.127\tAccuracy: 31.250\n",
      "Train step: 31500\tLoss: 1.970\tAccuracy: 56.250\n",
      "Train step: 32000\tLoss: 2.134\tAccuracy: 40.625\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 2.129\tAccuracy: 31.250\n",
      "Train step: 33000\tLoss: 2.083\tAccuracy: 50.000\n",
      "Train step: 33500\tLoss: 2.049\tAccuracy: 37.500\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 2.229\tAccuracy: 25.000\n",
      "Train step: 34500\tLoss: 2.136\tAccuracy: 37.500\n",
      "Train step: 35000\tLoss: 2.065\tAccuracy: 50.000\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 2.168\tAccuracy: 34.375\n",
      "Train step: 36000\tLoss: 2.070\tAccuracy: 46.875\n",
      "Train step: 36500\tLoss: 2.088\tAccuracy: 40.625\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 2.046\tAccuracy: 43.750\n",
      "Train step: 37500\tLoss: 2.037\tAccuracy: 50.000\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 1.988\tAccuracy: 53.125\n",
      "Train step: 38500\tLoss: 2.085\tAccuracy: 40.625\n",
      "Train step: 39000\tLoss: 2.136\tAccuracy: 34.375\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 2.080\tAccuracy: 34.375\n",
      "Train step: 40000\tLoss: 2.096\tAccuracy: 34.375\n",
      "Train step: 40500\tLoss: 2.108\tAccuracy: 34.375\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 2.075\tAccuracy: 34.375\n",
      "Train step: 41500\tLoss: 2.119\tAccuracy: 37.500\n",
      "Train step: 42000\tLoss: 2.172\tAccuracy: 21.875\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.941\tAccuracy: 59.375\n",
      "Train step: 43000\tLoss: 2.148\tAccuracy: 31.250\n",
      "Train step: 43500\tLoss: 1.954\tAccuracy: 53.125\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 2.001\tAccuracy: 50.000\n",
      "Train step: 44500\tLoss: 2.068\tAccuracy: 43.750\n",
      "Train step: 45000\tLoss: 2.087\tAccuracy: 37.500\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 2.056\tAccuracy: 43.750\n",
      "Train step: 46000\tLoss: 1.978\tAccuracy: 53.125\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 2.077\tAccuracy: 40.625\n",
      "Train step: 47000\tLoss: 2.040\tAccuracy: 40.625\n",
      "Train step: 47500\tLoss: 2.127\tAccuracy: 31.250\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 1.947\tAccuracy: 59.375\n",
      "Train step: 48500\tLoss: 2.065\tAccuracy: 43.750\n",
      "Train step: 49000\tLoss: 2.034\tAccuracy: 46.875\n",
      "Training finished, took 620.96s\n"
     ]
    }
   ],
   "source": [
    "CNN3 = CNN()\n",
    "trainNet(CNN3, batch_size=32, n_epochs=35, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4981
    },
    "colab_type": "code",
    "id": "b9Faxywld4Ob",
    "outputId": "e3039324-dd4e-42d9-f248-0f6029056bb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== HYPERPARAMETERS =====\n",
      "batch_size= 32\n",
      "epochs= 70\n",
      "learning_rate= 0.001\n",
      "==============================\n",
      "Current Epoch: 0/n\n",
      "Train step: 0\tLoss: 2.305\tAccuracy: 9.375\n",
      "Train step: 500\tLoss: 2.307\tAccuracy: 15.625\n",
      "Train step: 1000\tLoss: 2.302\tAccuracy: 18.750\n",
      "Current Epoch: 1/n\n",
      "Train step: 1500\tLoss: 2.302\tAccuracy: 12.500\n",
      "Train step: 2000\tLoss: 2.296\tAccuracy: 18.750\n",
      "Train step: 2500\tLoss: 2.297\tAccuracy: 15.625\n",
      "Current Epoch: 2/n\n",
      "Train step: 3000\tLoss: 2.293\tAccuracy: 15.625\n",
      "Train step: 3500\tLoss: 2.296\tAccuracy: 18.750\n",
      "Train step: 4000\tLoss: 2.297\tAccuracy: 12.500\n",
      "Current Epoch: 3/n\n",
      "Train step: 4500\tLoss: 2.295\tAccuracy: 12.500\n",
      "Train step: 5000\tLoss: 2.296\tAccuracy: 9.375\n",
      "Train step: 5500\tLoss: 2.298\tAccuracy: 12.500\n",
      "Current Epoch: 4/n\n",
      "Train step: 6000\tLoss: 2.276\tAccuracy: 21.875\n",
      "Train step: 6500\tLoss: 2.280\tAccuracy: 12.500\n",
      "Train step: 7000\tLoss: 2.298\tAccuracy: 12.500\n",
      "Current Epoch: 5/n\n",
      "Train step: 7500\tLoss: 2.274\tAccuracy: 12.500\n",
      "Train step: 8000\tLoss: 2.280\tAccuracy: 6.250\n",
      "Current Epoch: 6/n\n",
      "Train step: 8500\tLoss: 2.271\tAccuracy: 12.500\n",
      "Train step: 9000\tLoss: 2.255\tAccuracy: 18.750\n",
      "Train step: 9500\tLoss: 2.239\tAccuracy: 31.250\n",
      "Current Epoch: 7/n\n",
      "Train step: 10000\tLoss: 2.262\tAccuracy: 18.750\n",
      "Train step: 10500\tLoss: 2.263\tAccuracy: 15.625\n",
      "Train step: 11000\tLoss: 2.213\tAccuracy: 25.000\n",
      "Current Epoch: 8/n\n",
      "Train step: 11500\tLoss: 2.166\tAccuracy: 37.500\n",
      "Train step: 12000\tLoss: 2.278\tAccuracy: 15.625\n",
      "Train step: 12500\tLoss: 2.204\tAccuracy: 28.125\n",
      "Current Epoch: 9/n\n",
      "Train step: 13000\tLoss: 2.257\tAccuracy: 15.625\n",
      "Train step: 13500\tLoss: 2.229\tAccuracy: 15.625\n",
      "Train step: 14000\tLoss: 2.229\tAccuracy: 18.750\n",
      "Current Epoch: 10/n\n",
      "Train step: 14500\tLoss: 2.216\tAccuracy: 21.875\n",
      "Train step: 15000\tLoss: 2.202\tAccuracy: 28.125\n",
      "Current Epoch: 11/n\n",
      "Train step: 15500\tLoss: 2.234\tAccuracy: 18.750\n",
      "Train step: 16000\tLoss: 2.271\tAccuracy: 12.500\n",
      "Train step: 16500\tLoss: 2.223\tAccuracy: 21.875\n",
      "Current Epoch: 12/n\n",
      "Train step: 17000\tLoss: 2.203\tAccuracy: 25.000\n",
      "Train step: 17500\tLoss: 2.239\tAccuracy: 12.500\n",
      "Train step: 18000\tLoss: 2.215\tAccuracy: 18.750\n",
      "Current Epoch: 13/n\n",
      "Train step: 18500\tLoss: 2.157\tAccuracy: 34.375\n",
      "Train step: 19000\tLoss: 2.194\tAccuracy: 18.750\n",
      "Train step: 19500\tLoss: 2.259\tAccuracy: 9.375\n",
      "Current Epoch: 14/n\n",
      "Train step: 20000\tLoss: 2.043\tAccuracy: 43.750\n",
      "Train step: 20500\tLoss: 2.163\tAccuracy: 31.250\n",
      "Train step: 21000\tLoss: 2.101\tAccuracy: 31.250\n",
      "Current Epoch: 15/n\n",
      "Train step: 21500\tLoss: 2.157\tAccuracy: 31.250\n",
      "Train step: 22000\tLoss: 2.151\tAccuracy: 34.375\n",
      "Train step: 22500\tLoss: 2.156\tAccuracy: 37.500\n",
      "Current Epoch: 16/n\n",
      "Train step: 23000\tLoss: 2.199\tAccuracy: 25.000\n",
      "Train step: 23500\tLoss: 2.141\tAccuracy: 28.125\n",
      "Current Epoch: 17/n\n",
      "Train step: 24000\tLoss: 2.140\tAccuracy: 40.625\n",
      "Train step: 24500\tLoss: 2.142\tAccuracy: 28.125\n",
      "Train step: 25000\tLoss: 2.128\tAccuracy: 31.250\n",
      "Current Epoch: 18/n\n",
      "Train step: 25500\tLoss: 2.229\tAccuracy: 18.750\n",
      "Train step: 26000\tLoss: 2.158\tAccuracy: 31.250\n",
      "Train step: 26500\tLoss: 2.165\tAccuracy: 21.875\n",
      "Current Epoch: 19/n\n",
      "Train step: 27000\tLoss: 2.132\tAccuracy: 37.500\n",
      "Train step: 27500\tLoss: 2.162\tAccuracy: 34.375\n",
      "Train step: 28000\tLoss: 2.118\tAccuracy: 40.625\n",
      "Current Epoch: 20/n\n",
      "Train step: 28500\tLoss: 2.188\tAccuracy: 31.250\n",
      "Train step: 29000\tLoss: 2.149\tAccuracy: 21.875\n",
      "Train step: 29500\tLoss: 2.147\tAccuracy: 37.500\n",
      "Current Epoch: 21/n\n",
      "Train step: 30000\tLoss: 2.165\tAccuracy: 25.000\n",
      "Train step: 30500\tLoss: 2.108\tAccuracy: 43.750\n",
      "Current Epoch: 22/n\n",
      "Train step: 31000\tLoss: 2.080\tAccuracy: 46.875\n",
      "Train step: 31500\tLoss: 2.101\tAccuracy: 43.750\n",
      "Train step: 32000\tLoss: 2.099\tAccuracy: 40.625\n",
      "Current Epoch: 23/n\n",
      "Train step: 32500\tLoss: 2.102\tAccuracy: 34.375\n",
      "Train step: 33000\tLoss: 2.067\tAccuracy: 40.625\n",
      "Train step: 33500\tLoss: 2.049\tAccuracy: 43.750\n",
      "Current Epoch: 24/n\n",
      "Train step: 34000\tLoss: 2.032\tAccuracy: 46.875\n",
      "Train step: 34500\tLoss: 2.083\tAccuracy: 43.750\n",
      "Train step: 35000\tLoss: 2.187\tAccuracy: 28.125\n",
      "Current Epoch: 25/n\n",
      "Train step: 35500\tLoss: 2.129\tAccuracy: 28.125\n",
      "Train step: 36000\tLoss: 2.072\tAccuracy: 43.750\n",
      "Train step: 36500\tLoss: 2.111\tAccuracy: 34.375\n",
      "Current Epoch: 26/n\n",
      "Train step: 37000\tLoss: 2.154\tAccuracy: 25.000\n",
      "Train step: 37500\tLoss: 2.084\tAccuracy: 40.625\n",
      "Current Epoch: 27/n\n",
      "Train step: 38000\tLoss: 2.129\tAccuracy: 34.375\n",
      "Train step: 38500\tLoss: 2.061\tAccuracy: 43.750\n",
      "Train step: 39000\tLoss: 1.974\tAccuracy: 50.000\n",
      "Current Epoch: 28/n\n",
      "Train step: 39500\tLoss: 2.064\tAccuracy: 40.625\n",
      "Train step: 40000\tLoss: 2.066\tAccuracy: 40.625\n",
      "Train step: 40500\tLoss: 1.991\tAccuracy: 50.000\n",
      "Current Epoch: 29/n\n",
      "Train step: 41000\tLoss: 1.964\tAccuracy: 53.125\n",
      "Train step: 41500\tLoss: 2.057\tAccuracy: 43.750\n",
      "Train step: 42000\tLoss: 1.967\tAccuracy: 50.000\n",
      "Current Epoch: 30/n\n",
      "Train step: 42500\tLoss: 1.995\tAccuracy: 53.125\n",
      "Train step: 43000\tLoss: 1.980\tAccuracy: 56.250\n",
      "Train step: 43500\tLoss: 2.153\tAccuracy: 34.375\n",
      "Current Epoch: 31/n\n",
      "Train step: 44000\tLoss: 2.163\tAccuracy: 28.125\n",
      "Train step: 44500\tLoss: 2.038\tAccuracy: 43.750\n",
      "Train step: 45000\tLoss: 1.925\tAccuracy: 56.250\n",
      "Current Epoch: 32/n\n",
      "Train step: 45500\tLoss: 2.068\tAccuracy: 34.375\n",
      "Train step: 46000\tLoss: 1.993\tAccuracy: 53.125\n",
      "Current Epoch: 33/n\n",
      "Train step: 46500\tLoss: 1.912\tAccuracy: 62.500\n",
      "Train step: 47000\tLoss: 1.980\tAccuracy: 46.875\n",
      "Train step: 47500\tLoss: 1.968\tAccuracy: 59.375\n",
      "Current Epoch: 34/n\n",
      "Train step: 48000\tLoss: 2.092\tAccuracy: 37.500\n",
      "Train step: 48500\tLoss: 2.129\tAccuracy: 31.250\n",
      "Train step: 49000\tLoss: 1.976\tAccuracy: 46.875\n",
      "Current Epoch: 35/n\n",
      "Train step: 49500\tLoss: 2.047\tAccuracy: 37.500\n",
      "Train step: 50000\tLoss: 1.960\tAccuracy: 50.000\n",
      "Train step: 50500\tLoss: 1.919\tAccuracy: 53.125\n",
      "Current Epoch: 36/n\n",
      "Train step: 51000\tLoss: 1.967\tAccuracy: 56.250\n",
      "Train step: 51500\tLoss: 2.147\tAccuracy: 28.125\n",
      "Train step: 52000\tLoss: 2.037\tAccuracy: 40.625\n",
      "Current Epoch: 37/n\n",
      "Train step: 52500\tLoss: 2.047\tAccuracy: 34.375\n",
      "Train step: 53000\tLoss: 1.979\tAccuracy: 46.875\n",
      "Current Epoch: 38/n\n",
      "Train step: 53500\tLoss: 1.972\tAccuracy: 53.125\n",
      "Train step: 54000\tLoss: 2.003\tAccuracy: 43.750\n",
      "Train step: 54500\tLoss: 1.964\tAccuracy: 53.125\n",
      "Current Epoch: 39/n\n",
      "Train step: 55000\tLoss: 2.028\tAccuracy: 43.750\n",
      "Train step: 55500\tLoss: 1.952\tAccuracy: 53.125\n",
      "Train step: 56000\tLoss: 1.957\tAccuracy: 50.000\n",
      "Current Epoch: 40/n\n",
      "Train step: 56500\tLoss: 2.035\tAccuracy: 46.875\n",
      "Train step: 57000\tLoss: 1.948\tAccuracy: 53.125\n",
      "Train step: 57500\tLoss: 2.112\tAccuracy: 37.500\n",
      "Current Epoch: 41/n\n",
      "Train step: 58000\tLoss: 2.001\tAccuracy: 43.750\n",
      "Train step: 58500\tLoss: 2.027\tAccuracy: 40.625\n",
      "Train step: 59000\tLoss: 2.056\tAccuracy: 34.375\n",
      "Current Epoch: 42/n\n",
      "Train step: 59500\tLoss: 1.886\tAccuracy: 65.625\n",
      "Train step: 60000\tLoss: 1.921\tAccuracy: 59.375\n",
      "Train step: 60500\tLoss: 2.285\tAccuracy: 3.125\n",
      "Current Epoch: 43/n\n",
      "Train step: 61000\tLoss: 1.962\tAccuracy: 59.375\n",
      "Train step: 61500\tLoss: 2.078\tAccuracy: 40.625\n",
      "Current Epoch: 44/n\n",
      "Train step: 62000\tLoss: 2.043\tAccuracy: 40.625\n",
      "Train step: 62500\tLoss: 1.938\tAccuracy: 56.250\n",
      "Train step: 63000\tLoss: 1.915\tAccuracy: 59.375\n",
      "Current Epoch: 45/n\n",
      "Train step: 63500\tLoss: 2.021\tAccuracy: 43.750\n",
      "Train step: 64000\tLoss: 1.961\tAccuracy: 53.125\n",
      "Train step: 64500\tLoss: 2.044\tAccuracy: 40.625\n",
      "Current Epoch: 46/n\n",
      "Train step: 65000\tLoss: 1.925\tAccuracy: 56.250\n",
      "Train step: 65500\tLoss: 2.034\tAccuracy: 37.500\n",
      "Train step: 66000\tLoss: 2.142\tAccuracy: 31.250\n",
      "Current Epoch: 47/n\n",
      "Train step: 66500\tLoss: 1.925\tAccuracy: 53.125\n",
      "Train step: 67000\tLoss: 2.089\tAccuracy: 34.375\n",
      "Train step: 67500\tLoss: 1.950\tAccuracy: 50.000\n",
      "Current Epoch: 48/n\n",
      "Train step: 68000\tLoss: 1.996\tAccuracy: 50.000\n",
      "Train step: 68500\tLoss: 1.922\tAccuracy: 53.125\n",
      "Current Epoch: 49/n\n",
      "Train step: 69000\tLoss: 1.950\tAccuracy: 56.250\n",
      "Train step: 69500\tLoss: 2.018\tAccuracy: 43.750\n",
      "Train step: 70000\tLoss: 1.954\tAccuracy: 46.875\n",
      "Current Epoch: 50/n\n",
      "Train step: 70500\tLoss: 2.126\tAccuracy: 34.375\n",
      "Train step: 71000\tLoss: 1.891\tAccuracy: 56.250\n",
      "Train step: 71500\tLoss: 1.938\tAccuracy: 53.125\n",
      "Current Epoch: 51/n\n",
      "Train step: 72000\tLoss: 2.060\tAccuracy: 40.625\n",
      "Train step: 72500\tLoss: 1.968\tAccuracy: 53.125\n",
      "Train step: 73000\tLoss: 1.870\tAccuracy: 62.500\n",
      "Current Epoch: 52/n\n",
      "Train step: 73500\tLoss: 1.948\tAccuracy: 50.000\n",
      "Train step: 74000\tLoss: 1.999\tAccuracy: 46.875\n",
      "Train step: 74500\tLoss: 1.926\tAccuracy: 56.250\n",
      "Current Epoch: 53/n\n",
      "Train step: 75000\tLoss: 2.064\tAccuracy: 50.000\n",
      "Train step: 75500\tLoss: 1.992\tAccuracy: 46.875\n",
      "Current Epoch: 54/n\n",
      "Train step: 76000\tLoss: 1.847\tAccuracy: 62.500\n",
      "Train step: 76500\tLoss: 1.871\tAccuracy: 59.375\n",
      "Train step: 77000\tLoss: 1.917\tAccuracy: 56.250\n",
      "Current Epoch: 55/n\n",
      "Train step: 77500\tLoss: 1.853\tAccuracy: 65.625\n",
      "Train step: 78000\tLoss: 1.996\tAccuracy: 46.875\n",
      "Train step: 78500\tLoss: 1.912\tAccuracy: 56.250\n",
      "Current Epoch: 56/n\n",
      "Train step: 79000\tLoss: 1.907\tAccuracy: 56.250\n",
      "Train step: 79500\tLoss: 2.014\tAccuracy: 50.000\n",
      "Train step: 80000\tLoss: 1.855\tAccuracy: 65.625\n",
      "Current Epoch: 57/n\n",
      "Train step: 80500\tLoss: 1.972\tAccuracy: 56.250\n",
      "Train step: 81000\tLoss: 1.871\tAccuracy: 65.625\n",
      "Train step: 81500\tLoss: 1.967\tAccuracy: 50.000\n",
      "Current Epoch: 58/n\n",
      "Train step: 82000\tLoss: 1.857\tAccuracy: 59.375\n",
      "Train step: 82500\tLoss: 1.991\tAccuracy: 46.875\n",
      "Train step: 83000\tLoss: 1.993\tAccuracy: 50.000\n",
      "Current Epoch: 59/n\n",
      "Train step: 83500\tLoss: 2.109\tAccuracy: 37.500\n",
      "Train step: 84000\tLoss: 1.918\tAccuracy: 62.500\n",
      "Current Epoch: 60/n\n",
      "Train step: 84500\tLoss: 1.799\tAccuracy: 68.750\n",
      "Train step: 85000\tLoss: 2.025\tAccuracy: 40.625\n",
      "Train step: 85500\tLoss: 1.833\tAccuracy: 68.750\n",
      "Current Epoch: 61/n\n",
      "Train step: 86000\tLoss: 1.846\tAccuracy: 62.500\n",
      "Train step: 86500\tLoss: 1.901\tAccuracy: 59.375\n",
      "Train step: 87000\tLoss: 1.952\tAccuracy: 56.250\n",
      "Current Epoch: 62/n\n",
      "Train step: 87500\tLoss: 1.879\tAccuracy: 59.375\n",
      "Train step: 88000\tLoss: 1.997\tAccuracy: 53.125\n",
      "Train step: 88500\tLoss: 2.008\tAccuracy: 43.750\n",
      "Current Epoch: 63/n\n",
      "Train step: 89000\tLoss: 1.972\tAccuracy: 50.000\n",
      "Train step: 89500\tLoss: 2.005\tAccuracy: 43.750\n",
      "Train step: 90000\tLoss: 1.917\tAccuracy: 56.250\n",
      "Current Epoch: 64/n\n",
      "Train step: 90500\tLoss: 2.028\tAccuracy: 46.875\n",
      "Train step: 91000\tLoss: 1.883\tAccuracy: 59.375\n",
      "Current Epoch: 65/n\n",
      "Train step: 91500\tLoss: 2.067\tAccuracy: 37.500\n",
      "Train step: 92000\tLoss: 2.007\tAccuracy: 46.875\n",
      "Train step: 92500\tLoss: 1.931\tAccuracy: 53.125\n",
      "Current Epoch: 66/n\n",
      "Train step: 93000\tLoss: 1.921\tAccuracy: 50.000\n",
      "Train step: 93500\tLoss: 1.892\tAccuracy: 56.250\n",
      "Train step: 94000\tLoss: 1.901\tAccuracy: 56.250\n",
      "Current Epoch: 67/n\n",
      "Train step: 94500\tLoss: 1.830\tAccuracy: 62.500\n",
      "Train step: 95000\tLoss: 1.988\tAccuracy: 50.000\n",
      "Train step: 95500\tLoss: 1.841\tAccuracy: 65.625\n",
      "Current Epoch: 68/n\n",
      "Train step: 96000\tLoss: 1.884\tAccuracy: 59.375\n",
      "Train step: 96500\tLoss: 1.911\tAccuracy: 50.000\n",
      "Train step: 97000\tLoss: 1.878\tAccuracy: 59.375\n",
      "Current Epoch: 69/n\n",
      "Train step: 97500\tLoss: 1.935\tAccuracy: 50.000\n",
      "Train step: 98000\tLoss: 2.004\tAccuracy: 46.875\n",
      "Training finished, took 1246.80s\n"
     ]
    }
   ],
   "source": [
    "CNN4 = CNN()\n",
    "trainNet(CNN4, batch_size=32, n_epochs=70, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L7a4VoUWvbMQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FINAL PART 2 SUBMISSION",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
